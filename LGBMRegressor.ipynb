{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd66320-1c89-439b-bd95-93ffe21d4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "处理数据集: VOD_Ku_Hpol_Asc_Cleaned_Type1 (添加VWC_sample≤30过滤)\n",
      "==================================================\n",
      "开始数据加载和预处理...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['clay', 'sand', 'silt'] (sheet: VOD_Ku_Hpol_Asc_Cleaned_Type1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:607\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[1;34m(self, columns, usecols_key, num_original_columns)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     col_indices\u001b[38;5;241m.\u001b[39mappend(\u001b[43musecols_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: 'clay' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 369\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m处理数据集: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (添加VWC_sample≤30过滤)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m X, y, df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# 模型训练与评估\u001b[39;00m\n\u001b[0;32m    372\u001b[0m model \u001b[38;5;241m=\u001b[39m train_and_evaluate(X, y, df)\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(file_path, sheet_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m columns_to_extract \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSM_Asc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrass_man\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrass_nat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShrub_bd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShrub_be\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShrub_nd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShrub_ne\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHveg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msilt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msand\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 添加静态特征\u001b[39;00m\n\u001b[0;32m     37\u001b[0m ]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 读取数据\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns_to_extract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 计算VWC_sample\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:916\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    915\u001b[0m         err\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (sheet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39merr\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m--> 916\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_sheetname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet name is an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:878\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# GH 12292 : error when read one empty column from excel file\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextParser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_index_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_index_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_blank_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GH 39808\u001b[39;49;00m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     output[asheetname] \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mread(nrows\u001b[38;5;241m=\u001b[39mnrows)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m header_names:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:2053\u001b[0m, in \u001b[0;36mTextParser\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;124;03mConverts lists of lists/tuples into DataFrames with proper type inference\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;124;03mand optional (e.g. string to datetime) conversion. Also enables iterating\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2050\u001b[0m \u001b[38;5;124;03m    `round_trip` for the round-trip converter.\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:133\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[0;32m    129\u001b[0m (\n\u001b[0;32m    130\u001b[0m     columns,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_original_columns,\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols,\n\u001b[1;32m--> 133\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    146\u001b[0m )\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:542\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m             columns \u001b[38;5;241m=\u001b[39m [names]\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m         columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_usecols\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_original_columns\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m     ncols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_header_line)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:609\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[1;34m(self, columns, usecols_key, num_original_columns)\u001b[0m\n\u001b[0;32m    607\u001b[0m         col_indices\u001b[38;5;241m.\u001b[39mappend(usecols_key\u001b[38;5;241m.\u001b[39mindex(col))\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 609\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_usecols_names\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m     col_indices\u001b[38;5;241m.\u001b[39mappend(col)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:979\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[1;34m(self, usecols, names)\u001b[0m\n\u001b[0;32m    977\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    982\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['clay', 'sand', 'silt'] (sheet: VOD_Ku_Hpol_Asc_Cleaned_Type1)"
     ]
    }
   ],
   "source": [
    "# Ku波段H极化的VOD输入，LightGBM版本，贝叶斯优化超参数\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ============================== 数据预处理部分 ==============================\n",
    "def load_and_preprocess_data(file_path, sheet_name):\n",
    "    \"\"\"数据加载和预处理函数，添加静态特征\"\"\"\n",
    "    print(\"开始数据加载和预处理...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 定义要提取的列\n",
    "    columns_to_extract = [\n",
    "        'AGB', 'SM_Asc', 'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne',\n",
    "        'LAI', 'LFMCValue', 'VOD_Ku_Hpol_Asc', 'SamplingDate',\n",
    "        'Hveg', 'clay', 'silt', 'sand'  # 添加静态特征\n",
    "    ]\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, usecols=columns_to_extract)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # 计算VWC_sample\n",
    "    df['VWC_sample'] = (df['AGB'] * df['LFMCValue']) / 1000\n",
    "    \n",
    "    # =========== 移除VWC_sample > 30的样本（异常值） ===========\n",
    "    original_count = len(df)\n",
    "    df = df[df['VWC_sample'] <= 30]  # 过滤条件\n",
    "    filtered_count = len(df)\n",
    "    print(f\"  移除VWC_sample > 30的样本: 原始样本数 {original_count}, 过滤后样本数 {filtered_count} (移除 {original_count-filtered_count} 个样本)\")\n",
    "    # ==========================================================\n",
    "    \n",
    "    df.drop(['AGB', 'LFMCValue'], axis=1, inplace=True)\n",
    "    \n",
    "    # 提取年份差\n",
    "    df['Year_diff'] = df['SamplingDate'].dt.year.apply(lambda x: 2020 - x)\n",
    "    \n",
    "    # 归一化处理\n",
    "    df['LAI'] = df['LAI'].clip(0, 6) / 6\n",
    "    df['VOD'] = df['VOD_Ku_Hpol_Asc'].clip(0, 2) / 2\n",
    "    df['Hveg'] = df['Hveg'] / 10  # 树高归一化\n",
    "    \n",
    "    # 土壤特征处理\n",
    "    df['soil_total'] = df[['clay', 'silt', 'sand']].sum(axis=1)\n",
    "    df['clay_ratio'] = df['clay'] / df['soil_total']\n",
    "    df['silt_ratio'] = df['silt'] / df['soil_total']\n",
    "    df['sand_ratio'] = df['sand'] / df['soil_total']\n",
    "    \n",
    "    # 创建交互特征\n",
    "    df['LAI_SM'] = df['LAI'] * df['SM_Asc']\n",
    "    df['VOD_Hveg'] = df['VOD'] * df['Hveg']\n",
    "    \n",
    "    # 重命名列\n",
    "    df = df.rename(columns={'SM_Asc': 'SM'})\n",
    "    \n",
    "    # 定义特征和目标列\n",
    "    feature_columns = [\n",
    "        'VOD', 'LAI', 'SM', 'Hveg',\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne',\n",
    "        'clay_ratio', 'silt_ratio', 'sand_ratio',\n",
    "        'LAI_SM', 'VOD_Hveg'\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df['VWC_sample']\n",
    "    \n",
    "    # 数据质量分析\n",
    "    print(\"\\n数据特征分析 (过滤后):\")\n",
    "    print(f\"特征数量: {len(feature_columns)}\")\n",
    "    print(f\"样本数量: {len(X)}\")\n",
    "    print(f\"VWC范围: {y.min():.2f} - {y.max():.2f} kg/m²\")\n",
    "    \n",
    "    # 检测特征相关性\n",
    "    corr_matrix = pd.concat([X, y], axis=1).corr()\n",
    "    print(\"\\n特征相关性分析 (top 5):\")\n",
    "    print(corr_matrix['VWC_sample'].abs().sort_values(ascending=False).head(10))\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    print(f\"数据预处理完成，耗时: {elapsed_time:.2f} 分钟\")\n",
    "    \n",
    "    return X, y, df  # 返回原始df用于可视化\n",
    "\n",
    "# ============================== 模型训练与评估部分 ==============================\n",
    "def train_and_evaluate(X, y, df):\n",
    "    \"\"\"模型训练与评估主函数 - LightGBM版本\"\"\"\n",
    "    print(\"\\n开始模型训练与评估流程(使用LightGBM)...\")\n",
    "    \n",
    "    # 1. 数据划分（2:1比例）\n",
    "    print(\"划分训练集和测试集...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.333, \n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        np.arange(len(X)), \n",
    "        test_size=0.333, \n",
    "        random_state=SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"训练集样本数: {len(X_train)}, 测试集样本数: {len(X_test)}\")\n",
    "    \n",
    "    # 创建LightGBM数据集\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "    \n",
    "    # 2. 贝叶斯优化调参\n",
    "    print(\"\\n开始贝叶斯优化调参...\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"VWC_LGBM_Optimization_KuHpol\",\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=SEED)\n",
    "    )\n",
    "    \n",
    "    # 使用自定义评估函数进行优化\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_train, y_train, X_test, y_test), \n",
    "        n_trials=100,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # 获取最佳参数\n",
    "    best_params = study.best_params\n",
    "    print(\"\\n最佳参数组合:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"最佳验证RMSE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 3. 使用最佳参数训练最终模型\n",
    "    print(\"\\n训练最终模型...\")\n",
    "    final_model = lgb.train(\n",
    "        {**best_params, \n",
    "         'objective': 'regression',\n",
    "         'metric': 'rmse',\n",
    "         'verbosity': -1,\n",
    "         'seed': SEED},\n",
    "        lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgb_test],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 4. 测试集评估\n",
    "    print(\"\\n测试集评估...\")\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"测试集RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"测试集R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # 5. 高级模型诊断\n",
    "    model_diagnosis(final_model, X_test, y_test, df.iloc[test_idx])\n",
    "    \n",
    "    # 6. 可视化预测结果\n",
    "    plot_results(y_test, y_pred)\n",
    "    \n",
    "    # 7. 保存模型\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_path = \"models/LGBM_Ku_Hpol_Type1.txt\"\n",
    "    final_model.save_model(model_path)\n",
    "    print(f\"\\n模型已保存至: {model_path}\")\n",
    "    \n",
    "    return final_model\n",
    "\n",
    "# ============================== 贝叶斯优化目标函数 ==============================\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"贝叶斯优化目标函数 - LightGBM版本\"\"\"\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 200, step=10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0, step=0.05),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0, step=0.05),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.3),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100, 500, step=50)\n",
    "    }\n",
    "    \n",
    "    # 使用早停策略训练模型\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_val = lgb.Dataset(X_test, label=y_test)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        {**params, \n",
    "         'objective': 'regression',\n",
    "         'metric': 'rmse',\n",
    "         'verbosity': -1,\n",
    "         'seed': SEED},\n",
    "        lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgb_val],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=30),\n",
    "            lgb.log_evaluation(False)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 获取验证集最佳RMSE\n",
    "    best_rmse = model.best_score['valid_0']['rmse']\n",
    "    \n",
    "    # 特征重要性分析（用于优化过程）\n",
    "    importances = model.feature_importance(importance_type='gain')\n",
    "    top_features = sorted(zip(X_train.columns, importances), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # 将重要特征保存到trial中\n",
    "    for i, (feature, importance) in enumerate(top_features):\n",
    "        trial.set_user_attr(f\"top_feature_{i+1}\", feature)\n",
    "        trial.set_user_attr(f\"importance_{i+1}\", importance)\n",
    "    \n",
    "    return best_rmse\n",
    "\n",
    "# ============================== 模型诊断函数 ==============================\n",
    "def model_diagnosis(model, X_test, y_test, test_df):\n",
    "    \"\"\"高级模型诊断函数\"\"\"\n",
    "    print(\"\\n高级模型诊断:\")\n",
    "    \n",
    "    # 1. 特征重要性分析\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_test.columns,\n",
    "        'Importance': model.feature_importance(importance_type='gain')\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10特征重要性:\")\n",
    "    print(importance_df.head(10))\n",
    "    \n",
    "    # 2. 按植被类型分析\n",
    "    for veg_type in ['Grass', 'Shrub', 'Tree']:\n",
    "        mask = test_df[f\"{veg_type}_man\"] + test_df[f\"{veg_type}_nat\"] > 0.5\n",
    "        if mask.sum() > 0:\n",
    "            sub_pred = model.predict(X_test[mask])\n",
    "            sub_rmse = np.sqrt(mean_squared_error(y_test[mask], sub_pred))\n",
    "            print(f\"{veg_type}植被区域RMSE: {sub_rmse:.4f} (样本数: {mask.sum()})\")\n",
    "    \n",
    "    # 3. 按土壤类型分析\n",
    "    soil_primary = test_df[['clay_ratio', 'silt_ratio', 'sand_ratio']].idxmax(axis=1)\n",
    "    for soil_type in ['clay_ratio', 'silt_ratio', 'sand_ratio']:\n",
    "        mask = soil_primary == soil_type\n",
    "        if mask.sum() > 0:\n",
    "            sub_pred = model.predict(X_test[mask])\n",
    "            sub_rmse = np.sqrt(mean_squared_error(y_test[mask], sub_pred))\n",
    "            soil_name = soil_type.replace('_ratio', '')\n",
    "            print(f\"{soil_name}土壤区域RMSE: {sub_rmse:.4f} (样本数: {mask.sum()})\")\n",
    "    \n",
    "    # 4. 树高与预测精度的关系\n",
    "    height_bins = pd.cut(test_df['Hveg'], bins=5)\n",
    "    print(\"\\n树高与预测精度关系:\")\n",
    "    for bin_group in height_bins.cat.categories:\n",
    "        mask = height_bins == bin_group\n",
    "        sub_pred = model.predict(X_test[mask])\n",
    "        sub_rmse = np.sqrt(mean_squared_error(y_test[mask], sub_pred))\n",
    "        print(f\"树高 {bin_group}: RMSE {sub_rmse:.4f} (样本数: {mask.sum()})\")\n",
    "        \n",
    "    # 5. VWC_sample分布分析（关键新增）\n",
    "    vwc_bins = pd.cut(test_df['VWC_sample'], bins=5)\n",
    "    print(\"\\nVWC区间预测精度分析:\")\n",
    "    for bin_group in vwc_bins.cat.categories:\n",
    "        mask = vwc_bins == bin_group\n",
    "        if mask.sum() > 0:\n",
    "            sub_pred = model.predict(X_test[mask])\n",
    "            sub_rmse = np.sqrt(mean_squared_error(y_test[mask], sub_pred))\n",
    "            vwc_mean = test_df.loc[mask, 'VWC_sample'].mean()\n",
    "            print(f\"VWC区间 {bin_group} (均值{vwc_mean:.2f}): RMSE {sub_rmse:.4f} (样本数: {mask.sum()})\")\n",
    "\n",
    "# ============================== 可视化函数 ==============================\n",
    "def plot_results(y_true, y_pred):\n",
    "    \"\"\"结果可视化函数 - 改进版\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # 计算RMSE和R²\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 绘制散点图（增加透明度）\n",
    "    plt.scatter(\n",
    "        y_true, y_pred, \n",
    "        alpha=0.5,\n",
    "        c='#1f77b4',\n",
    "        edgecolors='none'\n",
    "    )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val = max(max(y_true), max(y_pred)) * 1.05\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7)   \n",
    "    \n",
    "    # 设置坐标轴范围和标签\n",
    "    plt.xlim(0, 30)\n",
    "    plt.ylim(0, 30)\n",
    "    plt.xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('LGBM Predicted VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title('Ku-Band, H-pol - LightGBM Prediction (VWC≤30)', fontsize=16, pad=20, fontweight='bold')\n",
    "    \n",
    "    # 添加统计指标文本\n",
    "    plt.text(0.05, 0.95, \n",
    "             f'RMSE = {rmse:.3f} kg/m²\\nR² = {r2:.3f}', \n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=13,\n",
    "             fontweight='bold',\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # 添加密度等高线\n",
    "    try:\n",
    "        from scipy.stats import gaussian_kde\n",
    "        xy = np.vstack([y_true, y_pred])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        idx = z.argsort()\n",
    "        plt.scatter(\n",
    "            y_true, y_pred, \n",
    "            c=z[idx], \n",
    "            cmap='viridis', \n",
    "            alpha=0.4, \n",
    "            s=10\n",
    "        )\n",
    "        plt.colorbar(label='Density')\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # 网格线和样式调整\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    plot_path = \"figures/lgbm_prediction_results_Ku_Hpol_Type1_filtered.png\"\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Prediction plot saved to: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================== 主执行流程 ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    # 数据加载与预处理\n",
    "    file_path = r\"E:\\Matlab\\EX2025\\AuxiliaryData\\VWC_ML_Data.xlsx\"\n",
    "    sheet_name = \"VOD_Ku_Hpol_Asc_Cleaned_Type1\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理数据集: {sheet_name} (添加VWC_sample≤30过滤)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X, y, df = load_and_preprocess_data(file_path, sheet_name)\n",
    "    \n",
    "    # 模型训练与评估\n",
    "    model = train_and_evaluate(X, y, df)\n",
    "    \n",
    "    # 输出训练完成信息\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"模型训练完成 (添加VWC_sample>30过滤)!\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f66b2-6456-455b-8cc3-9e47b8202c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

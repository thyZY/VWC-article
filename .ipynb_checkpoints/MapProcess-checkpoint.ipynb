{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5123586a-2b03-46c6-b48f-1d98c6fbfbf4",
   "metadata": {},
   "source": [
    "# 地图的进一步分析与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4a5c5-8119-4682-bbce-facd9f2457a9",
   "metadata": {},
   "source": [
    "制作掩膜，去除VWC产品中不合要求的数据并使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8198f876-c145-4d72-9773-a554c34c6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理: E:\\data\\ESACCI PFT\\Resample\\Data\\2020.mat\n",
      "成功创建: E:\\data\\ESACCI PFT\\Resample\\Data\\mainType.tif\n",
      "处理完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\osgeo\\gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "# 定义文件路径和变量列表\n",
    "PFT_BASE_PATH = r'E:\\data\\ESACCI PFT\\Resample\\Data'\n",
    "MAT_FILE = os.path.join(PFT_BASE_PATH, '2020.mat')\n",
    "OUTPUT_FILE = os.path.join(PFT_BASE_PATH, 'mainType.tif')\n",
    "\n",
    "# 确保变量顺序与指定的索引匹配\n",
    "VARIABLES = [\n",
    "    'water', 'bare', 'snowice', 'built', \n",
    "    'grassman', 'grassnat', \n",
    "    'shrubbd', 'shrubbe', 'shrubnd', 'shrubne',\n",
    "    'treebd', 'treebe', 'treend', 'treene'\n",
    "]\n",
    "\n",
    "# 主处理函数\n",
    "def process_pft_data():\n",
    "    try:\n",
    "        # 打开MAT文件 (v7.3格式)\n",
    "        with h5py.File(MAT_FILE, 'r') as f:\n",
    "            # 检查文件是否包含所需变量\n",
    "            available_keys = list(f.keys())\n",
    "            missing_vars = [var for var in VARIABLES if var not in available_keys]\n",
    "            \n",
    "            if missing_vars:\n",
    "                raise ValueError(f\"MAT文件缺少必需变量: {', '.join(missing_vars)}\")\n",
    "            \n",
    "            # 创建数据立方体 (14, 1800, 3600)\n",
    "            data_cube = np.zeros((len(VARIABLES), 1800, 3600), dtype=np.float32)\n",
    "            \n",
    "            # 读取所有变量并调整形状\n",
    "            for idx, var in enumerate(VARIABLES):\n",
    "                dataset = f[var]\n",
    "                \n",
    "                # 提取数据 - 适用于v7.3的HDF5格式\n",
    "                if isinstance(dataset, h5py.Dataset):\n",
    "                    data = dataset[:]\n",
    "                    \n",
    "                    # 处理不同的数据方向\n",
    "                    if data.shape == (3600, 1800):\n",
    "                        data = data.T  # 转置为1800x3600\n",
    "                    elif data.shape != (1800, 3600):\n",
    "                        raise ValueError(f\"变量 {var} 具有不支持的形状: {data.shape}\")\n",
    "                    \n",
    "                    # 确保数据类型为浮点数\n",
    "                    data_cube[idx] = data.astype(np.float32)\n",
    "                else:\n",
    "                    raise ValueError(f\"变量 {var} 不是HDF5数据集\")\n",
    "            \n",
    "            # 检查形状\n",
    "            if data_cube.shape != (14, 1800, 3600):\n",
    "                raise ValueError(f\"数据立方体形状异常: {data_cube.shape} (期望 (14, 1800, 3600))\")\n",
    "            \n",
    "            # 找出每个位置的最大值索引\n",
    "            main_type = np.argmax(data_cube, axis=0).astype(np.uint8)\n",
    "            \n",
    "            # 保存为TIFF文件\n",
    "            save_as_geotiff(main_type, OUTPUT_FILE)\n",
    "            \n",
    "            return f\"成功创建: {OUTPUT_FILE}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"处理失败: {str(e)}\"\n",
    "\n",
    "# TIFF保存函数\n",
    "def save_as_geotiff(data, output_path):\n",
    "    \"\"\"将2D数组保存为地理参考的TIFF文件\"\"\"\n",
    "    # 设置GDAL驱动程序\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    # 创建输出数据集\n",
    "    out_ds = driver.Create(\n",
    "        output_path,\n",
    "        xsize=data.shape[1],\n",
    "        ysize=data.shape[0],\n",
    "        bands=1,\n",
    "        eType=gdal.GDT_Byte\n",
    "    )\n",
    "    \n",
    "    # 验证尺寸\n",
    "    if data.shape != (1800, 3600):\n",
    "        print(f\"警告: 数据形状异常 {data.shape} (期望 1800x3600)\")\n",
    "    \n",
    "    # 设置地理变换 (WGS84坐标，分辨率0.1度)\n",
    "    geotransform = (-180.0, 0.1, 0.0, 90.0, 0.0, -0.1)\n",
    "    out_ds.SetGeoTransform(geotransform)\n",
    "    \n",
    "    # 设置坐标系\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)  # WGS84坐标系\n",
    "    out_ds.SetProjection(srs.ExportToWkt())\n",
    "    \n",
    "    # 写入数据\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(data)\n",
    "    \n",
    "    # 设置元数据\n",
    "    out_band.SetDescription('Dominant_Land_Cover')\n",
    "    out_ds.SetMetadata({\n",
    "        'DATA_TYPE': 'Dominant land cover index',\n",
    "        'INDEX_VALUES': '0=water,1=bare,2=snowice,3=built,4=grassman,5=grassnat,'\n",
    "                       '6=shrubbd,7=shrubbe,8=shrubnd,9=shrubne,10=treebd,'\n",
    "                       '11=treebe,12=treend,13=treene'\n",
    "    })\n",
    "    \n",
    "    # 清理资源\n",
    "    out_band.FlushCache()\n",
    "    out_band = None\n",
    "    out_ds = None\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"开始处理: {MAT_FILE}\")\n",
    "    result = process_pft_data()\n",
    "    print(result)\n",
    "    print(\"处理完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8337c8-4834-49ec-9408-8e7e561e410b",
   "metadata": {},
   "source": [
    "地面数据集和验证集能否对上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7813ff5-3481-4168-b1cd-9df10eb4c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对齐地面验证数据集和LFMC数据集...\n",
      "在SMEX02中没有找到匹配项\n",
      "在CLASIC07中没有找到匹配项\n",
      "在SMAPVEX08中没有找到匹配项\n",
      "在SMAPVEX16中没有找到匹配项\n",
      "在所有数据集中都没有找到匹配项\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def align_insitu_data():\n",
    "    # 定义文件路径\n",
    "    insitu_file = r'E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx'\n",
    "    lfmc_file = r'E:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx'\n",
    "    output_file = r'E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\Insitu_VWC_align.xlsx'\n",
    "\n",
    "    # 读取LFMC数据集 - 不使用sheet名称\n",
    "    lfmc_df = pd.read_excel(lfmc_file)  # 默认读取第一个工作表\n",
    "    \n",
    "    # 检查LFMC数据是否包含四个地面验证数据集的信息\n",
    "    lfmc_has_insitu_data = False\n",
    "    for col in lfmc_df.columns:\n",
    "        if 'Dataset' in col or any(ds in col for ds in ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']):\n",
    "            lfmc_has_insitu_data = True\n",
    "            break\n",
    "    \n",
    "    # 重命名LFMC列以匹配地面验证数据集\n",
    "    lfmc_df = lfmc_df.rename(columns={\n",
    "        'RowVOD': 'row',\n",
    "        'ColVOD': 'col',\n",
    "        'SamplingDate': 'Date'\n",
    "    })\n",
    "    \n",
    "    # 确保Date列是datetime类型\n",
    "    lfmc_df['Date'] = pd.to_datetime(lfmc_df['Date']).dt.date\n",
    "    \n",
    "    # 创建一个空的DataFrame来存储对齐结果\n",
    "    aligned_results = []\n",
    "\n",
    "    # 定义要处理的数据集列表\n",
    "    datasets = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "    \n",
    "    # 处理每个地面验证数据集\n",
    "    for dataset in datasets:\n",
    "        # 读取数据集\n",
    "        df = pd.read_excel(insitu_file, sheet_name=dataset)\n",
    "        \n",
    "        # 确保Date列是datetime类型\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "        \n",
    "        # 如果LFMC数据已经包含地面验证数据，直接提取\n",
    "        if lfmc_has_insitu_data:\n",
    "            # 提取该数据集的数据\n",
    "            dataset_df = lfmc_df[lfmc_df['Dataset'] == dataset].copy()\n",
    "            if not dataset_df.empty:\n",
    "                aligned_results.append(dataset_df)\n",
    "                print(f\"从LFMC数据中提取了{len(dataset_df)}个{dataset}匹配项\")\n",
    "            else:\n",
    "                print(f\"LFMC数据中没有{dataset}的匹配项\")\n",
    "        else:\n",
    "            # 创建匹配的键值\n",
    "            df['match_key'] = df.apply(lambda x: f\"{x['row']}-{x['col']}-{x['Date']}\", axis=1)\n",
    "            \n",
    "            # 在LFMC数据集中寻找匹配项\n",
    "            matched_df = pd.merge(\n",
    "                df, \n",
    "                lfmc_df,\n",
    "                on=['row', 'col', 'Date'],\n",
    "                how='inner',\n",
    "                suffixes=('', '_LFMC')\n",
    "            )\n",
    "            \n",
    "            if not matched_df.empty:\n",
    "                # 添加数据集来源标识\n",
    "                matched_df['Dataset'] = dataset\n",
    "                aligned_results.append(matched_df)\n",
    "                \n",
    "                # 打印匹配统计\n",
    "                print(f\"在{dataset}中找到了{len(matched_df)}个匹配项\")\n",
    "            else:\n",
    "                print(f\"在{dataset}中没有找到匹配项\")\n",
    "    \n",
    "    # 合并所有匹配结果\n",
    "    if aligned_results:\n",
    "        final_df = pd.concat(aligned_results, ignore_index=True)\n",
    "        \n",
    "        # 保存对齐结果\n",
    "        with pd.ExcelWriter(output_file) as writer:\n",
    "            final_df.to_excel(writer, sheet_name='Aligned_Data', index=False)\n",
    "        \n",
    "        # 添加摘要信息\n",
    "        summary = {\n",
    "            \"总匹配项数\": len(final_df),\n",
    "            \"数据集分布\": final_df['Dataset'].value_counts().to_dict(),\n",
    "            \"日期范围\": f\"{final_df['Date'].min().strftime('%Y-%m-%d')} - {final_df['Date'].max().strftime('%Y-%m-%d')}\",\n",
    "            \"数据来源\": \"LFMC数据已包含匹配项\" if lfmc_has_insitu_data else \"通过匹配生成\"\n",
    "        }\n",
    "        \n",
    "        # 添加唯一位置计数\n",
    "        unique_locations = final_df.groupby(['row', 'col']).size().reset_index(name='访问次数')\n",
    "        unique_locations['坐标'] = unique_locations.apply(lambda x: f\"({x['row']}, {x['col']})\", axis=1)\n",
    "        \n",
    "        # 保存统计信息\n",
    "        with pd.ExcelWriter(output_file, mode='a') as writer:\n",
    "            pd.DataFrame.from_dict([summary]).to_excel(\n",
    "                writer, sheet_name='Summary', index=False\n",
    "            )\n",
    "            unique_locations.to_excel(\n",
    "                writer, sheet_name='Unique_Locations', index=False\n",
    "            )\n",
    "        \n",
    "        print(f\"成功保存对齐数据到: {output_file}\")\n",
    "        print(f\"总匹配项数: {len(final_df)}\")\n",
    "        print(f\"数据集分布: {summary['数据集分布']}\")\n",
    "        print(f\"日期范围: {summary['日期范围']}\")\n",
    "        print(f\"数据来源: {summary['数据来源']}\")\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"在所有数据集中都没有找到匹配项\")\n",
    "        return None\n",
    "\n",
    "# 执行对齐操作\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"开始对齐地面验证数据集和LFMC数据集...\")\n",
    "    aligned_data = align_insitu_data()\n",
    "    \n",
    "    if aligned_data is not None:\n",
    "        print(\"处理完成！对齐数据已保存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744565cd-1d67-48c7-9c2f-fe7f73fc07ea",
   "metadata": {},
   "source": [
    "制作VOD与VWC的相关性图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a42978e-05fd-4bae-9992-5aa06fc9f332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理2015-2016年VWC与VOD相关性分析...\n",
      "成功加载主地物类型掩膜\n",
      "掩膜尺寸: 1800x3600\n",
      "共发现 92 个时间节点\n",
      "\n",
      "处理时间节点 1/92: 2015-01-01\n",
      "成功掩膜处理: VWC-20150101.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 2/92: 2015-01-09\n",
      "成功掩膜处理: VWC-20150109.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 3/92: 2015-01-17\n",
      "成功掩膜处理: VWC-20150117.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 4/92: 2015-01-25\n",
      "成功掩膜处理: VWC-20150125.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 5/92: 2015-02-02\n",
      "成功掩膜处理: VWC-20150202.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 6/92: 2015-02-10\n",
      "成功掩膜处理: VWC-20150210.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 7/92: 2015-02-18\n",
      "成功掩膜处理: VWC-20150218.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 8/92: 2015-02-26\n",
      "成功掩膜处理: VWC-20150226.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 9/92: 2015-03-06\n",
      "成功掩膜处理: VWC-20150306.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 10/92: 2015-03-14\n",
      "成功掩膜处理: VWC-20150314.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 11/92: 2015-03-22\n",
      "成功掩膜处理: VWC-20150322.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 12/92: 2015-03-30\n",
      "成功掩膜处理: VWC-20150330.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 13/92: 2015-04-07\n",
      "成功掩膜处理: VWC-20150407.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 14/92: 2015-04-15\n",
      "成功掩膜处理: VWC-20150415.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 15/92: 2015-04-23\n",
      "成功掩膜处理: VWC-20150423.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 16/92: 2015-05-01\n",
      "成功掩膜处理: VWC-20150501.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 17/92: 2015-05-09\n",
      "成功掩膜处理: VWC-20150509.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 18/92: 2015-05-17\n",
      "成功掩膜处理: VWC-20150517.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 19/92: 2015-05-25\n",
      "成功掩膜处理: VWC-20150525.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 20/92: 2015-06-02\n",
      "成功掩膜处理: VWC-20150602.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 21/92: 2015-06-10\n",
      "成功掩膜处理: VWC-20150610.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 22/92: 2015-06-18\n",
      "成功掩膜处理: VWC-20150618.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 23/92: 2015-06-26\n",
      "成功掩膜处理: VWC-20150626.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 24/92: 2015-07-04\n",
      "成功掩膜处理: VWC-20150704.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 25/92: 2015-07-12\n",
      "成功掩膜处理: VWC-20150712.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 26/92: 2015-07-20\n",
      "成功掩膜处理: VWC-20150720.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 27/92: 2015-07-28\n",
      "成功掩膜处理: VWC-20150728.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 28/92: 2015-08-05\n",
      "成功掩膜处理: VWC-20150805.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 29/92: 2015-08-13\n",
      "成功掩膜处理: VWC-20150813.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 30/92: 2015-08-21\n",
      "成功掩膜处理: VWC-20150821.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 31/92: 2015-08-29\n",
      "成功掩膜处理: VWC-20150829.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 32/92: 2015-09-06\n",
      "成功掩膜处理: VWC-20150906.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 33/92: 2015-09-14\n",
      "成功掩膜处理: VWC-20150914.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 34/92: 2015-09-22\n",
      "成功掩膜处理: VWC-20150922.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 35/92: 2015-09-30\n",
      "成功掩膜处理: VWC-20150930.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 36/92: 2015-10-08\n",
      "成功掩膜处理: VWC-20151008.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 37/92: 2015-10-16\n",
      "成功掩膜处理: VWC-20151016.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 38/92: 2015-10-24\n",
      "成功掩膜处理: VWC-20151024.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 39/92: 2015-11-01\n",
      "成功掩膜处理: VWC-20151101.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 40/92: 2015-11-09\n",
      "成功掩膜处理: VWC-20151109.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 41/92: 2015-11-17\n",
      "成功掩膜处理: VWC-20151117.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 42/92: 2015-11-25\n",
      "成功掩膜处理: VWC-20151125.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 43/92: 2015-12-03\n",
      "成功掩膜处理: VWC-20151203.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 44/92: 2015-12-11\n",
      "成功掩膜处理: VWC-20151211.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 45/92: 2015-12-19\n",
      "成功掩膜处理: VWC-20151219.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 46/92: 2015-12-27\n",
      "成功掩膜处理: VWC-20151227.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 47/92: 2016-01-01\n",
      "成功掩膜处理: VWC-20160101.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 48/92: 2016-01-09\n",
      "成功掩膜处理: VWC-20160109.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 49/92: 2016-01-17\n",
      "成功掩膜处理: VWC-20160117.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 50/92: 2016-01-25\n",
      "成功掩膜处理: VWC-20160125.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 51/92: 2016-02-02\n",
      "成功掩膜处理: VWC-20160202.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 52/92: 2016-02-10\n",
      "成功掩膜处理: VWC-20160210.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 53/92: 2016-02-18\n",
      "成功掩膜处理: VWC-20160218.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 54/92: 2016-02-26\n",
      "成功掩膜处理: VWC-20160226.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 55/92: 2016-03-05\n",
      "成功掩膜处理: VWC-20160305.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 56/92: 2016-03-13\n",
      "成功掩膜处理: VWC-20160313.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 57/92: 2016-03-21\n",
      "成功掩膜处理: VWC-20160321.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 58/92: 2016-03-29\n",
      "成功掩膜处理: VWC-20160329.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 59/92: 2016-04-06\n",
      "成功掩膜处理: VWC-20160406.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 60/92: 2016-04-14\n",
      "成功掩膜处理: VWC-20160414.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 61/92: 2016-04-22\n",
      "成功掩膜处理: VWC-20160422.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 62/92: 2016-04-30\n",
      "成功掩膜处理: VWC-20160430.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 63/92: 2016-05-08\n",
      "成功掩膜处理: VWC-20160508.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 64/92: 2016-05-16\n",
      "成功掩膜处理: VWC-20160516.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 65/92: 2016-05-24\n",
      "成功掩膜处理: VWC-20160524.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 66/92: 2016-06-01\n",
      "成功掩膜处理: VWC-20160601.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 67/92: 2016-06-09\n",
      "成功掩膜处理: VWC-20160609.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 68/92: 2016-06-17\n",
      "成功掩膜处理: VWC-20160617.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 69/92: 2016-06-25\n",
      "成功掩膜处理: VWC-20160625.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 70/92: 2016-07-03\n",
      "成功掩膜处理: VWC-20160703.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 71/92: 2016-07-11\n",
      "成功掩膜处理: VWC-20160711.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 72/92: 2016-07-19\n",
      "成功掩膜处理: VWC-20160719.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 73/92: 2016-07-27\n",
      "成功掩膜处理: VWC-20160727.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 74/92: 2016-08-04\n",
      "成功掩膜处理: VWC-20160804.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 75/92: 2016-08-12\n",
      "成功掩膜处理: VWC-20160812.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 76/92: 2016-08-20\n",
      "成功掩膜处理: VWC-20160820.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 77/92: 2016-08-28\n",
      "成功掩膜处理: VWC-20160828.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 78/92: 2016-09-05\n",
      "成功掩膜处理: VWC-20160905.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 79/92: 2016-09-13\n",
      "成功掩膜处理: VWC-20160913.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 80/92: 2016-09-21\n",
      "成功掩膜处理: VWC-20160921.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 81/92: 2016-09-29\n",
      "成功掩膜处理: VWC-20160929.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 82/92: 2016-10-07\n",
      "成功掩膜处理: VWC-20161007.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 83/92: 2016-10-15\n",
      "成功掩膜处理: VWC-20161015.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 84/92: 2016-10-23\n",
      "成功掩膜处理: VWC-20161023.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 85/92: 2016-10-31\n",
      "成功掩膜处理: VWC-20161031.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 86/92: 2016-11-08\n",
      "成功掩膜处理: VWC-20161108.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 87/92: 2016-11-16\n",
      "成功掩膜处理: VWC-20161116.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 88/92: 2016-11-24\n",
      "成功掩膜处理: VWC-20161124.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 89/92: 2016-12-02\n",
      "成功掩膜处理: VWC-20161202.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 90/92: 2016-12-10\n",
      "成功掩膜处理: VWC-20161210.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 91/92: 2016-12-18\n",
      "成功掩膜处理: VWC-20161218.tif\n",
      "  成功添加数据\n",
      "\n",
      "处理时间节点 92/92: 2016-12-26\n",
      "成功掩膜处理: VWC-20161226.tif\n",
      "  成功添加数据\n",
      "开始计算基于92个时间节点的相关系数...\n",
      "相关系数结果已保存至: E:/文章/HUITU/Fig/Corr_KuH_Masked.tif\n",
      "\n",
      "处理完成! 结果统计:\n",
      "总像素数: 6480000\n",
      "有效像素数: 1064088 (16.42%)\n",
      "平均相关系数: 0.5275\n",
      "相关系数范围: [-1.0000, 1.0000]\n",
      "输出文件: E:/文章/HUITU/Fig/Corr_KuH_Masked.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, osr\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================================\n",
    "# 配置参数\n",
    "# ==========================================================\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2016\n",
    "VWC_DIR = \"E:/data/VWC/VWCMap/8Day\"\n",
    "VOD_DIR = \"E:/data/VOD/mat/kuxcVOD/ASC\"\n",
    "OUTPUT_PATH = \"E:/文章/HUITU/Fig/Corr_KuH_Masked.tif\"  # 更新输出文件名表示已应用掩膜\n",
    "\n",
    "# 添加掩膜配置参数\n",
    "MAIN_TYPE_FILE = r'E:\\data\\ESACCI PFT\\Resample\\Data\\mainType.tif'\n",
    "MASK_TYPES = [0, 1, 2]  # 0=water, 1=bare, 2=snowice\n",
    "NODATA_VALUE = -9999.0\n",
    "\n",
    "# ==========================================================\n",
    "# 掩膜处理函数\n",
    "# ==========================================================\n",
    "def load_main_type_mask():\n",
    "    \"\"\"加载主地物类型掩膜（含空间参考校验）\"\"\"\n",
    "    try:\n",
    "        ds = gdal.Open(MAIN_TYPE_FILE, gdal.GA_ReadOnly)\n",
    "        if ds is None:\n",
    "            raise ValueError(f\"无法打开主地物类型文件: {MAIN_TYPE_FILE}\")\n",
    "        \n",
    "        band = ds.GetRasterBand(1)\n",
    "        main_type = band.ReadAsArray()\n",
    "        \n",
    "        # 创建掩膜（需要掩膜的类型为True）\n",
    "        mask = np.isin(main_type, MASK_TYPES)\n",
    "        \n",
    "        # 获取NoData值并处理\n",
    "        nodata = band.GetNoDataValue()\n",
    "        if nodata is not None:\n",
    "            mask = np.logical_and(mask, main_type != nodata)\n",
    "        \n",
    "        # 获取空间参考信息\n",
    "        geotransform = ds.GetGeoTransform()\n",
    "        projection = ds.GetProjection()\n",
    "        ds = None\n",
    "        \n",
    "        print(\"成功加载主地物类型掩膜\")\n",
    "        return mask, geotransform, projection\n",
    "    except Exception as e:\n",
    "        print(f\"加载主地物类型文件失败: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def apply_mask_to_vwc_file(file_path, mask):\n",
    "    \"\"\"对单个VWC文件应用掩膜（仅处理第一个波段）\"\"\"\n",
    "    try:\n",
    "        # 以读写模式打开文件\n",
    "        ds = gdal.Open(file_path, gdal.GA_Update)\n",
    "        if ds is None:\n",
    "            raise ValueError(f\"无法打开VWC文件: {file_path}\")\n",
    "        \n",
    "        # 读取第一个波段\n",
    "        band = ds.GetRasterBand(1)\n",
    "        data = band.ReadAsArray()\n",
    "        \n",
    "        # 应用掩膜\n",
    "        data[mask] = NODATA_VALUE\n",
    "        \n",
    "        # 写回数据并设置NoData属性\n",
    "        band.WriteArray(data)\n",
    "        band.SetNoDataValue(NODATA_VALUE)\n",
    "        \n",
    "        # 强制写入磁盘\n",
    "        ds.FlushCache()\n",
    "        ds = None\n",
    "        \n",
    "        print(f\"成功掩膜处理: {os.path.basename(file_path)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"掩膜处理失败: {os.path.basename(file_path)}，错误: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# ==========================================================\n",
    "# 辅助函数：获取每年独立的时间节点（保持不变）\n",
    "# ==========================================================\n",
    "def get_yearly_time_nodes(year):\n",
    "    \"\"\"获取单一年份的独立8日时间节点\"\"\"\n",
    "    dates = []\n",
    "    start_date = pd.Timestamp(f\"{year}-01-01\")\n",
    "    \n",
    "    # 全年46个周期（MODIS标准）\n",
    "    for i in range(0, 46 * 8, 8):\n",
    "        current_date = start_date + pd.Timedelta(days=i)\n",
    "        dates.append(current_date)\n",
    "    return dates\n",
    "\n",
    "def get_all_time_nodes():\n",
    "    \"\"\"获取所有年份的独立时间节点\"\"\"\n",
    "    all_dates = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        all_dates.extend(get_yearly_time_nodes(year))\n",
    "    return all_dates\n",
    "\n",
    "# ==========================================================\n",
    "# VWC数据处理函数（添加掩膜处理）\n",
    "# ==========================================================\n",
    "def process_vwc(date, mask=None, geotransform=None, projection=None):\n",
    "    \"\"\"处理单个时间节点的VWC数据\"\"\"\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    vwc_path = os.path.join(VWC_DIR, f\"VWC-{date_str}.tif\")\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(vwc_path):\n",
    "        # 尝试替代命名方案\n",
    "        alt_path = os.path.join(VWC_DIR, f\"VWC_{date_str}.tif\")\n",
    "        if os.path.exists(alt_path):\n",
    "            vwc_path = alt_path\n",
    "        else:\n",
    "            print(f\"  VWC数据缺失: {date.strftime('%Y%m%d')}\")\n",
    "            return None, geotransform, projection\n",
    "    \n",
    "    # 在计算前应用掩膜\n",
    "    if mask is not None:\n",
    "        apply_mask_to_vwc_file(vwc_path, mask)\n",
    "    \n",
    "    try:\n",
    "        ds = gdal.Open(vwc_path)\n",
    "        if ds is None:\n",
    "            print(f\"  无法打开文件: {vwc_path}\")\n",
    "            return None, geotransform, projection\n",
    "        \n",
    "        # 获取地理信息\n",
    "        current_geotransform = ds.GetGeoTransform()\n",
    "        current_projection = ds.GetProjection()\n",
    "        \n",
    "        # 优先使用已有的地理信息\n",
    "        if geotransform is None:\n",
    "            geotransform = current_geotransform\n",
    "        if projection is None:\n",
    "            projection = current_projection\n",
    "        \n",
    "        # 读取第一个波段(KuH)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        vwc_data = band.ReadAsArray()\n",
    "        vwc_data = vwc_data.astype(np.float32)\n",
    "        \n",
    "        # 处理无效值\n",
    "        vwc_data[vwc_data == NODATA_VALUE] = np.nan\n",
    "        \n",
    "        ds = None\n",
    "        return vwc_data, geotransform, projection\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  处理VWC文件出错: {vwc_path} - {str(e)}\")\n",
    "        return None, geotransform, projection\n",
    "\n",
    "# ==========================================================\n",
    "# VOD数据处理函数（保持不变）\n",
    "# ==========================================================\n",
    "def process_vod_period(start_date, end_date):\n",
    "    \"\"\"处理8天周期的VOD数据（允许跨年）\"\"\"\n",
    "    # 计算实际日期范围（可能跨年）\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    \n",
    "    vod_sum = None\n",
    "    valid_count = None\n",
    "    \n",
    "    # 处理周期内每一天\n",
    "    for single_date in date_range:\n",
    "        date_str = single_date.strftime('%Y%m%d')\n",
    "        vod_path = os.path.join(VOD_DIR, f\"MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "        \n",
    "        if not os.path.exists(vod_path):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # 使用h5py读取v7.3格式的MAT文件\n",
    "            with h5py.File(vod_path, 'r') as f:\n",
    "                # 获取变量并转置\n",
    "                vod = f['ku_vod_H'][()].T\n",
    "                qc = f['QC'][()].T\n",
    "                \n",
    "            # 初始化累加器\n",
    "            if vod_sum is None:\n",
    "                vod_sum = np.zeros_like(vod, dtype=np.float32)\n",
    "                valid_count = np.zeros_like(vod, dtype=np.int32)\n",
    "            \n",
    "            # 应用质量控制\n",
    "            valid_mask = (qc == 0)\n",
    "            vod[~valid_mask] = np.nan\n",
    "            \n",
    "            # 累加有效值\n",
    "            valid_vod_mask = ~np.isnan(vod)\n",
    "            np.add(vod_sum, vod, out=vod_sum, where=valid_vod_mask)\n",
    "            np.add(valid_count, valid_vod_mask, out=valid_count)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理VOD文件出错: {vod_path} - {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 计算周期平均值\n",
    "    if vod_sum is not None and valid_count is not None:\n",
    "        vod_avg = np.divide(vod_sum, valid_count, \n",
    "                           out=np.full_like(vod_sum, np.nan),\n",
    "                           where=(valid_count > 0))\n",
    "        return vod_avg\n",
    "    return None\n",
    "\n",
    "# ==========================================================\n",
    "# 相关系数计算函数（优化性能）\n",
    "# ==========================================================\n",
    "def calculate_correlation(vwc_series, vod_series):\n",
    "    \"\"\"计算每个像素的相关系数（向量化优化版本）\"\"\"\n",
    "    # 转换为三维数组\n",
    "    vwc_stack = np.stack(vwc_series, axis=0)\n",
    "    vod_stack = np.stack(vod_series, axis=0)\n",
    "    \n",
    "    # 初始化相关系数数组\n",
    "    correlation = np.full(vwc_stack.shape[1:], np.nan, dtype=np.float32)\n",
    "    \n",
    "    # 计算均值\n",
    "    vwc_mean = np.nanmean(vwc_stack, axis=0)\n",
    "    vod_mean = np.nanmean(vod_stack, axis=0)\n",
    "    \n",
    "    # 计算相关系数分量\n",
    "    numerator = np.nansum(\n",
    "        (vwc_stack - vwc_mean[np.newaxis, :, :]) * \n",
    "        (vod_stack - vod_mean[np.newaxis, :, :]), \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    vwc_std = np.sqrt(np.nansum(\n",
    "        (vwc_stack - vwc_mean[np.newaxis, :, :]) ** 2, \n",
    "        axis=0\n",
    "    ))\n",
    "    \n",
    "    vod_std = np.sqrt(np.nansum(\n",
    "        (vod_stack - vod_mean[np.newaxis, :, :]) ** 2, \n",
    "        axis=0\n",
    "    ))\n",
    "    \n",
    "    denominator = vwc_std * vod_std\n",
    "    \n",
    "    # 计算相关系数，避免除以零\n",
    "    valid_mask = (denominator > 0) & (~np.isnan(denominator))\n",
    "    correlation[valid_mask] = numerator[valid_mask] / denominator[valid_mask]\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "# ==========================================================\n",
    "# 结果保存函数（保持不变）\n",
    "# ==========================================================\n",
    "def save_correlation(correlation, geotransform, projection):\n",
    "    \"\"\"保存相关系数为GeoTIFF\"\"\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_ds = driver.Create(OUTPUT_PATH, correlation.shape[1], correlation.shape[0], 1, gdal.GDT_Float32)\n",
    "    \n",
    "    out_ds.SetGeoTransform(geotransform)\n",
    "    out_ds.SetProjection(projection)\n",
    "    \n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(correlation)\n",
    "    out_band.SetNoDataValue(np.nan)\n",
    "    \n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(projection)\n",
    "    out_ds.SetProjection(srs.ExportToWkt())\n",
    "    \n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "    print(f\"相关系数结果已保存至: {OUTPUT_PATH}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 主处理函数（添加掩膜处理）\n",
    "# ==========================================================\n",
    "def main():\n",
    "    print(f\"开始处理{START_YEAR}-{END_YEAR}年VWC与VOD相关性分析...\")\n",
    "    \n",
    "    # 加载主地物类型掩膜\n",
    "    mask, ref_geotransform, ref_projection = load_main_type_mask()\n",
    "    if mask is None:\n",
    "        print(\"错误：无法加载主掩膜，程序终止\")\n",
    "        return\n",
    "    \n",
    "    print(f\"掩膜尺寸: {mask.shape[0]}x{mask.shape[1]}\")\n",
    "    \n",
    "    # 获取所有独立年度时间节点\n",
    "    time_nodes = get_all_time_nodes()\n",
    "    print(f\"共发现 {len(time_nodes)} 个时间节点\")\n",
    "    \n",
    "    # 存储结果\n",
    "    vwc_series = []\n",
    "    vod_series = []\n",
    "    geotransform = None\n",
    "    projection = None\n",
    "    \n",
    "    # 处理每个时间节点\n",
    "    for idx, date in enumerate(time_nodes):\n",
    "        print(f\"\\n处理时间节点 {idx+1}/{len(time_nodes)}: {date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # 处理VWC数据（并应用掩膜）\n",
    "        vwc_data, geotransform, projection = process_vwc(date, mask, geotransform, projection)\n",
    "        \n",
    "        # 计算VOD数据周期（8天，允许跨年）\n",
    "        end_date = date + pd.Timedelta(days=7)\n",
    "        vod_data = process_vod_period(date, end_date)\n",
    "        \n",
    "        # 确保数据有效\n",
    "        if vwc_data is not None and vod_data is not None:\n",
    "            # 验证尺寸一致性\n",
    "            if vwc_data.shape != vod_data.shape:\n",
    "                print(\"  尺寸不匹配，调整VOD数据尺寸\")\n",
    "                vod_data = vod_data[:vwc_data.shape[0], :vwc_data.shape[1]]\n",
    "            \n",
    "            vwc_series.append(vwc_data)\n",
    "            vod_series.append(vod_data)\n",
    "            print(f\"  成功添加数据\")\n",
    "        else:\n",
    "            print(f\"  数据不完整，跳过该时间节点\")\n",
    "    \n",
    "    # 检查数据完整性\n",
    "    if len(vwc_series) < 10:  # 至少需要10个有效时间节点\n",
    "        print(f\"错误: 有效时间节点不足 ({len(vwc_series)}个)，无法计算相关系数\")\n",
    "        return\n",
    "    \n",
    "    print(f\"开始计算基于{len(vwc_series)}个时间节点的相关系数...\")\n",
    "    \n",
    "    # 计算相关系数（使用优化版本）\n",
    "    correlation = calculate_correlation(vwc_series, vod_series)\n",
    "    \n",
    "    # 保存结果\n",
    "    save_correlation(correlation, geotransform, projection)\n",
    "    \n",
    "    # 结果统计\n",
    "    valid_pixels = np.sum(~np.isnan(correlation))\n",
    "    total_pixels = correlation.size\n",
    "    valid_ratio = valid_pixels / total_pixels * 100\n",
    "    \n",
    "    print(\"\\n处理完成! 结果统计:\")\n",
    "    print(f\"总像素数: {total_pixels}\")\n",
    "    print(f\"有效像素数: {valid_pixels} ({valid_ratio:.2f}%)\")\n",
    "    print(f\"平均相关系数: {np.nanmean(correlation):.4f}\")\n",
    "    print(f\"相关系数范围: [{np.nanmin(correlation):.4f}, {np.nanmax(correlation):.4f}]\")\n",
    "    print(f\"输出文件: {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab16b7-4cf2-4fef-aeb5-2d9a77dadbaf",
   "metadata": {},
   "source": [
    "相关性图绘制尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876a20a3-2c3a-4c0e-96a7-462dab23e21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:86: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:86: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:86: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  plt.title('VOD(Ku-Band,H-Pol) ~ VWC$_{\\mathrm{est}}$', fontsize=16, pad=20, fontweight='bold', fontfamily='Arial')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载相关系数数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\project\\Lib\\site-packages\\osgeo\\gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据尺寸: (1800, 3600), 有效像素: 1284659\n",
      "绘制空间分布图...\n",
      "绘制散点密度图...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 23494 (\\N{CJK UNIFIED IDEOGRAPH-5BC6}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 31995 (\\N{CJK UNIFIED IDEOGRAPH-7CFB}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 20013 (\\N{CJK UNIFIED IDEOGRAPH-4E2D}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 31665 (\\N{CJK UNIFIED IDEOGRAPH-7BB1}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:135: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 23494 (\\N{CJK UNIFIED IDEOGRAPH-5BC6}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 31995 (\\N{CJK UNIFIED IDEOGRAPH-7CFB}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 20013 (\\N{CJK UNIFIED IDEOGRAPH-4E2D}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 31665 (\\N{CJK UNIFIED IDEOGRAPH-7BB1}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:139: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from current font.\n",
      "  plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合最终结果...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 31995 (\\N{CJK UNIFIED IDEOGRAPH-7CFB}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 31354 (\\N{CJK UNIFIED IDEOGRAPH-7A7A}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\thy01\\AppData\\Local\\Temp\\ipykernel_9300\\1863744257.py:170: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.\n",
      "  plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成! 结果文件:\n",
      "空间分布图: E:/文章/HUITU/Fig\\VWC_VOD_Correlation_Map_Spatial.png\n",
      "散点密度图: E:/文章/HUITU/Fig\\VWC_VOD_Correlation_Map_Density.png\n",
      "组合结果图: E:/文章/HUITU/Fig\\VWC_VOD_Correlation_Map_Combined.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from osgeo import gdal\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# ==========================================================\n",
    "# 配置参数\n",
    "# ==========================================================\n",
    "CORR_PATH = \"E:/文章/HUITU/Fig/Corr_KuH.tif\"\n",
    "OUTPUT_DIR = \"E:/文章/HUITU/Fig\"\n",
    "OUTPUT_NAME = \"VWC_VOD_Correlation_Map\"\n",
    "\n",
    "# ==========================================================\n",
    "# 数据加载函数\n",
    "# ==========================================================\n",
    "def load_correlation_tif(tif_path):\n",
    "    \"\"\"加载相关系数GeoTIFF文件\"\"\"\n",
    "    ds = gdal.Open(tif_path)\n",
    "    if ds is None:\n",
    "        raise FileNotFoundError(f\"无法打开文件: {tif_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    band = ds.GetRasterBand(1)\n",
    "    correlation = band.ReadAsArray()\n",
    "    \n",
    "    # 获取地理信息\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    \n",
    "    # 计算地理范围\n",
    "    lon_min = geotransform[0]\n",
    "    lon_max = geotransform[0] + geotransform[1] * ds.RasterXSize\n",
    "    lat_max = geotransform[3]\n",
    "    lat_min = geotransform[3] + geotransform[5] * ds.RasterYSize\n",
    "    \n",
    "    ds = None\n",
    "    return correlation, (lon_min, lon_max, lat_min, lat_max), projection\n",
    "\n",
    "# ==========================================================\n",
    "# 空间分布图绘制函数\n",
    "# ==========================================================\n",
    "def plot_spatial_correlation(correlation, extent, projection):\n",
    "    \"\"\"绘制相关系数空间分布图\"\"\"\n",
    "    # 创建地图投影\n",
    "    if \"WGS 84\" in projection or \"EPSG:4326\" in projection:\n",
    "        crs = ccrs.PlateCarree()\n",
    "    else:\n",
    "        crs = ccrs.Mollweide()\n",
    "    \n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=crs)\n",
    "    \n",
    "    # 设置地图范围\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # 添加地理特征\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "    \n",
    "    # 创建自定义颜色映射\n",
    "    colors = [\"blue\", \"white\", \"red\"]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"correlation_cmap\", colors, N=256)\n",
    "    \n",
    "    # 绘制相关系数\n",
    "    im = ax.imshow(correlation, origin='upper', \n",
    "                  extent=extent,\n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  cmap=cmap, vmin=-1, vmax=1)\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation='vertical', pad=0.02, shrink=0.6)\n",
    "    cbar.set_label('Correlation', fontsize=12)\n",
    "    \n",
    "    # 添加标题\n",
    "    plt.title('VOD(Ku-Band,H-Pol) ~ VWC$_{\\mathrm{est}}$', fontsize=16, pad=20, fontweight='bold', fontfamily='Arial')\n",
    "    \n",
    "    # 保存图像\n",
    "    spatial_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Spatial.png\")\n",
    "    plt.savefig(spatial_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return spatial_path\n",
    "\n",
    "# ==========================================================\n",
    "# 散点密度图绘制函数\n",
    "# ==========================================================\n",
    "def plot_density_scatter(correlation):\n",
    "    \"\"\"绘制散点密度图\"\"\"\n",
    "    # 准备数据\n",
    "    valid_corr = correlation[~np.isnan(correlation)]\n",
    "    \n",
    "    # 创建网格布局\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "    \n",
    "    # 主图：散点密度图\n",
    "    ax_main = plt.subplot(gs[0])\n",
    "    \n",
    "    # 创建密度散点图\n",
    "    sns.kdeplot(x=valid_corr, fill=True, color='blue', alpha=0.7, \n",
    "                ax=ax_main, warn_singular=False)\n",
    "    \n",
    "    # 设置坐标轴\n",
    "    ax_main.set_xlim(-1, 1)\n",
    "    ax_main.set_xlabel('Correlation', fontsize=12)\n",
    "    ax_main.set_ylabel('密度', fontsize=12)\n",
    "    ax_main.set_title('相关系数分布密度', fontsize=14)\n",
    "    \n",
    "    # 添加统计信息\n",
    "    mean_val = np.mean(valid_corr)\n",
    "    median_val = np.median(valid_corr)\n",
    "    ax_main.axvline(mean_val, color='red', linestyle='--', label=f'均值: {mean_val:.3f}')\n",
    "    ax_main.axvline(median_val, color='green', linestyle='-.', label=f'中位数: {median_val:.3f}')\n",
    "    ax_main.legend()\n",
    "    \n",
    "    # 副图：箱线图\n",
    "    ax_box = plt.subplot(gs[1])\n",
    "    sns.boxplot(x=valid_corr, ax=ax_box, orient='h', color='lightblue', width=0.6)\n",
    "    ax_box.set_xlim(-1, 1)\n",
    "    ax_box.set_xlabel('相关系数', fontsize=12)\n",
    "    ax_box.set_title('相关系数分布箱线图', fontsize=14)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像\n",
    "    scatter_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Density.png\")\n",
    "    plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return scatter_path\n",
    "\n",
    "# ==========================================================\n",
    "# 组合图绘制函数\n",
    "# ==========================================================\n",
    "def plot_combined_figure(spatial_path, scatter_path):\n",
    "    \"\"\"组合空间分布和散点密度图\"\"\"\n",
    "    # 加载图像\n",
    "    spatial_img = plt.imread(spatial_path)\n",
    "    scatter_img = plt.imread(scatter_path)\n",
    "    \n",
    "    # 创建组合图\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # 添加空间分布图（上部）\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.imshow(spatial_img)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('相关系数空间分布', fontsize=16, pad=10)\n",
    "    \n",
    "    # 添加散点密度图（下部）\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax2.imshow(scatter_img)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Correlation PDF', fontsize=16, pad=10)\n",
    "    \n",
    "    # 保存组合图\n",
    "    combined_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Combined.png\")\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return combined_path\n",
    "\n",
    "# ==========================================================\n",
    "# 主执行函数\n",
    "# ==========================================================\n",
    "def main():\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # 加载相关系数数据\n",
    "    print(\"加载相关系数数据...\")\n",
    "    correlation, extent, projection = load_correlation_tif(CORR_PATH)\n",
    "    print(f\"数据尺寸: {correlation.shape}, 有效像素: {np.sum(~np.isnan(correlation))}\")\n",
    "    \n",
    "    # 绘制空间分布图\n",
    "    print(\"绘制空间分布图...\")\n",
    "    spatial_path = plot_spatial_correlation(correlation, extent, projection)\n",
    "    \n",
    "    # 绘制散点密度图\n",
    "    print(\"绘制散点密度图...\")\n",
    "    scatter_path = plot_density_scatter(correlation)\n",
    "    \n",
    "    # 绘制组合图\n",
    "    print(\"组合最终结果...\")\n",
    "    combined_path = plot_combined_figure(spatial_path, scatter_path)\n",
    "    \n",
    "    print(\"\\n处理完成! 结果文件:\")\n",
    "    print(f\"空间分布图: {spatial_path}\")\n",
    "    print(f\"散点密度图: {scatter_path}\")\n",
    "    print(f\"组合结果图: {combined_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218ccf8-7971-4af6-8b69-17f09eb6d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用掩膜之后的数据\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from osgeo import gdal\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# ==========================================================\n",
    "# 配置参数\n",
    "# ==========================================================\n",
    "CORR_PATH = \"E:/文章/HUITU/Fig/Corr_KuH_Masked.tif\"  # 使用掩膜后的数据\n",
    "OUTPUT_DIR = \"E:/文章/HUITU/Fig\"\n",
    "OUTPUT_NAME = \"VWC_VOD_Correlation_Map\"\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# ==========================================================\n",
    "# 数据加载函数\n",
    "# ==========================================================\n",
    "def load_correlation_tif(tif_path):\n",
    "    \"\"\"加载相关系数GeoTIFF文件\"\"\"\n",
    "    ds = gdal.Open(tif_path)\n",
    "    if ds is None:\n",
    "        raise FileNotFoundError(f\"无法打开文件: {tif_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    band = ds.GetRasterBand(1)\n",
    "    correlation = band.ReadAsArray()\n",
    "    \n",
    "    # 获取地理信息\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    \n",
    "    # 计算地理范围\n",
    "    lon_min = geotransform[0]\n",
    "    lon_max = geotransform[0] + geotransform[1] * ds.RasterXSize\n",
    "    lat_max = geotransform[3]\n",
    "    lat_min = geotransform[3] + geotransform[5] * ds.RasterYSize\n",
    "    \n",
    "    extent = (lon_min, lon_max, lat_min, lat_max)\n",
    "    \n",
    "    ds = None\n",
    "    return correlation, extent, projection\n",
    "\n",
    "# ==========================================================\n",
    "# 空间分布图绘制函数\n",
    "# ==========================================================\n",
    "def plot_spatial_correlation(correlation, extent, projection):\n",
    "    \"\"\"绘制相关系数空间分布图\"\"\"\n",
    "    # 创建地图投影\n",
    "    if \"WGS 84\" in projection or \"EPSG:4326\" in projection:\n",
    "        crs = ccrs.PlateCarree()\n",
    "    else:\n",
    "        crs = ccrs.Mollweide()\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=crs)\n",
    "    \n",
    "    # 设置地图范围\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # 添加地理特征\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "    \n",
    "    # 创建自定义颜色映射\n",
    "    colors = [\"blue\", \"white\", \"red\"]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"correlation_cmap\", colors, N=256)\n",
    "    \n",
    "    # 绘制相关系数\n",
    "    im = ax.imshow(correlation, origin='upper', \n",
    "                  extent=extent,\n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  cmap=cmap, vmin=-1, vmax=1)\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation='vertical', pad=0.02, shrink=0.6)\n",
    "    cbar.set_label('Correlation Coefficient', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 添加标题 - 使用原始字符串避免转义问题\n",
    "    plt.title(r'VOD(Ku-Band, H-Pol) ~ VWC$_{\\mathrm{est}}$', \n",
    "              fontsize=16, pad=20, fontweight='bold', fontfamily='Arial')\n",
    "    \n",
    "    # 保存图像\n",
    "    spatial_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Spatial.png\")\n",
    "    plt.savefig(spatial_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return spatial_path\n",
    "\n",
    "# ==========================================================\n",
    "# 散点密度图绘制函数\n",
    "# ==========================================================\n",
    "def plot_density_scatter(correlation):\n",
    "    \"\"\"绘制散点密度图\"\"\"\n",
    "    # 准备数据\n",
    "    valid_corr = correlation[~np.isnan(correlation)]\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "    \n",
    "    # 主图：散点密度图\n",
    "    ax_main = plt.subplot(gs[0])\n",
    "    \n",
    "    # 创建密度散点图\n",
    "    sns.kdeplot(x=valid_corr, fill=True, color='blue', alpha=0.7, \n",
    "                ax=ax_main, warn_singular=False)\n",
    "    \n",
    "    # 设置坐标轴\n",
    "    ax_main.set_xlim(-1, 1)\n",
    "    ax_main.set_xlabel('Correlation Coefficient', fontsize=12, fontweight='bold')\n",
    "    ax_main.set_ylabel('Density', fontsize=12, fontweight='bold')\n",
    "    ax_main.set_title('Correlation Coefficient Distribution', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 添加统计信息\n",
    "    mean_val = np.mean(valid_corr)\n",
    "    median_val = np.median(valid_corr)\n",
    "    ax_main.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.3f}')\n",
    "    ax_main.axvline(median_val, color='green', linestyle='-.', label=f'Median: {median_val:.3f}')\n",
    "    ax_main.legend(fontsize=10)\n",
    "    \n",
    "    # 副图：箱线图\n",
    "    ax_box = plt.subplot(gs[1])\n",
    "    sns.boxplot(x=valid_corr, ax=ax_box, orient='h', color='lightblue', width=0.6)\n",
    "    ax_box.set_xlim(-1, 1)\n",
    "    ax_box.set_xlabel('Correlation Coefficient', fontsize=12, fontweight='bold')\n",
    "    ax_box.set_title('Boxplot of Correlation Coefficients', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像\n",
    "    scatter_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Density.png\")\n",
    "    plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return scatter_path\n",
    "\n",
    "# ==========================================================\n",
    "# 组合图绘制函数\n",
    "# ==========================================================\n",
    "def plot_combined_figure(spatial_path, scatter_path):\n",
    "    \"\"\"组合空间分布和散点密度图\"\"\"\n",
    "    # 创建组合图\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # 添加空间分布图（上部）\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    spatial_img = plt.imread(spatial_path)\n",
    "    ax1.imshow(spatial_img)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Spatial Distribution of Correlation Coefficients', \n",
    "                 fontsize=16, pad=10, fontweight='bold')\n",
    "    \n",
    "    # 添加散点密度图（下部）\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    scatter_img = plt.imread(scatter_path)\n",
    "    ax2.imshow(scatter_img)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Distribution of Correlation Coefficients', \n",
    "                 fontsize=16, pad=10, fontweight='bold')\n",
    "    \n",
    "    # 保存组合图\n",
    "    combined_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}_Combined.png\")\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return combined_path\n",
    "\n",
    "# ==========================================================\n",
    "# 主执行函数\n",
    "# ==========================================================\n",
    "def main():\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # 加载相关系数数据\n",
    "    print(\"加载相关系数数据...\")\n",
    "    correlation, extent, projection = load_correlation_tif(CORR_PATH)\n",
    "    print(f\"数据尺寸: {correlation.shape}, 有效像素: {np.sum(~np.isnan(correlation))}\")\n",
    "    \n",
    "    # 绘制空间分布图\n",
    "    print(\"绘制空间分布图...\")\n",
    "    spatial_path = plot_spatial_correlation(correlation, extent, projection)\n",
    "    \n",
    "    # 绘制散点密度图\n",
    "    print(\"绘制散点密度图...\")\n",
    "    scatter_path = plot_density_scatter(correlation)\n",
    "    \n",
    "    # 绘制组合图\n",
    "    print(\"组合最终结果...\")\n",
    "    combined_path = plot_combined_figure(spatial_path, scatter_path)\n",
    "    \n",
    "    print(\"\\n处理完成! 结果文件:\")\n",
    "    print(f\"空间分布图: {spatial_path}\")\n",
    "    print(f\"散点密度图: {scatter_path}\")\n",
    "    print(f\"组合结果图: {combined_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1b3bb-a34c-4c62-8333-3b4efc6357f9",
   "metadata": {},
   "source": [
    "1、4、7、10月均值VWC地图绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424bc875-ff12-4ce1-a994-cbe36bb5732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 开始掩膜处理 ========\n",
      "成功加载主地物类型掩膜\n",
      "掩膜尺寸: 1800x3600\n",
      "正在掩膜处理: VWC-201501.tif\n",
      "成功掩膜处理: VWC-201501.tif\n",
      "正在掩膜处理: VWC-201504.tif\n",
      "成功掩膜处理: VWC-201504.tif\n",
      "正在掩膜处理: VWC-201507.tif\n",
      "成功掩膜处理: VWC-201507.tif\n",
      "正在掩膜处理: VWC-201510.tif\n",
      "成功掩膜处理: VWC-201510.tif\n",
      "======== 掩膜处理完成 ========\n",
      "开始读取特定月度VWC数据...\n",
      "读取掩膜后的文件: E:\\data\\VWC\\VWCMap\\Monthly\\VWC-201501.tif\n",
      "读取掩膜后的文件: E:\\data\\VWC\\VWCMap\\Monthly\\VWC-201504.tif\n",
      "读取掩膜后的文件: E:\\data\\VWC\\VWCMap\\Monthly\\VWC-201507.tif\n",
      "读取掩膜后的文件: E:\\data\\VWC\\VWCMap\\Monthly\\VWC-201510.tif\n",
      "结果已保存至: E:\\文章\\HUITU\\Fig\\Global_VWC_KuH_Seasonal_2015_Custom.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from osgeo import gdal, osr\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib as mpl\n",
    "import logging\n",
    "\n",
    "# ==========================================================\n",
    "# 配置参数\n",
    "# ==========================================================\n",
    "VWC_DIR = r\"E:\\data\\VWC\\VWCMap\\Monthly\"\n",
    "SPECIFIC_MONTHS = {\n",
    "    \"2015-01\": \"201501\",\n",
    "    \"2015-04\": \"201504\",\n",
    "    \"2015-07\": \"201507\",\n",
    "    \"2015-10\": \"201510\"\n",
    "}\n",
    "BAND = 1  # 读取第一个波段(KuH)\n",
    "OUTPUT_DIR = r\"E:\\文章\\HUITU\\Fig\"\n",
    "OUTPUT_NAME = \"Global_VWC_KuH_Seasonal_2015_Custom\"\n",
    "\n",
    "# 掩膜相关参数\n",
    "MAIN_TYPE_FILE = r'E:\\data\\ESACCI PFT\\Resample\\Data\\mainType.tif'\n",
    "MASK_TYPES = [0, 1, 2]  # 0=water, 1=bare, 2=snowice\n",
    "NODATA_VALUE = -9999.0\n",
    "\n",
    "# ==========================================================\n",
    "# 掩膜处理函数（使用修复后的方法）\n",
    "# ==========================================================\n",
    "def load_main_type_mask():\n",
    "    \"\"\"加载主地物类型掩膜（含空间参考校验）\"\"\"\n",
    "    try:\n",
    "        ds = gdal.Open(MAIN_TYPE_FILE, gdal.GA_ReadOnly)\n",
    "        if ds is None:\n",
    "            raise ValueError(f\"无法打开主地物类型文件: {MAIN_TYPE_FILE}\")\n",
    "        \n",
    "        band = ds.GetRasterBand(1)\n",
    "        main_type = band.ReadAsArray()\n",
    "        \n",
    "        # 创建掩膜（需要掩膜的类型为True）\n",
    "        mask = np.isin(main_type, MASK_TYPES)\n",
    "        \n",
    "        # 获取NoData值并处理\n",
    "        nodata = band.GetNoDataValue()\n",
    "        if nodata is not None:\n",
    "            mask = np.logical_and(mask, main_type != nodata)\n",
    "        \n",
    "        # 获取空间参考信息\n",
    "        geotransform = ds.GetGeoTransform()\n",
    "        projection = ds.GetProjection()\n",
    "        ds = None\n",
    "        \n",
    "        print(\"成功加载主地物类型掩膜\")\n",
    "        return mask, geotransform, projection\n",
    "    except Exception as e:\n",
    "        print(f\"加载主地物类型文件失败: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def apply_mask_to_vwc_file(file_path, mask, ref_geotransform, ref_projection):\n",
    "    \"\"\"对单个VWC文件应用掩膜（仅处理第一个波段）\"\"\"\n",
    "    try:\n",
    "        print(f\"正在掩膜处理: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # 以读写模式打开文件\n",
    "        ds = gdal.Open(file_path, gdal.GA_Update)\n",
    "        if ds is None:\n",
    "            raise ValueError(f\"无法打开VWC文件: {file_path}\")\n",
    "        \n",
    "        # 验证空间参考是否匹配\n",
    "        if (ds.GetGeoTransform() != ref_geotransform or \n",
    "            ds.GetProjection() != ref_projection):\n",
    "            raise ValueError(\"空间参考不匹配，请确保文件投影一致\")\n",
    "        \n",
    "        # 仅处理第一个波段\n",
    "        band = ds.GetRasterBand(BAND)\n",
    "        data = band.ReadAsArray()\n",
    "        \n",
    "        # 应用掩膜\n",
    "        data[mask] = NODATA_VALUE\n",
    "        \n",
    "        # 写回数据并设置NoData属性\n",
    "        band.WriteArray(data)\n",
    "        band.SetNoDataValue(NODATA_VALUE)\n",
    "        \n",
    "        # 强制写入磁盘\n",
    "        ds.FlushCache()\n",
    "        ds = None\n",
    "        \n",
    "        print(f\"成功掩膜处理: {os.path.basename(file_path)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"掩膜处理失败: {os.path.basename(file_path)}，错误: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# ==========================================================\n",
    "# 数据读取函数（保持不变）\n",
    "# ==========================================================\n",
    "def read_vwc_tif(file_path, band=1, no_data=-9999):\n",
    "    \"\"\"读取VWC TIFF文件并处理无效值\"\"\"\n",
    "    ds = gdal.Open(file_path)\n",
    "    if ds is None:\n",
    "        raise FileNotFoundError(f\"Cannot open file: {file_path}\")\n",
    "    \n",
    "    # 读取指定波段\n",
    "    band = ds.GetRasterBand(band)\n",
    "    data = band.ReadAsArray()\n",
    "    \n",
    "    # 获取地理信息\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    \n",
    "    # 计算地理范围\n",
    "    x_size = ds.RasterXSize\n",
    "    y_size = ds.RasterYSize\n",
    "    lon_min = geotransform[0]\n",
    "    lat_max = geotransform[3]\n",
    "    lon_max = lon_min + geotransform[1] * x_size\n",
    "    lat_min = lat_max + geotransform[5] * y_size\n",
    "    \n",
    "    # 处理无效值\n",
    "    data = data.astype(np.float32)\n",
    "    data[data == no_data] = np.nan\n",
    "    \n",
    "    ds = None\n",
    "    return data, (lon_min, lon_max, lat_min, lat_max), projection\n",
    "\n",
    "# ==========================================================\n",
    "# 创建自定义颜色映射（保持不变）\n",
    "# ==========================================================\n",
    "def create_custom_cmap():\n",
    "    \"\"\"创建自定义颜色映射\"\"\"\n",
    "    # 使用指定的五种颜色\n",
    "    colors = [\n",
    "        '#fe3c19',  # 0 kg/m²\n",
    "        '#ffac18',  # 5 kg/m²\n",
    "        '#f2fe2a',  # 10 kg/m²\n",
    "        '#7cb815',  # 15 kg/m²\n",
    "        '#147218'   # 20 kg/m²\n",
    "    ]\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    cmap = LinearSegmentedColormap.from_list('custom_vwc', colors, N=256)\n",
    "    return cmap\n",
    "\n",
    "# ==========================================================\n",
    "# 地图绘制函数（保持不变）\n",
    "# ==========================================================\n",
    "def plot_vwc_map(ax, data, extent, month_label, vmin=0, vmax=20):\n",
    "    \"\"\"在指定轴对象上绘制VWC地图\"\"\"\n",
    "    # 创建自定义颜色映射\n",
    "    cmap = create_custom_cmap()\n",
    "    \n",
    "    # 添加地图特征\n",
    "    ax.coastlines(linewidth=0.5, color='gray')\n",
    "    ax.add_feature(NaturalEarthFeature(category='physical', name='ocean', scale='50m', \n",
    "                                      facecolor='lightblue', alpha=0.3))\n",
    "    ax.add_feature(NaturalEarthFeature(category='cultural', name='admin_0_countries', \n",
    "                                      scale='50m', edgecolor='gray', facecolor='none', linewidth=0.3))\n",
    "    \n",
    "    # 添加经纬度网格\n",
    "    gl = ax.gridlines(draw_labels=True, linestyle='--', alpha=0.7)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    \n",
    "    # 绘制VWC数据\n",
    "    im = ax.imshow(data, origin='upper', \n",
    "                  extent=extent,\n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "                  interpolation='nearest')\n",
    "    \n",
    "    # 添加标题 (格式为YYYY-MM)\n",
    "    ax.set_title(f\"{month_label}\", fontsize=12, pad=10)\n",
    "    \n",
    "    return im\n",
    "\n",
    "# ==========================================================\n",
    "# 主执行函数（添加掩膜处理步骤）\n",
    "# ==========================================================\n",
    "def main():\n",
    "    print(\"======== 开始掩膜处理 ========\")\n",
    "    \n",
    "    # 加载主地物类型掩膜\n",
    "    mask, ref_geotransform, ref_projection = load_main_type_mask()\n",
    "    if mask is None:\n",
    "        print(\"错误：无法加载主掩膜，程序终止\")\n",
    "        return\n",
    "    \n",
    "    # 检查掩膜尺寸\n",
    "    print(f\"掩膜尺寸: {mask.shape[0]}x{mask.shape[1]}\")\n",
    "    \n",
    "    # 对SPECIFIC_MONTHS中的每个文件应用掩膜\n",
    "    for label, month_code in SPECIFIC_MONTHS.items():\n",
    "        file_path = os.path.join(VWC_DIR, f\"VWC-{month_code}.tif\")\n",
    "        if os.path.exists(file_path):\n",
    "            apply_mask_to_vwc_file(file_path, mask, ref_geotransform, ref_projection)\n",
    "        else:\n",
    "            print(f\"警告: 文件不存在 - {file_path}\")\n",
    "    \n",
    "    print(\"======== 掩膜处理完成 ========\")\n",
    "    print(\"开始读取特定月度VWC数据...\")\n",
    "    \n",
    "    # 准备存储数据\n",
    "    vwc_data = []\n",
    "    \n",
    "    # 读取已掩膜处理的数据\n",
    "    for label, month_code in SPECIFIC_MONTHS.items():\n",
    "        file_path = os.path.join(VWC_DIR, f\"VWC-{month_code}.tif\")\n",
    "        print(f\"读取掩膜后的文件: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            data, extent, projection = read_vwc_tif(file_path, band=BAND, no_data=NODATA_VALUE)\n",
    "            vwc_data.append({\n",
    "                \"data\": data,\n",
    "                \"extent\": extent,\n",
    "                \"label\": label  # 使用YYYY-MM格式的标签\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"错误读取文件: {file_path}\\n{str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 检查数据完整性\n",
    "    if not vwc_data:\n",
    "        print(\"错误: 无有效数据，无法绘制\")\n",
    "        return\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # 创建2x2网格布局\n",
    "    gs = gridspec.GridSpec(2, 2, figure=fig, \n",
    "                          wspace=0.1, hspace=0.15,\n",
    "                          top=0.95, bottom=0.1,\n",
    "                          left=0.05, right=0.95)\n",
    "    \n",
    "    axs = [\n",
    "        fig.add_subplot(gs[0], projection=ccrs.PlateCarree()),\n",
    "        fig.add_subplot(gs[1], projection=ccrs.PlateCarree()),\n",
    "        fig.add_subplot(gs[2], projection=ccrs.PlateCarree()),\n",
    "        fig.add_subplot(gs[3], projection=ccrs.PlateCarree())\n",
    "    ]\n",
    "    \n",
    "    # 绘制四个季度的地图\n",
    "    images = []\n",
    "    for i in range(4):\n",
    "        if i < len(vwc_data):\n",
    "            ax = axs[i]\n",
    "            data = vwc_data[i]['data']\n",
    "            extent = vwc_data[i]['extent']\n",
    "            label = vwc_data[i]['label']\n",
    "            \n",
    "            # 设置全球视图\n",
    "            ax.set_global()\n",
    "            \n",
    "            # 绘制地图\n",
    "            img = plot_vwc_map(ax, data, extent, label)\n",
    "            images.append(img)\n",
    "    \n",
    "    # 添加共享颜色条\n",
    "    cax = fig.add_axes([0.25, 0.05, 0.5, 0.02])\n",
    "    \n",
    "    # 创建颜色条，使用自定义颜色映射\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=20)\n",
    "    cmap = create_custom_cmap()\n",
    "    \n",
    "    # 创建颜色条标签\n",
    "    ticks = [0, 5, 10, 15, 20]  # 对应五种颜色的位置\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "                     cax=cax, orientation='horizontal',\n",
    "                     ticks=ticks)\n",
    "    cbar.set_label('VWC (kg/m²)', fontsize=11)\n",
    "    \n",
    "    # 添加主标题\n",
    "    plt.suptitle(\"Global VWC Map - 2015\", \n",
    "                 fontsize=14, y=0.98)\n",
    "    \n",
    "    # 保存图像（路径不变）\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_NAME}.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    print(f\"结果已保存至: {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c069b-a99a-4ecc-98c9-6cace2a3a3f0",
   "metadata": {},
   "source": [
    "给原先的训练数据进行处理，填充经纬度情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38828b4-5f16-4062-9405-62ba6120228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取Excel文件: E:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\n",
      "正在覆盖保存文件...\n",
      "处理成功完成！\n",
      "已添加经纬度列并保存到: E:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\n",
      "处理后数据前几行:\n",
      "   RowVOD  ColVOD  Latitude  Longitude\n",
      "0     459     694     44.15    -110.65\n",
      "1     462     695     43.85    -110.55\n",
      "2     463     693     43.75    -110.75\n",
      "3     463     694     43.75    -110.65\n",
      "4     464     693     43.65    -110.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定Excel文件路径\n",
    "excel_path = r\"E:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\"\n",
    "\n",
    "try:\n",
    "    # 读取Excel文件\n",
    "    print(f\"正在读取Excel文件: {excel_path}\")\n",
    "    df = pd.read_excel(excel_path)\n",
    "    \n",
    "    # 检查所需列是否存在\n",
    "    if 'RowVOD' not in df.columns or 'ColVOD' not in df.columns:\n",
    "        missing = []\n",
    "        if 'RowVOD' not in df.columns:\n",
    "            missing.append('RowVOD')\n",
    "        if 'ColVOD' not in df.columns:\n",
    "            missing.append('ColVOD')\n",
    "        raise ValueError(f\"Excel文件中缺少必要的列: {', '.join(missing)}\")\n",
    "    \n",
    "    # 添加经纬度列\n",
    "    # 纬度计算：起始点89.95°N（第1行），每增加一行纬度减少0.1°\n",
    "    df['Latitude'] = 89.95 - (df['RowVOD'] - 1) * 0.1\n",
    "    \n",
    "    # 经度计算：起始点179.95°W（第1列），每增加一列经度增加0.1°\n",
    "    # 注意：179.95°W = -179.95°\n",
    "    df['Longitude'] = -179.95 + (df['ColVOD'] - 1) * 0.1\n",
    "    \n",
    "    # 覆盖保存Excel文件\n",
    "    print(\"正在覆盖保存文件...\")\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(\"处理成功完成！\")\n",
    "    print(f\"已添加经纬度列并保存到: {excel_path}\")\n",
    "    print(f\"处理后数据前几行:\")\n",
    "    print(df[['RowVOD', 'ColVOD', 'Latitude', 'Longitude']].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399c2ba-4181-4db4-81ae-748c7c804745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

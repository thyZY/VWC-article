{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f16288f-0d37-4b52-a549-0a956a7a1335",
   "metadata": {},
   "source": [
    "# 不同极化、波段模型下的实测数据验证模块(均为Insitu数据)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89d686-5496-4824-b81a-7326006c3dba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.SMAPVEX16 Map（Iowa）（数据预处理部分参考matlab的A3_process_SMAPVEX16.m）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c5ea5-1a48-4b5d-b131-065f1a3924b0",
   "metadata": {},
   "source": [
    "matlab中操作步骤：\n",
    "读取E:\\data\\VWC\\test-VWC\\SMAPVEX16_Iowa\\mat中的所有mat文件，即SMAPVEX16数据集内容（不要读取文件夹路径中子文件夹的mat），命名规则为YYYYMMDD.mat，YYYYMMDD为年月日字符串。需要进行填充的变量大小均为1800*3600（按照0.1°格网来的，可以先生成中心经纬度格网数据，数据在matlab存储的为北纬89.95至南纬89.95），根据SMAPVEX16数据集的mat文件的LAT、LON变量得知每个元素对应的经纬度后，提取四个邻近位置的0.1°格网的数据点，根据经纬度的距离差进行双线性插值操作。现需要对原先的数据填充以下变量：\n",
    "\n",
    "①PFT：14个类别，读取文件名为E:\\data\\ESACCI PFT\\Resample\\Data\\YYYY.mat，YYYY就是SMAPVEX对应的年份（这里由于SMAPVEX数据都是2016年的，故你直接读取2016年即可），读取变量：'water','bare','snowice','built','grassnat','grassman','shrubbd','shrubbe','shrubnd','shrubne','treebd','treebe','treend','treene'，先将每个变量每个元素除以100转为比例值，每个变量均按照前面所说的方法进行插值。\n",
    "\n",
    "\n",
    "②VOD：6个类别，读取文件名为E:\\data\\VOD\\mat\\kuxcVOD\\ASC\\MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_YYYYMMDD_V0.nc4.mat的文件，读取变量'VOD_Ku_Hpol_Asc', 'VOD_X_Hpol_Asc', 'VOD_C_Hpol_Asc','VOD_Ku_Vpol_Asc', 'VOD_X_Vpol_Asc', 'VOD_C_Vpol_Asc'，并按照前面所说方法对每个变量进行插值。\n",
    "\n",
    "\n",
    "③LAI：数据为月中数据，涉及逐日插值，所以先读取固定的数据。因为数据跨度为2016年5月28日（使用的插值数据为2016年5月）至2016年8月16日（使用的插值数据为2016年9月的），先读取这5个数据（E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\YYYY-MM-01.tif.mat,YYYY和MM替换成我所说的月和日即可），可以使用这些数据插值出2016年1月16日至2016年9月14日之间的每一天的情况（月中数据不需要插值）。然后根据SMAPVEX数据的内容，读取对应的插值日期数据后，根据经纬度位置再进行插值。\n",
    "\n",
    "\n",
    "④（SM暂时使用数据中已有）Hveg数据，'E:\\data\\CanopyHeight\\CH.mat';根据经纬度位置完成插值处理即可。\n",
    "\n",
    "最后，读取这些插值的数据，分别生成6个掩膜数据：Ku_H_mask、Ku_V_mask、X_H_mask、X_V_mask、C_H_mask、C_V_mask，每个掩膜都读取变量VSM（来自SMAPVEX的mat文件）、前面处理的PFT14个变量和对应的VOD（例如Ku_H_mask就是使用），然后VOD和VSM位置有其一NaN或者PFT的变量'water','bare','snowice','built'加起来的值大于等于0.05，那么这个元素的位置就应该被mask掉，无法用于后续验证。\n",
    "\n",
    "将上述新变量以及掩膜变量覆盖保存至SMAPVEX16的mat文件中\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0724f7fb-a340-402a-8f74-280f8d827719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现以下模型文件:\n",
      "- RFR_C_Hpol_Type1.pkl (波段: C, 极化: H, 类型: 1)\n",
      "跳过模型 RFR_C_Hpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_C_Hpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_C_HVpol_Type1.pkl (波段: C, 极化: HV, 类型: 1)\n",
      "跳过模型 RFR_C_HVpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_C_HVpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_C_Vpol_Type1.pkl (波段: C, 极化: V, 类型: 1)\n",
      "跳过模型 RFR_C_Vpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_C_Vpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_Ku_Hpol_Type1.pkl (波段: Ku, 极化: H, 类型: 1)\n",
      "跳过模型 RFR_Ku_Hpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_Ku_Hpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_Ku_HVpol_Type1.pkl (波段: Ku, 极化: HV, 类型: 1)\n",
      "跳过模型 RFR_Ku_HVpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_Ku_HVpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_Ku_Vpol_Type1.pkl (波段: Ku, 极化: V, 类型: 1)\n",
      "跳过模型 RFR_Ku_Vpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_Ku_Vpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_X_Hpol_Type1.pkl (波段: X, 极化: H, 类型: 1)\n",
      "跳过模型 RFR_X_Hpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_X_Hpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_X_HVpol_Type1.pkl (波段: X, 极化: HV, 类型: 1)\n",
      "跳过模型 RFR_X_HVpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_X_HVpol_Type3.pkl (类型 3 != 1)\n",
      "- RFR_X_Vpol_Type1.pkl (波段: X, 极化: V, 类型: 1)\n",
      "跳过模型 RFR_X_Vpol_Type2.pkl (类型 2 != 1)\n",
      "跳过模型 RFR_X_Vpol_Type3.pkl (类型 3 != 1)\n",
      "\n",
      "找到 12 个MAT文件, 开始处理...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:   0%|                                                                              | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160528.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160528.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160528.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:   8%|█████▊                                                                | 1/12 [00:01<00:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理文件 20160531.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:  33%|███████████████████████▎                                              | 4/12 [00:02<00:03,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160601.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "\n",
      "处理文件 20160601.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n",
      "模型 RFR_C_HVpol_Type1 在文件 20160602.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "\n",
      "处理文件 20160602.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n",
      "模型 RFR_C_HVpol_Type1 在文件 20160603.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160603.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160603.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:  50%|███████████████████████████████████                                   | 6/12 [00:04<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160605.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "\n",
      "处理文件 20160605.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n",
      "\n",
      "处理文件 20160803.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n",
      "\n",
      "处理文件 20160805.mat 时出错: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by RandomForestRegressor. 在文件 965321359.py 的第 187 行\n",
      "模型 RFR_C_HVpol_Type1 在文件 20160806.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160806.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160806.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:  75%|████████████████████████████████████████████████████▌                 | 9/12 [00:05<00:01,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160813.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160813.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160813.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:  83%|█████████████████████████████████████████████████████████▌           | 10/12 [00:07<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160814.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160814.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160814.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件:  92%|███████████████████████████████████████████████████████████████▎     | 11/12 [00:08<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_HVpol_Type1 在文件 20160816.mat 中缺少变量: c_vod_HV, C_HV_mask\n",
      "模型 RFR_Ku_HVpol_Type1 在文件 20160816.mat 中缺少变量: ku_vod_HV, Ku_HV_mask\n",
      "模型 RFR_X_HVpol_Type1 在文件 20160816.mat 中缺少变量: x_vod_HV, X_HV_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理MAT文件: 100%|█████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成, 开始保存结果和绘图...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:   0%|                                                                                  | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 RFR_C_Hpol_Type1 有效点数量: 37043\n",
      "模型 RFR_C_Hpol_Type1 评估指标:\n",
      "  RMSE = 2.9634\n",
      "  Bias = 2.8039\n",
      "保存PNG结果: RFR_C_Hpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:  11%|████████▏                                                                 | 1/9 [00:03<00:26,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_C_Hpol_Type1_scatter.pdf\n",
      "模型 RFR_C_HVpol_Type1 没有预测数据，跳过\n",
      "模型 RFR_C_Vpol_Type1 有效点数量: 6857\n",
      "模型 RFR_C_Vpol_Type1 评估指标:\n",
      "  RMSE = 2.7479\n",
      "  Bias = 2.5967\n",
      "保存PNG结果: RFR_C_Vpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:  33%|████████████████████████▋                                                 | 3/9 [00:04<00:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_C_Vpol_Type1_scatter.pdf\n",
      "模型 RFR_Ku_Hpol_Type1 有效点数量: 26135\n",
      "模型 RFR_Ku_Hpol_Type1 评估指标:\n",
      "  RMSE = 2.0016\n",
      "  Bias = 1.8442\n",
      "保存PNG结果: RFR_Ku_Hpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:  44%|████████████████████████████████▉                                         | 4/9 [00:07<00:09,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_Ku_Hpol_Type1_scatter.pdf\n",
      "模型 RFR_Ku_HVpol_Type1 没有预测数据，跳过\n",
      "模型 RFR_Ku_Vpol_Type1 有效点数量: 24874\n",
      "模型 RFR_Ku_Vpol_Type1 评估指标:\n",
      "  RMSE = 2.9737\n",
      "  Bias = 2.8415\n",
      "保存PNG结果: RFR_Ku_Vpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:  67%|█████████████████████████████████████████████████▎                        | 6/9 [00:10<00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_Ku_Vpol_Type1_scatter.pdf\n",
      "模型 RFR_X_Hpol_Type1 有效点数量: 27239\n",
      "模型 RFR_X_Hpol_Type1 评估指标:\n",
      "  RMSE = 2.8751\n",
      "  Bias = 2.7067\n",
      "保存PNG结果: RFR_X_Hpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果:  78%|█████████████████████████████████████████████████████████▌                | 7/9 [00:12<00:03,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_X_Hpol_Type1_scatter.pdf\n",
      "模型 RFR_X_HVpol_Type1 没有预测数据，跳过\n",
      "模型 RFR_X_Vpol_Type1 有效点数量: 26350\n",
      "模型 RFR_X_Vpol_Type1 评估指标:\n",
      "  RMSE = 1.8060\n",
      "  Bias = 1.6190\n",
      "保存PNG结果: RFR_X_Vpol_Type1_scatter.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成结果: 100%|██████████████████████████████████████████████████████████████████████████| 9/9 [00:15<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存PDF结果: RFR_X_Vpol_Type1_scatter.pdf\n",
      "\n",
      "所有处理完成! 结果保存在 'smapvex16Iowa_prediction_results' 文件夹中\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 设置路径\n",
    "mat_folder = r\"E:\\data\\VWC\\test-VWC\\SMAPVEX16_Iowa\\mat\"\n",
    "\n",
    "# 获取当前工作目录\n",
    "script_path = os.getcwd()    \n",
    "models_dir = os.path.join(script_path, 'models')\n",
    "\n",
    "# 定义需要读取的基本变量\n",
    "base_variables = [\n",
    "    'grassnat', 'grassman', 'shrubbd', 'shrubbe', 'shrubnd', 'shrubne',\n",
    "    'treebd', 'treebe', 'treend', 'treene', 'LAI', 'VSM', 'VWC'\n",
    "]\n",
    "\n",
    "# 查找所有匹配的模型文件\n",
    "model_files = glob.glob(os.path.join(models_dir, 'RFR_*.pkl'))\n",
    "models = []\n",
    "\n",
    "print(\"发现以下模型文件:\")\n",
    "for model_file in model_files:\n",
    "    filename = os.path.basename(model_file)\n",
    "    # 解析模型名称\n",
    "    parts = filename[:-4].split('_')  # 移除.pkl\n",
    "    if len(parts) < 4 or parts[0] != \"RFR\":\n",
    "        continue\n",
    "        \n",
    "    band = parts[1]\n",
    "    pol = parts[2].replace(\"pol\", \"\")  # 移除\"pol\"\n",
    "    model_type = int(parts[3].replace(\"Type\", \"\"))\n",
    "    \n",
    "    # 只保留类型为1的模型\n",
    "    if model_type != 1:\n",
    "        print(f\"跳过模型 {filename} (类型 {model_type} != 1)\")\n",
    "        continue\n",
    "    \n",
    "    # 添加该模型需要的VOD变量\n",
    "    vod_var = f\"{band.lower()}_vod_{pol}\"\n",
    "    mask_var = f\"{band}_{pol}_mask\"\n",
    "    \n",
    "    # 加载模型\n",
    "    try:\n",
    "        model = joblib.load(model_file)\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型 {filename} 时出错: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    models.append({\n",
    "        'name': filename[:-4],\n",
    "        'band': band,\n",
    "        'pol': pol,\n",
    "        'type': model_type,\n",
    "        'vod_var': vod_var,\n",
    "        'mask_var': mask_var,\n",
    "        'model': model,\n",
    "        'predicted': [],\n",
    "        'actual': []\n",
    "    })\n",
    "    print(f\"- {filename} (波段: {band}, 极化: {pol}, 类型: {model_type})\")\n",
    "\n",
    "if not models:\n",
    "    print(\"未找到任何类型为1的模型文件!\")\n",
    "    exit()\n",
    "\n",
    "# 遍历MAT文件夹\n",
    "mat_files = [f for f in os.listdir(mat_folder) \n",
    "            if f.endswith('.mat') and os.path.isfile(os.path.join(mat_folder, f))]\n",
    "\n",
    "print(f\"\\n找到 {len(mat_files)} 个MAT文件, 开始处理...\")\n",
    "\n",
    "for mat_file in tqdm(mat_files, desc=\"处理MAT文件\"):\n",
    "    file_path = os.path.join(mat_folder, mat_file)\n",
    "    \n",
    "    # 检查文件是否存在并可读\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"文件 {mat_file} 不存在\")\n",
    "        continue\n",
    "        \n",
    "    if not os.access(file_path, os.R_OK):\n",
    "        print(f\"没有权限读取文件 {mat_file}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 使用scipy加载MAT文件\n",
    "        mat_data = loadmat(file_path, simplify_cells=True)\n",
    "        \n",
    "        # 创建数据字典，方便访问\n",
    "        data_dict = {}\n",
    "        for var in base_variables:\n",
    "            if var in mat_data:\n",
    "                data_dict[var] = mat_data[var]\n",
    "            else:\n",
    "                print(f\"变量 {var} 在文件 {mat_file} 中缺失\")\n",
    "        \n",
    "        # 添加模型需要的变量\n",
    "        for model in models:\n",
    "            vod_var = model['vod_var']\n",
    "            mask_var = model['mask_var']\n",
    "            \n",
    "            if vod_var not in data_dict and vod_var in mat_data:\n",
    "                data_dict[vod_var] = mat_data[vod_var]\n",
    "            if mask_var not in data_dict and mask_var in mat_data:\n",
    "                data_dict[mask_var] = mat_data[mask_var]\n",
    "        \n",
    "        # 处理每个模型\n",
    "        for model in models:\n",
    "            vod_var = model['vod_var']\n",
    "            mask_var = model['mask_var']\n",
    "            \n",
    "            # 检查所需变量是否都存在\n",
    "            required_vars = [vod_var, mask_var, 'VSM', 'LAI'] + [v for v in base_variables if v != 'VWC']\n",
    "            missing_vars = [v for v in required_vars if v not in data_dict]\n",
    "            \n",
    "            if missing_vars:\n",
    "                print(f\"模型 {model['name']} 在文件 {mat_file} 中缺少变量: {', '.join(missing_vars)}\")\n",
    "                continue\n",
    "            \n",
    "            # 检查数组形状\n",
    "            base_shape = data_dict['VWC'].shape\n",
    "            for var in required_vars:\n",
    "                if data_dict[var].shape != base_shape:\n",
    "                    print(f\"警告: 变量 {var} 形状不一致: 期望 {base_shape}, 实际 {data_dict[var].shape}\")\n",
    "            \n",
    "            # 应用掩膜过滤无效数据\n",
    "            mask = data_dict[mask_var].astype(bool)\n",
    "            mask_flat = mask.flatten()\n",
    "            \n",
    "            # 获取实际VWC值\n",
    "            actual_vwc = data_dict['VWC'].flatten()[mask_flat]\n",
    "            \n",
    "            # 准备模型输入数据\n",
    "            lai_data = data_dict['LAI'].flatten()\n",
    "            lai_data = lai_data[:len(mask_flat)][mask_flat]\n",
    "            lai_data = np.clip(lai_data, 0, 6) / 6  # 归一化LAI\n",
    "            \n",
    "            vod_data = data_dict[vod_var].flatten()\n",
    "            vod_data = vod_data[:len(mask_flat)][mask_flat]\n",
    "            vod_data = np.clip(vod_data, 0, 2) / 2  # 归一化VOD\n",
    "            \n",
    "            # 获取PFT变量\n",
    "            pft_vars = {\n",
    "                'grassman': data_dict['grassman'].flatten(),\n",
    "                'grassnat': data_dict['grassnat'].flatten(),\n",
    "                'shrubbd': data_dict['shrubbd'].flatten(),\n",
    "                'shrubbe': data_dict['shrubbe'].flatten(),\n",
    "                'shrubnd': data_dict['shrubnd'].flatten(),\n",
    "                'shrubne': data_dict['shrubne'].flatten(),\n",
    "                'treebd': data_dict['treebd'].flatten(),\n",
    "                'treebe': data_dict['treebe'].flatten(),\n",
    "                'treend': data_dict['treend'].flatten(),\n",
    "                'treene': data_dict['treene'].flatten()\n",
    "            }\n",
    "            \n",
    "            # 截断到掩膜长度\n",
    "            for key in pft_vars:\n",
    "                pft_vars[key] = pft_vars[key][:len(mask_flat)][mask_flat]\n",
    "            \n",
    "            # 创建输入数据框\n",
    "            input_df = pd.DataFrame()\n",
    "            input_df['VOD'] = vod_data\n",
    "            input_df['LAI'] = lai_data\n",
    "            input_df['SM'] = data_dict['VSM'].flatten()[:len(mask_flat)][mask_flat]\n",
    "            \n",
    "            # 根据模型类型合成特征 (只处理类型1)\n",
    "            if model['type'] == 1:\n",
    "                input_df['Grass_man'] = pft_vars['grassman']\n",
    "                input_df['Grass_nat'] = pft_vars['grassnat']\n",
    "                input_df['Shrub_bd'] = pft_vars['shrubbd']\n",
    "                input_df['Shrub_be'] = pft_vars['shrubbe']\n",
    "                input_df['Shrub_nd'] = pft_vars['shrubnd']\n",
    "                input_df['Shrub_ne'] = pft_vars['shrubne']\n",
    "                input_df['Tree_bd'] = pft_vars['treebd']\n",
    "                input_df['Tree_be'] = pft_vars['treebe']\n",
    "                input_df['Tree_nd'] = pft_vars['treend']\n",
    "                input_df['Tree_ne'] = pft_vars['treene']\n",
    "                \n",
    "            # 使用模型预测\n",
    "            predicted_vwc = model['model'].predict(input_df)\n",
    "            \n",
    "            # 收集结果\n",
    "            model['predicted'].extend(predicted_vwc)\n",
    "            model['actual'].extend(actual_vwc)\n",
    "            \n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1] if exc_tb else \"unknown\"\n",
    "        lineno = exc_tb.tb_lineno if exc_tb else 0\n",
    "        print(f\"\\n处理文件 {mat_file} 时出错: {str(e)} 在文件 {fname} 的第 {lineno} 行\")\n",
    "\n",
    "# 保存结果并绘图\n",
    "output_dir = \"smapvex16Iowa_prediction_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\n处理完成, 开始保存结果和绘图...\")\n",
    "\n",
    "# 配置Matplotlib使用无中文字体的后端\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Tahoma'],\n",
    "    'axes.unicode_minus': False\n",
    "})\n",
    "\n",
    "for model in tqdm(models, desc=\"生成结果\"):\n",
    "    if not model['predicted']:\n",
    "        print(f\"模型 {model['name']} 没有预测数据，跳过\")\n",
    "        continue\n",
    "        \n",
    "    # 转换为NumPy数组\n",
    "    predicted = np.array(model['predicted'])\n",
    "    actual = np.array(model['actual'])\n",
    "    \n",
    "    # 移除NaN值\n",
    "    valid_mask = ~np.isnan(actual) & ~np.isnan(predicted)\n",
    "    if valid_mask.sum() == 0:\n",
    "        print(f\"模型 {model['name']} 没有有效数据\")\n",
    "        continue\n",
    "        \n",
    "    actual = actual[valid_mask]\n",
    "    predicted = predicted[valid_mask]\n",
    "    \n",
    "    # 计算样本点数量\n",
    "    n_points = len(actual)\n",
    "    print(f\"模型 {model['name']} 有效点数量: {n_points}\")\n",
    "    \n",
    "    # 如果结果太多，随机采样一部分用于绘图\n",
    "    max_points = 100000\n",
    "    if n_points > max_points:\n",
    "        indices = np.random.choice(n_points, max_points, replace=False)\n",
    "        sampled_actual = actual[indices]\n",
    "        sampled_predicted = predicted[indices]\n",
    "    else:\n",
    "        sampled_actual = actual\n",
    "        sampled_predicted = predicted\n",
    "    \n",
    "    # 保存所有预测结果和实际值到CSV\n",
    "    result_df = pd.DataFrame({\n",
    "        'Actual': actual,\n",
    "        'Predicted': predicted\n",
    "    })\n",
    "    result_df.to_csv(os.path.join(output_dir, f\"{model['name']}_results.csv\"), index=False)\n",
    "    \n",
    "    # 计算评估指标\n",
    "    rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
    "    bias = np.mean(predicted - actual)\n",
    "    \n",
    "    print(f\"模型 {model['name']} 评估指标:\")\n",
    "    print(f\"  RMSE = {rmse:.4f}\")\n",
    "    print(f\"  Bias = {bias:.4f}\")\n",
    "    \n",
    "    try:\n",
    "        # 绘制散点图 - PNG版本\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        hb = plt.hexbin(\n",
    "            sampled_actual, \n",
    "            sampled_predicted, \n",
    "            gridsize=100, \n",
    "            cmap='viridis', \n",
    "            mincnt=1,\n",
    "            bins='log'  # 使用对数尺度增强可视化\n",
    "        )\n",
    "        cb = plt.colorbar(hb, label='Point Density')  # 修改为英文以避免字体问题\n",
    "        \n",
    "        # 添加参考线 y=x\n",
    "        max_val = max(sampled_actual.max(), sampled_predicted.max())\n",
    "        plt.plot([0, max_val], [0, max_val], 'r--', linewidth=2, label=\"1:1 Line\")\n",
    "\n",
    "        # 添加统计信息 (使用英文避免字体问题)\n",
    "        plt.text(\n",
    "            0.05, 0.95,\n",
    "            f\"n = {n_points:,}\\nRMSE = {rmse:.3f}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "\n",
    "        plt.title(f\"VWC Prediction - {model['name']}\", fontsize=16)\n",
    "        plt.xlabel(\"Actual VWC\", fontsize=12)\n",
    "        plt.ylabel(\"Predicted VWC\", fontsize=12)\n",
    "        \n",
    "        # 添加网格线增强可读性\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像为PNG\n",
    "        plot_path = os.path.join(output_dir, f\"{model['name']}_scatter.png\")\n",
    "        plt.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"保存PNG结果: {model['name']}_scatter.png\")\n",
    "        \n",
    "        # 绘制PDF版本\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        hb_pdf = plt.hexbin(\n",
    "            sampled_actual, \n",
    "            sampled_predicted, \n",
    "            gridsize=200,  # PDF使用更高的分辨率\n",
    "            cmap='viridis', \n",
    "            mincnt=1,\n",
    "            bins='log'\n",
    "        )\n",
    "        cb_pdf = plt.colorbar(hb_pdf, label='Point Density')\n",
    "        plt.plot([0, max_val], [0, max_val], 'r--', linewidth=2)\n",
    "        plt.title(f\"VWC Prediction - {model['name']}\", fontsize=16)\n",
    "        plt.xlabel(\"Actual VWC\", fontsize=12)\n",
    "        plt.ylabel(\"Predicted VWC\", fontsize=12)\n",
    "        \n",
    "        # PDF版本的统计信息放在底部\n",
    "        plt.text(\n",
    "            0.05, 0.05,\n",
    "            f\"n = {n_points:,} | RMSE = {rmse:.3f} | Bias = {bias:.3f}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            verticalalignment='bottom',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "        \n",
    "        plt.grid(True, linestyle='--', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        pdf_path = os.path.join(output_dir, f\"{model['name']}_scatter.pdf\")\n",
    "        plt.savefig(pdf_path, format='pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"保存PDF结果: {model['name']}_scatter.pdf\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"为模型 {model['name']} 生成图表时出错: {str(e)}\")\n",
    "\n",
    "print(\"\\n所有处理完成! 结果保存在 'smapvex16Iowa_prediction_results' 文件夹中\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d291a-2340-4bb1-b662-e98655ad4160",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2.CLASIC07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2470ece-13e6-40a8-8eed-6ff9fb071efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功处理并保存至: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 将txt读取为xlsx，并且转化WGS84的经纬度坐标\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# 忽略pyproj的警告信息\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def convert_utm_to_wgs84(easting, northing, zone=14, hemisphere='N'):\n",
    "    \"\"\"\n",
    "    将UTM坐标转换为WGS84经纬度\n",
    "    \n",
    "    参数:\n",
    "        easting: UTM东坐标\n",
    "        northing: UTM北坐标\n",
    "        zone: UTM区域号 (默认为14)\n",
    "        hemisphere: 半球标识 ('N' 北半球 或 'S' 南半球)\n",
    "    \n",
    "    返回:\n",
    "        (经度, 纬度) 元组\n",
    "    \"\"\"\n",
    "    # 定义UTM投影系统\n",
    "    utm_crs = pyproj.CRS(f\"+proj=utm +zone={zone} +{hemisphere} +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n",
    "    \n",
    "    # 定义WGS84地理坐标系统\n",
    "    wgs84_crs = pyproj.CRS(\"EPSG:4326\")  # WGS84\n",
    "    \n",
    "    # 创建转换器\n",
    "    transformer = Transformer.from_crs(utm_crs, wgs84_crs)\n",
    "    \n",
    "    # 执行坐标转换 - 返回(经度, 纬度)\n",
    "    longitude, latitude = transformer.transform(easting, northing)\n",
    "    \n",
    "    return longitude, latitude  # 正确返回(经度, 纬度)\n",
    "\n",
    "def process_vegetation_data(input_file_path):\n",
    "    # 读取文本文件\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # 处理数据行（跳过前5行标题）\n",
    "    processed_data = []\n",
    "    \n",
    "    # 从第6行开始处理（索引5），跳过前5行标题\n",
    "    for line in lines[5:]:\n",
    "        clean_line = line.strip()\n",
    "        if not clean_line:  # 跳过空行\n",
    "            continue\n",
    "            \n",
    "        parts = clean_line.split()\n",
    "        \n",
    "        # 处理Crop列可能包含空格的情况\n",
    "        if len(parts) == 10:\n",
    "            # 标准情况：Crop为单次词\n",
    "            crop = parts[1]\n",
    "            date_index = 2\n",
    "        elif len(parts) == 11:\n",
    "            # Crop包含空格：如\"Cut WW\"\n",
    "            crop = f\"{parts[1]} {parts[2]}\"\n",
    "            date_index = 3\n",
    "        else:\n",
    "            # 跳过格式不匹配的行\n",
    "            print(f\"跳过格式不匹配的行: {clean_line}\")\n",
    "            continue\n",
    "        \n",
    "        # 提取各字段\n",
    "        field = parts[0]\n",
    "        date_str = parts[date_index]\n",
    "        doy = parts[date_index + 1]\n",
    "        time = parts[date_index + 2]\n",
    "        vwc = parts[date_index + 3]\n",
    "        easting = parts[date_index + 6]\n",
    "        northing = parts[date_index + 7]\n",
    "        \n",
    "        # 跳过标题行（如果第一个字段是\"Field\"）\n",
    "        if field == \"Field\":\n",
    "            print(f\"跳过标题行: {clean_line}\")\n",
    "            continue\n",
    "        \n",
    "        # 转换日期格式\n",
    "        try:\n",
    "            # 解析原始日期格式: \"月/日/年\"\n",
    "            date_obj = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "            # 格式化为新的日期字符串: YYYY-MM-DD\n",
    "            formatted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "        except ValueError as e:\n",
    "            print(f\"日期格式转换错误: {e} (Field: {field}, Date: {date_str})\")\n",
    "            formatted_date = date_str  # 保留原始日期字符串\n",
    "        \n",
    "        # 将UTM坐标转换为WGS84经纬度\n",
    "        try:\n",
    "            # 转换为浮点数\n",
    "            easting_float = float(easting)\n",
    "            northing_float = float(northing)\n",
    "            \n",
    "            # 执行坐标转换 (使用UTM Zone 14N)\n",
    "            # 正确获取经度和纬度\n",
    "            longitude, latitude = convert_utm_to_wgs84(easting_float, northing_float, zone=14, hemisphere='N')\n",
    "            \n",
    "            # 保留6位小数精度\n",
    "            longitude = round(longitude, 6)\n",
    "            latitude = round(latitude, 6)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(f\"坐标转换错误: {e} (Field: {field}, Easting: {easting}, Northing: {northing})\")\n",
    "            longitude, latitude = None, None\n",
    "        \n",
    "        processed_data.append([\n",
    "            field, crop, formatted_date, doy, time, vwc,\n",
    "            longitude, latitude, easting, northing  # 正确顺序：经度、纬度\n",
    "        ])\n",
    "    \n",
    "    # 创建DataFrame - 修正列名\n",
    "    columns = [\n",
    "        \"Field\", \"Crop\", \"Date\", \"DOY\", \"Time (CDT)\", \n",
    "        \"VWC (kg/m²)\", \"Latitude (WGS84)\", \"Longitude (WGS84)\", \n",
    "        \"UTM Easting\", \"UTM Northing\"\n",
    "    ]\n",
    "    df = pd.DataFrame(processed_data, columns=columns)\n",
    "    \n",
    "    # 优化数据类型\n",
    "    numeric_cols = [\"DOY\", \"VWC (kg/m²)\", \"Longitude (WGS84)\", \"Latitude (WGS84)\", \n",
    "                   \"UTM Easting\", \"UTM Northing\"]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # 创建输出文件路径（同名.xlsx）\n",
    "    base_name = os.path.splitext(os.path.basename(input_file_path))[0]\n",
    "    output_dir = os.path.dirname(input_file_path)\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}.xlsx\")\n",
    "    \n",
    "    # 保存为Excel文件（带自动列宽调整）\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='Vegetation Data')\n",
    "            \n",
    "            # 获取工作簿和工作表对象\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['Vegetation Data']\n",
    "            \n",
    "            # 设置自动调整列宽\n",
    "            for i, col in enumerate(df.columns):\n",
    "                # 获取列的最大宽度\n",
    "                max_len = max(df[col].astype(str).map(len).max(), len(col)) + 2\n",
    "                worksheet.set_column(i, i, max_len)\n",
    "    except Exception as e:\n",
    "        # 如果xlsxwriter引擎失败，尝试使用openpyxl\n",
    "        print(f\"使用xlsxwriter引擎失败: {e}\")\n",
    "        print(\"尝试使用openpyxl引擎...\")\n",
    "        df.to_excel(output_file, index=False, sheet_name='Vegetation Data')\n",
    "        print(f\"已使用openpyxl引擎保存文件，但不支持自动调整列宽\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# 直接指定文本文件路径\n",
    "input_file_path = r\"E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.txt\"\n",
    "\n",
    "# 检查文件是否存在\n",
    "if not os.path.isfile(input_file_path):\n",
    "    print(f\"错误: 文件 '{input_file_path}' 不存在!\")\n",
    "else:\n",
    "    # 处理数据并保存\n",
    "    output_file = process_vegetation_data(input_file_path)\n",
    "    print(f\"数据已成功处理并保存至: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c4a55e-cd85-416d-9f51-0d53d0052d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "开始处理CLASIC07数据插值任务\n",
      "============================================================\n",
      "输入文件: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.xlsx\n",
      "输出将保存到: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
      "读取原始Excel文件: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.xlsx\n",
      "数据列名: ['Field', 'Crop', 'Date', 'DOY', 'Time (CDT)', 'VWC (kg/m²)', 'Latitude', 'Longitude', 'UTM Easting', 'UTM Northing']\n",
      "成功读取 22 条记录\n",
      "\n",
      "处理PFT数据: E:\\data\\ESACCI PFT\\Resample\\Data\\2007.mat\n",
      "  文件中可用的PFT变量: water, bare, snowice, built, grassnat, grassman, shrubbd, shrubbe, shrubnd, shrubne, treebd, treebe, treend, treene\n",
      "  已添加列: PFT_water\n",
      "  已添加列: PFT_bare\n",
      "  已添加列: PFT_snowice\n",
      "  已添加列: PFT_built\n",
      "  已添加列: PFT_grassnat\n",
      "  已添加列: PFT_grassman\n",
      "  已添加列: PFT_shrubbd\n",
      "  已添加列: PFT_shrubbe\n",
      "  已添加列: PFT_shrubnd\n",
      "  已添加列: PFT_shrubne\n",
      "  已添加列: PFT_treebd\n",
      "  已添加列: PFT_treebe\n",
      "  已添加列: PFT_treend\n",
      "  已添加列: PFT_treene\n",
      "\n",
      "处理VOD数据:\n",
      "  处理日期: 20070610, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070610_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070611, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070611_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070612, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070612_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070613, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070613_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070616, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070616_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070617, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070617_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070618, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070618_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070619, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070619_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070623, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070623_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070624, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070624_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070628, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070628_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20070703, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20070703_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "\n",
      "处理LAI卫星数据...\n",
      "  加载LAI数据 (2007-05-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-05-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  加载LAI数据 (2007-06-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-06-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  加载LAI数据 (2007-07-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-07-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  处理日期: 2007-06-10, 5-6月插值, 权重: 0.84\n",
      "    平均LAI: 1.4226\n",
      "  处理日期: 2007-06-11, 5-6月插值, 权重: 0.87\n",
      "    平均LAI: 1.4331\n",
      "  处理日期: 2007-06-12, 5-6月插值, 权重: 0.90\n",
      "    平均LAI: 1.4435\n",
      "  处理日期: 2007-06-13, 5-6月插值, 权重: 0.94\n",
      "    平均LAI: 1.4539\n",
      "  处理日期: 2007-06-16, 6-7月插值, 权重: 0.03\n",
      "    平均LAI: 1.4791\n",
      "  处理日期: 2007-06-17, 6-7月插值, 权重: 0.07\n",
      "    平均LAI: 1.4833\n",
      "  处理日期: 2007-06-18, 6-7月插值, 权重: 0.10\n",
      "    平均LAI: 1.4876\n",
      "  处理日期: 2007-06-19, 6-7月插值, 权重: 0.13\n",
      "    平均LAI: 1.4918\n",
      "  处理日期: 2007-06-23, 6-7月插值, 权重: 0.27\n",
      "    平均LAI: 1.5088\n",
      "  处理日期: 2007-06-24, 6-7月插值, 权重: 0.30\n",
      "    平均LAI: 1.5131\n",
      "  处理日期: 2007-06-28, 6-7月插值, 权重: 0.43\n",
      "    平均LAI: 1.5301\n",
      "  处理日期: 2007-07-03, 6-7月插值, 权重: 0.60\n",
      "    平均LAI: 1.5514\n",
      "\n",
      "处理植被高度数据...\n",
      "  加载植被高度数据: E:\\data\\CanopyHeight\\CH.mat\n",
      "  已添加植被高度列\n",
      "\n",
      "保存结果到: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
      "插值详细信息保存到: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\interpolation_details.xlsx\n",
      "\n",
      "处理完成!\n",
      "总记录数: 22\n",
      "插值操作次数: 506\n",
      "\n",
      "前3次插值的详细信息:\n",
      "\n",
      "插值 #1\n",
      "  类型: bilinear\n",
      "  目标位置: (35.207498, -98.593259)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 547, 列 813 - 位置 (35.250000, -98.650000) - 值: 0.000000\n",
      "    点2: 行 547, 列 814 - 位置 (35.250000, -98.550000) - 值: 0.039043\n",
      "    点3: 行 548, 列 813 - 位置 (35.150000, -98.650000) - 值: 0.000262\n",
      "    点4: 行 548, 列 814 - 位置 (35.150000, -98.550000) - 值: 0.000193\n",
      "\n",
      "插值 #2\n",
      "  类型: bilinear\n",
      "  目标位置: (35.206738, -98.576530)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 547, 列 813 - 位置 (35.250000, -98.650000) - 值: 0.000000\n",
      "    点2: 行 547, 列 814 - 位置 (35.250000, -98.550000) - 值: 0.039043\n",
      "    点3: 行 548, 列 813 - 位置 (35.150000, -98.650000) - 值: 0.000262\n",
      "    点4: 行 548, 列 814 - 位置 (35.150000, -98.550000) - 值: 0.000193\n",
      "\n",
      "插值 #3\n",
      "  类型: bilinear\n",
      "  目标位置: (35.208282, -98.567019)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 547, 列 813 - 位置 (35.250000, -98.650000) - 值: 0.000000\n",
      "    点2: 行 547, 列 814 - 位置 (35.250000, -98.550000) - 值: 0.039043\n",
      "    点3: 行 548, 列 813 - 位置 (35.150000, -98.650000) - 值: 0.000262\n",
      "    点4: 行 548, 列 814 - 位置 (35.150000, -98.550000) - 值: 0.000193\n",
      "\n",
      "==============================\n",
      "任务成功完成!\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 数据填充\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 全局变量记录插值详细信息\n",
    "interpolation_details = []\n",
    "\n",
    "# ====================== 改进的MAT文件读取函数 ======================\n",
    "def read_hdf5_mat(file_path, expected_keys=None):\n",
    "    \"\"\"读取MATLAB v7.3格式的HDF5文件，优先查找特定变量\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = {}\n",
    "            \n",
    "            def visitor_func(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    if h5py.check_string_dtype(obj.dtype):\n",
    "                        value = ''.join(chr(c) for c in obj[:])\n",
    "                    else:\n",
    "                        value = np.array(obj)\n",
    "                    if value.ndim >= 2:\n",
    "                        value = value.T\n",
    "                    base_name = name.split('/')[-1]\n",
    "                    data[base_name] = value\n",
    "            \n",
    "            f.visititems(visitor_func)\n",
    "            \n",
    "            # 优先查找预期变量\n",
    "            if expected_keys:\n",
    "                for key in expected_keys:\n",
    "                    if key in data:\n",
    "                        return {key: data[key]}\n",
    "            \n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"  读取HDF5 MAT文件失败: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# ====================== 改进的双线性插值函数 ======================\n",
    "def bilinear_interpolation_with_details(lat_grid, lon_grid, target_lat, target_lon, grid_data):\n",
    "    \"\"\"\n",
    "    执行双线性插值并记录详细信息\n",
    "    :param lat_grid: 网格纬度数组 (1D, 从北向南递减)\n",
    "    :param lon_grid: 网格经度数组 (1D, 从西向东递增)\n",
    "    :param target_lat: 目标点纬度\n",
    "    :param target_lon: 目标点经度\n",
    "    :param grid_data: 网格数据 (2D数组, 形状为(len(lat_grid), len(lon_grid)))\n",
    "    :return: 插值值\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        # 记录网格形状\n",
    "        grid_shape = grid_data.shape\n",
    "        \n",
    "        # 验证网格尺寸\n",
    "        if len(lat_grid) != grid_shape[0] or len(lon_grid) != grid_shape[1]:\n",
    "            print(f\"警告: 网格尺寸不匹配! 纬度网格: {len(lat_grid)}, 经度网格: {len(lon_grid)}, 数据形状: {grid_shape}\")\n",
    "            return np.nan\n",
    "        \n",
    "        # 查找最近的纬度索引（纬度从北向南递减）\n",
    "        # 纬度网格: 89.95 (北) -> -89.95 (南)\n",
    "        lat_idx = np.argmin(np.abs(lat_grid - target_lat))\n",
    "        \n",
    "        # 查找最近的经度索引（经度从西向东递增）\n",
    "        # 经度网格: -179.95 (西) -> 179.95 (东)\n",
    "\n",
    "        lon_idx = np.argmin(np.abs(lon_grid - target_lon))\n",
    "        \n",
    "        # 确定四个角点索引\n",
    "        # 纬度处理：目标点位于两个纬度网格点之间\n",
    "        if target_lat > lat_grid[lat_idx]:\n",
    "            # 目标纬度大于当前网格点纬度（更北）\n",
    "            if lat_idx > 0:\n",
    "                lat_idx0 = lat_idx - 1\n",
    "                lat_idx1 = lat_idx\n",
    "            else:\n",
    "                lat_idx0 = lat_idx\n",
    "                lat_idx1 = lat_idx\n",
    "        else:\n",
    "            # 目标纬度小于当前网格点纬度（更南）\n",
    "            if lat_idx < len(lat_grid) - 1:\n",
    "                lat_idx0 = lat_idx\n",
    "                lat_idx1 = lat_idx + 1\n",
    "            else:\n",
    "                lat_idx0 = lat_idx\n",
    "                lat_idx1 = lat_idx\n",
    "        \n",
    "        # 经度处理：目标点位于两个经度网格点之间\n",
    "        if target_lon > lon_grid[lon_idx]:\n",
    "            # 目标经度大于当前网格点经度（更东）\n",
    "            if lon_idx < len(lon_grid) - 1:\n",
    "                lon_idx0 = lon_idx\n",
    "                lon_idx1 = lon_idx + 1\n",
    "            else:\n",
    "                lon_idx0 = lon_idx\n",
    "                lon_idx1 = lon_idx\n",
    "        else:\n",
    "            # 目标经度小于当前网格点经度（更西）\n",
    "            if lon_idx > 0:\n",
    "                lon_idx0 = lon_idx - 1\n",
    "                lon_idx1 = lon_idx\n",
    "            else:\n",
    "                lon_idx0 = lon_idx\n",
    "                lon_idx1 = lon_idx\n",
    "        \n",
    "        # 获取四个角点值\n",
    "        Q00 = grid_data[lat_idx0, lon_idx0]\n",
    "        Q01 = grid_data[lat_idx0, lon_idx1]\n",
    "        Q10 = grid_data[lat_idx1, lon_idx0]\n",
    "        Q11 = grid_data[lat_idx1, lon_idx1]\n",
    "        \n",
    "        # 四个角点坐标\n",
    "        y0 = lat_grid[lat_idx0]\n",
    "        y1 = lat_grid[lat_idx1]\n",
    "        x0 = lon_grid[lon_idx0]\n",
    "        x1 = lon_grid[lon_idx1]\n",
    "        \n",
    "        # 如果有NaN，使用最接近的点\n",
    "        if np.isnan(Q00) or np.isnan(Q01) or np.isnan(Q10) or np.isnan(Q11):\n",
    "            result = grid_data[lat_idx, lon_idx]\n",
    "            details = {\n",
    "                'type': 'nearest',\n",
    "                'row': lat_idx,\n",
    "                'col': lon_idx,\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [grid_data[lat_idx, lon_idx]],\n",
    "                'lat_values': [lat_grid[lat_idx]],\n",
    "                'lon_values': [lon_grid[lon_idx]]\n",
    "            }\n",
    "        else:\n",
    "            # 双线性插值公式\n",
    "            dx = (target_lon - x0) / (x1 - x0) if (x1 - x0) != 0 else 0\n",
    "            dy = (target_lat - y0) / (y1 - y0) if (y1 - y0) != 0 else 0\n",
    "            result = (1 - dx) * (1 - dy) * Q00 + dx * (1 - dy) * Q01 + (1 - dx) * dy * Q10 + dx * dy * Q11\n",
    "            \n",
    "            details = {\n",
    "                'type': 'bilinear',\n",
    "                'rows': [lat_idx0, lat_idx0, lat_idx1, lat_idx1],\n",
    "                'cols': [lon_idx0, lon_idx1, lon_idx0, lon_idx1],\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [Q00, Q01, Q10, Q11],\n",
    "                'lat_values': [y0, y0, y1, y1],\n",
    "                'lon_values': [x0, x1, x0, x1]\n",
    "            }\n",
    "        \n",
    "        # 保存插值详细信息\n",
    "        interpolation_details.append(details)\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"插值错误: {str(e)}\")\n",
    "        return np.nan\n",
    "# ====================== 主处理函数 ======================\n",
    "def process_clasic07_data(input_file_path):\n",
    "    \"\"\"\n",
    "    处理CLASIC07数据，执行多种插值操作\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        interpolation_details = []  # 重置插值详情\n",
    "        \n",
    "        # ========== 1. 读取原始数据 ==========\n",
    "        print(f\"读取原始Excel文件: {input_file_path}\")\n",
    "        df = pd.read_excel(input_file_path)\n",
    "        \n",
    "        # 调整列名以匹配您的文件\n",
    "        df = df.rename(columns={\n",
    "            'Latitude (WGS84)': 'Latitude',\n",
    "            'Longitude (WGS84)': 'Longitude'\n",
    "        })\n",
    "        \n",
    "        # 打印列名以验证\n",
    "        print(\"数据列名:\", df.columns.tolist())\n",
    "        \n",
    "        # 定义标准经纬度网格 (0.1°分辨率)\n",
    "        # 纬度: 北纬89.95°(0) -> 南纬-89.95°(1799)\n",
    "        lat_grid = np.linspace(89.95, -89.95, 1800)\n",
    "        \n",
    "        # 经度: -179.95°(0) -> 179.95°(3599) [根据您的要求]\n",
    "        lon_grid = np.linspace(-179.95, 179.95, 3600)\n",
    "        \n",
    "        print(f\"成功读取 {len(df)} 条记录\")\n",
    "        \n",
    "        # ========== 2. 准备PFT数据 (14个类别) ==========\n",
    "        pft_file = r\"E:\\data\\ESACCI PFT\\Resample\\Data\\2007.mat\"\n",
    "        if os.path.exists(pft_file):\n",
    "            print(f\"\\n处理PFT数据: {pft_file}\")\n",
    "            mat_data = read_hdf5_mat(pft_file)\n",
    "            \n",
    "            pft_columns = ['water','bare','snowice','built','grassnat','grassman',\n",
    "                          'shrubbd','shrubbe','shrubnd','shrubne',\n",
    "                          'treebd','treebe','treend','treene']\n",
    "            \n",
    "            available_pft = [col for col in pft_columns if col in mat_data]\n",
    "            print(f\"  文件中可用的PFT变量: {', '.join(available_pft)}\")\n",
    "            \n",
    "            # 处理每个可用的PFT类别\n",
    "            for col in available_pft:\n",
    "                grid_data = mat_data[col] / 100.0\n",
    "                df[f'PFT_{col}'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        grid_data\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加列: PFT_{col}\")\n",
    "        else:\n",
    "            print(f\"\\n警告: PFT文件不存在 - {pft_file}\")\n",
    "        \n",
    "        # ========== 3. 处理VOD数据 (7个变量) ==========\n",
    "        vod_base_dir = r\"E:\\data\\VOD\\mat\\kuxcVOD\\ASC\"\n",
    "        vod_cols = ['SM','ku_vod_H', 'ku_vod_V', 'x_vod_H','x_vod_V', 'c_vod_H','c_vod_V']\n",
    "        \n",
    "        for col in vod_cols:\n",
    "            df[col] = np.nan\n",
    "        \n",
    "        print(\"\\n处理VOD数据:\")\n",
    "        \n",
    "        # 收集所有唯一日期并排序\n",
    "        unique_dates = sorted(df['Date'].unique())\n",
    "        vod_files_found = 0\n",
    "        \n",
    "        for date in unique_dates:\n",
    "            # 转换为字符串格式YYYYMMDD\n",
    "            try:\n",
    "                if isinstance(date, pd.Timestamp):\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "                elif isinstance(date, datetime):\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "                elif isinstance(date, str):\n",
    "                    date_dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "                    date_str = date_dt.strftime(\"%Y%m%d\")\n",
    "                else:\n",
    "                    date_str = str(date).replace(\"-\", \"\")[:8]\n",
    "            except Exception as e:\n",
    "                print(f\"  无法解析日期: {date}, 错误: {e}\")\n",
    "                continue\n",
    "            \n",
    "            vod_file = os.path.join(vod_base_dir, f\"MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "            if os.path.exists(vod_file):\n",
    "                vod_files_found += 1\n",
    "                print(f\"  处理日期: {date_str}, 文件: {os.path.basename(vod_file)}\")\n",
    "                vod_data = read_hdf5_mat(vod_file)\n",
    "                \n",
    "                for col in vod_cols:\n",
    "                    if col in vod_data:\n",
    "                        grid_data = vod_data[col]\n",
    "                        mask = df['Date'] == date\n",
    "                        df.loc[mask, col] = df[mask].apply(\n",
    "                            lambda row: bilinear_interpolation_with_details(\n",
    "                                lat_grid, lon_grid, \n",
    "                                row['Latitude'], row['Longitude'], \n",
    "                                grid_data\n",
    "                            ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                            else np.nan, axis=1\n",
    "                        )\n",
    "                        print(f\"    已更新: {col}\")\n",
    "                    else:\n",
    "                        print(f\"    警告: VOD变量 {col} 不存在于文件中\")\n",
    "            else:\n",
    "                print(f\"  警告: VOD文件不存在 - {os.path.basename(vod_file)}\")\n",
    "                \n",
    "        if vod_files_found == 0:\n",
    "            print(\"  警告: 没有找到任何VOD文件，VOD列将保留为空\")\n",
    "        \n",
    "        # ========== 4. 处理LAI卫星数据 (时间插值) ==========\n",
    "        print(\"\\n处理LAI卫星数据...\")\n",
    "        df['LAI_Satellite'] = np.nan\n",
    "        \n",
    "        # 预期可能的LAI变量名\n",
    "        expected_lai_keys = ['lai', 'LAI', 'data']\n",
    "        \n",
    "        # 定义三个LAI文件\n",
    "        lai_files = {\n",
    "            datetime(2007, 5, 15): r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-05-01.tif.mat\",\n",
    "            datetime(2007, 6, 15): r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-06-01.tif.mat\",\n",
    "            datetime(2007, 7, 15): r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2007-07-01.tif.mat\"\n",
    "        }\n",
    "        \n",
    "        # 加载LAI数据\n",
    "        lai_data = {}\n",
    "        for date_key, file_path in lai_files.items():\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"  加载LAI数据 ({date_key.strftime('%Y-%m-%d')}): {file_path}\")\n",
    "                # 使用增强的MAT文件读取函数，指定预期变量\n",
    "                file_data = read_hdf5_mat(file_path, expected_keys=expected_lai_keys)\n",
    "                \n",
    "                if file_data:\n",
    "                    # 直接获取LAI数据（优先找到的变量）\n",
    "                    lai_value = list(file_data.values())[0]\n",
    "                    print(f\"    成功读取LAI变量 '{list(file_data.keys())[0]}'，数据形状: {lai_value.shape}\")\n",
    "                    lai_data[date_key] = lai_value\n",
    "                else:\n",
    "                    print(\"    警告: 文件中未找到预期LAI变量，使用全零数组\")\n",
    "                    lai_data[date_key] = np.zeros((1800, 3600))\n",
    "            else:\n",
    "                print(f\"  警告: LAI文件不存在 - {file_path}\")\n",
    "                lai_data[date_key] = np.zeros((1800, 3600))\n",
    "        \n",
    "        # 定义关键日期\n",
    "        mid_may = datetime(2007, 5, 15)\n",
    "        mid_june = datetime(2007, 6, 15)\n",
    "        mid_july = datetime(2007, 7, 15)\n",
    "        \n",
    "        # 处理每个日期的数据\n",
    "        for date in unique_dates:\n",
    "            try:\n",
    "                # 确保日期为datetime对象\n",
    "                if isinstance(date, pd.Timestamp):\n",
    "                    date_dt = date.to_pydatetime()\n",
    "                elif isinstance(date, datetime):\n",
    "                    date_dt = date\n",
    "                elif isinstance(date, str):\n",
    "                    date_dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "                else:\n",
    "                    print(f\"  无法识别的日期格式: {date}\")\n",
    "                    continue\n",
    "                \n",
    "                # 应用LAI插值策略\n",
    "                if date_dt <= mid_may:\n",
    "                    # 使用5月15日数据\n",
    "                    interpolated_lai = lai_data[mid_may]\n",
    "                    print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 使用5月15日数据\")\n",
    "                elif date_dt == mid_june:\n",
    "                    # 直接使用6月15日数据\n",
    "                    interpolated_lai = lai_data[mid_june]\n",
    "                    print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 使用6月15日数据\")\n",
    "                elif date_dt >= mid_july:\n",
    "                    # 使用7月15日数据\n",
    "                    interpolated_lai = lai_data[mid_july]\n",
    "                    print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 使用7月15日数据\")\n",
    "                elif mid_may < date_dt < mid_june:\n",
    "                    # 5月16日至6月14日使用5月和6月数据插值\n",
    "                    weight = (date_dt - mid_may).days / (mid_june - mid_may).days\n",
    "                    interpolated_lai = (1 - weight) * lai_data[mid_may] + weight * lai_data[mid_june]\n",
    "                    print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 5-6月插值, 权重: {weight:.2f}\")\n",
    "                elif mid_june < date_dt < mid_july:\n",
    "                    # 6月16日至7月14日使用6月和7月数据插值\n",
    "                    weight = (date_dt - mid_june).days / (mid_july - mid_june).days\n",
    "                    interpolated_lai = (1 - weight) * lai_data[mid_june] + weight * lai_data[mid_july]\n",
    "                    print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 6-7月插值, 权重: {weight:.2f}\")\n",
    "                else:\n",
    "                    print(f\"  日期 {date_dt.strftime('%Y-%m-%d')} 不在处理范围内\")\n",
    "                    continue\n",
    "                \n",
    "                # 计算平均LAI值用于验证\n",
    "                mean_lai = np.nanmean(interpolated_lai)\n",
    "                print(f\"    平均LAI: {mean_lai:.4f}\")\n",
    "                \n",
    "                # 应用空间插值\n",
    "                mask = df['Date'] == date\n",
    "                df.loc[mask, 'LAI_Satellite'] = df[mask].apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        interpolated_lai\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"  处理日期{date}时出错: {str(e)}\")\n",
    "        \n",
    "        # ========== 5. 处理植被高度数据 ==========\n",
    "        print(\"\\n处理植被高度数据...\")\n",
    "        df['Hveg'] = np.nan\n",
    "        \n",
    "        hveg_file = r\"E:\\data\\CanopyHeight\\CH.mat\"\n",
    "        if os.path.exists(hveg_file):\n",
    "            print(f\"  加载植被高度数据: {hveg_file}\")\n",
    "            hveg_data = read_hdf5_mat(hveg_file)\n",
    "            hveg_key = next(iter(hveg_data)) if hveg_data else None\n",
    "            \n",
    "            if hveg_key:\n",
    "                df['Hveg'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        hveg_data[hveg_key]\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加植被高度列\")\n",
    "            else:\n",
    "                print(f\"  警告: 无法找到Hveg变量\")\n",
    "                df['Hveg'] = np.nan\n",
    "        else:\n",
    "            print(f\"  警告: Hveg文件不存在 - {hveg_file}\")\n",
    "            df['Hveg'] = np.nan\n",
    "        \n",
    "        # ========== 6. 保存结果 ==========\n",
    "        output_file_path = r\"E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\"\n",
    "        print(f\"\\n保存结果到: {output_file_path}\")\n",
    "        df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        # 保存插值详细信息到Excel\n",
    "        if interpolation_details:\n",
    "            details_df = pd.DataFrame(interpolation_details)\n",
    "            details_path = r\"E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\interpolation_details.xlsx\"\n",
    "            details_df.to_excel(details_path, index=False)\n",
    "            print(f\"插值详细信息保存到: {details_path}\")\n",
    "        else:\n",
    "            print(\"警告: 没有插值详细信息可保存\")\n",
    "        \n",
    "        # ========== 7. 统计报告 ==========\n",
    "        print(\"\\n处理完成!\")\n",
    "        print(f\"总记录数: {len(df)}\")\n",
    "        print(f\"插值操作次数: {len(interpolation_details)}\")\n",
    "        \n",
    "        if interpolation_details:\n",
    "            # 显示前3次插值的详细信息\n",
    "            print(\"\\n前3次插值的详细信息:\")\n",
    "            for i, detail in enumerate(interpolation_details[:3]):\n",
    "                print(f\"\\n插值 #{i+1}\")\n",
    "                print(f\"  类型: {detail['type']}\")\n",
    "                print(f\"  目标位置: ({detail['target_lat']:.6f}, {detail['target_lon']:.6f})\")\n",
    "                print(f\"  网格形状: {detail['grid_shape']}\")\n",
    "                \n",
    "                if detail['type'] == 'bilinear':\n",
    "                    print(f\"  使用的4个网格点:\")\n",
    "                    for j in range(4):\n",
    "                        print(f\"    点{j+1}: 行 {detail['rows'][j]}, 列 {detail['cols'][j]} - \" +\n",
    "                              f\"位置 ({detail['lat_values'][j]:.6f}, {detail['lon_values'][j]:.6f}) - \" +\n",
    "                              f\"值: {detail['values'][j]:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  最近邻点: 行 {detail['row']}, 列 {detail['col']} - \" +\n",
    "                          f\"位置 ({detail['lat_values'][0]:.6f}, {detail['lon_values'][0]:.6f}) - \" +\n",
    "                          f\"值: {detail['values'][0]:.6f}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"错误详细信息:\")\n",
    "        print(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "# ========================== 主程序 ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.xlsx\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"开始处理CLASIC07数据插值任务\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"错误: 输入文件不存在 - {input_file}\")\n",
    "        print(f\"请检查路径: {os.path.abspath(input_file)}\")\n",
    "    else:\n",
    "        print(f\"输入文件: {input_file}\")\n",
    "        print(f\"输出将保存到: E:\\\\data\\\\VWC\\\\test-VWC\\\\Insitu CLASIC07\\\\CL07V_SUM_VEG_CLASIC_ML.xlsx\")\n",
    "        \n",
    "        success = process_clasic07_data(input_file)\n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务成功完成!\")\n",
    "            print(\"=\"*30)\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务失败，请检查错误信息\")\n",
    "            print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29dfb1fd-c55c-4411-b0a2-f10778cd845e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载测试数据: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
      "加载完成，总样本数: 22\n",
      "\n",
      "处理 Ku-H 模型: RFR_Ku_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1272, R²: -0.4410\n",
      "\n",
      "处理 Ku-V 模型: RFR_Ku_Vpol_Type1.pkl\n",
      "  有效样本数: 7 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.8424, R²: -101.4697\n",
      "\n",
      "处理 Ku-HV 模型: RFR_Ku_HVpol_Type1.pkl\n",
      "  有效样本数: 7 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.4431, R²: -61.8683\n",
      "\n",
      "处理 C-H 模型: RFR_C_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.4028, R²: -0.8387\n",
      "\n",
      "处理 C-V 模型: RFR_C_Vpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.5623, R²: -1.0909\n",
      "\n",
      "处理 C-HV 模型: RFR_C_HVpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1126, R²: -0.4214\n",
      "\n",
      "处理 X-H 模型: RFR_X_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1898, R²: -0.5271\n",
      "\n",
      "处理 X-V 模型: RFR_X_Vpol_Type1.pkl\n",
      "  有效样本数: 11 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.7433, R²: -3.8789\n",
      "\n",
      "处理 X-HV 模型: RFR_X_HVpol_Type1.pkl\n",
      "  有效样本数: 11 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.5107, R²: -2.6636\n",
      "\n",
      "所有预测结果已保存至: model_predictions_results_CLASIC07.xlsx\n",
      "\n",
      "正在绘制组合散点图...\n",
      "  组合散点图已保存至: figures\\CLASIC07_VWC_Scatter.png\n",
      "\n",
      "所有处理完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# 设置常量\n",
    "TEST_FILE = r\"E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\"\n",
    "MODEL_DIR = \"models\"\n",
    "SAVE_RESULTS = \"model_predictions_results_CLASIC07.xlsx\"\n",
    "FIG_DIR = \"figures\"\n",
    "\n",
    "# 定义波段和极化组合\n",
    "BANDS = ['Ku', 'C', 'X']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 波段颜色定义\n",
    "BAND_COLORS = {\n",
    "    'Ku': (253/255, 173/255, 115/255, 0.7),\n",
    "    'C': (178/255, 125/255, 104/255, 0.7),\n",
    "    'X': (224/255, 104/255, 46/255, 0.7)\n",
    "}\n",
    "\n",
    "# 极化类型标记定义\n",
    "POL_MARKERS = {\n",
    "    'H': 's',  # 方形\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 'o'  # 圆形\n",
    "}\n",
    "\n",
    "def normalize_LAI(lai_series):\n",
    "    \"\"\"对LAI进行归一化\"\"\"\n",
    "    return lai_series.clip(0, 6) / 6\n",
    "\n",
    "def normalize_VOD(vod_series):\n",
    "    \"\"\"对VOD进行归一化\"\"\"\n",
    "    return vod_series.clip(0, 2) / 2\n",
    "\n",
    "# PFT列名映射字典\n",
    "PFT_MAPPING = {\n",
    "    'PFT_grassnat': 'Grass_nat',\n",
    "    'PFT_grassman': 'Grass_man',\n",
    "    'PFT_shrubbd': 'Shrub_bd',\n",
    "    'PFT_shrubbe': 'Shrub_be',\n",
    "    'PFT_shrubnd': 'Shrub_nd',\n",
    "    'PFT_shrubne': 'Shrub_ne',\n",
    "    'PFT_treebd': 'Tree_bd',\n",
    "    'PFT_treebe': 'Tree_be',\n",
    "    'PFT_treend': 'Tree_nd',\n",
    "    'PFT_treene': 'Tree_ne'\n",
    "}\n",
    "\n",
    "def get_model_columns(band, pol):\n",
    "    \"\"\"获取指定模型所需的列名\"\"\"\n",
    "    base_columns = [\n",
    "        'VWC (kg/m²)',  # 实际值\n",
    "        'LAI_Satellite',  # LAI\n",
    "        'SM'  # 土壤湿度\n",
    "    ]\n",
    "    \n",
    "    # 添加所有PFT列\n",
    "    base_columns.extend(PFT_MAPPING.keys())\n",
    "    \n",
    "    # 根据极化类型添加VOD列\n",
    "    if pol == 'H':\n",
    "        return base_columns + [f'{band.lower()}_vod_H']\n",
    "    elif pol == 'V':\n",
    "        return base_columns + [f'{band.lower()}_vod_V']\n",
    "    elif pol == 'HV':\n",
    "        return base_columns + [f'{band.lower()}_vod_H', f'{band.lower()}_vod_V']\n",
    "\n",
    "def get_feature_order(pol):\n",
    "    \"\"\"获取特征列的顺序（模型期望的列顺序）\"\"\"\n",
    "    base_features = [\n",
    "        'LAI', 'SM',\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    if pol in ['H', 'V']:\n",
    "        return ['VOD'] + base_features\n",
    "    elif pol == 'HV':\n",
    "        return ['VOD-Hpol', 'VOD-Vpol'] + base_features\n",
    "\n",
    "def prepare_input_data(df, band, pol):\n",
    "    \"\"\"为指定模型准备输入数据\"\"\"\n",
    "    # 创建数据副本\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 归一化处理\n",
    "    data['LAI'] = normalize_LAI(data['LAI_Satellite'])\n",
    "    \n",
    "    # 2. 处理VOD列\n",
    "    if pol == 'H':\n",
    "        vod_col = f'{band.lower()}_vod_H'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'V':\n",
    "        vod_col = f'{band.lower()}_vod_V'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'HV':\n",
    "        # 重命名列以匹配模型训练时的特征名\n",
    "        data = data.rename(columns={\n",
    "            f'{band.lower()}_vod_H': 'VOD-Hpol',\n",
    "            f'{band.lower()}_vod_V': 'VOD-Vpol'\n",
    "        })\n",
    "        # 归一化处理\n",
    "        data['VOD-Hpol'] = normalize_VOD(data['VOD-Hpol'])\n",
    "        data['VOD-Vpol'] = normalize_VOD(data['VOD-Vpol'])\n",
    "    \n",
    "    # 3. 重命名PFT列为模型期望的名称\n",
    "    data = data.rename(columns=PFT_MAPPING)\n",
    "    \n",
    "    # 4. 按模型要求排序特征列\n",
    "    feature_order = get_feature_order(pol)\n",
    "    \n",
    "    return data[feature_order]\n",
    "\n",
    "def plot_combined_scatter(actual, predictions_dict):\n",
    "    \"\"\"\n",
    "    绘制组合散点图，包含所有波段和极化类型\n",
    "    \n",
    "    参数:\n",
    "    actual -- 实际值 (Series)\n",
    "    predictions_dict -- 字典结构: {\n",
    "        'H': {band: pred_series},\n",
    "        'V': {band: pred_series},\n",
    "        'HV': {band: pred_series}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # 存储所有组合的RMSE值\n",
    "    rmse_values = {}\n",
    "    \n",
    "    # 收集所有数据点\n",
    "    max_val = 0\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            pred_series = predictions_dict[pol].get(band)\n",
    "            \n",
    "            if pred_series is not None and not pred_series.isnull().all():\n",
    "                # 创建实际值和预测值的临时DF\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'actual': actual,\n",
    "                    'pred': pred_series\n",
    "                }).dropna()\n",
    "                \n",
    "                if not temp_df.empty:\n",
    "                    # 计算RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(temp_df['actual'], temp_df['pred']))\n",
    "                    rmse_values[f\"{band}-{pol}\"] = rmse\n",
    "                    \n",
    "                    # 更新最大值\n",
    "                    band_max = max(temp_df['actual'].max(), temp_df['pred'].max())\n",
    "                    if band_max > max_val:\n",
    "                        max_val = band_max\n",
    "                    \n",
    "                    # 绘制散点\n",
    "                    plt.scatter(\n",
    "                        temp_df['actual'], temp_df['pred'], \n",
    "                        alpha=0.7, \n",
    "                        color=BAND_COLORS[band],\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        s=50,\n",
    "                        edgecolors='none',\n",
    "                        zorder=2,\n",
    "                        label=f\"{band}-{pol}\"\n",
    "                    )\n",
    "    \n",
    "    # 如果没有数据可绘制，直接返回\n",
    "    if not rmse_values:\n",
    "        print(\"  警告: 没有有效的预测数据!\")\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val *= 1.05\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围\n",
    "    plt.xlim(0, max_val)\n",
    "    plt.ylim(0, max_val)\n",
    "    \n",
    "    # 设置坐标轴标签\n",
    "    plt.xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('RF VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title('CLASIC07 Insitu VWC', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "    \n",
    "    # # 添加图例\n",
    "    # plt.legend(loc='lower right', frameon=True, fontsize=10, ncol=3)\n",
    "    \n",
    "    # 添加RMSE文本（左上角，3×3网格布局）\n",
    "    if rmse_values:\n",
    "        # 设置文本位置\n",
    "        x_pos = 0.05\n",
    "        y_pos = 0.95\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.text(x_pos, y_pos, 'RMSE (kg/m²):', \n",
    "                 transform=ax.transAxes,\n",
    "                 fontsize=12,\n",
    "                 fontweight='bold',\n",
    "                 verticalalignment='top')\n",
    "        \n",
    "        y_pos -= 0.05\n",
    "        \n",
    "        # 遍历每个波段\n",
    "        for band_idx, band in enumerate(BANDS):\n",
    "            # 遍历每个极化类型\n",
    "            for pol_idx, pol in enumerate(POLS):\n",
    "                # 计算位置\n",
    "                text_x = x_pos + pol_idx * 0.15\n",
    "                text_y = y_pos - band_idx * 0.08\n",
    "                \n",
    "                # 获取RMSE值\n",
    "                rmse = rmse_values.get(f\"{band}-{pol}\", None)\n",
    "                \n",
    "                if rmse is not None:\n",
    "                    # 绘制标记\n",
    "                    plt.scatter(\n",
    "                        text_x, text_y, \n",
    "                        transform=ax.transAxes,\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        color=BAND_COLORS[band],\n",
    "                        s=80,\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                    \n",
    "                    # 添加文本\n",
    "                    plt.text(\n",
    "                        text_x + 0.01, text_y, \n",
    "                        f\"{band}-{pol}: {rmse:.3f}\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center'\n",
    "                    )\n",
    "                else:\n",
    "                    # 添加缺失值标记\n",
    "                    plt.text(\n",
    "                        text_x, text_y, \n",
    "                        f\"{band}-{pol}: N/A\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center',\n",
    "                        color='gray'\n",
    "                    )\n",
    "    \n",
    "    # 添加网格线\n",
    "    plt.grid(True, linestyle='--', alpha=0.3, zorder=0)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(FIG_DIR, exist_ok=True)\n",
    "    \n",
    "    # 保存图像\n",
    "    fig_path = os.path.join(FIG_DIR, 'CLASIC07_VWC_Scatter.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  组合散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def predict_and_evaluate():\n",
    "    \"\"\"主函数：加载所有模型进行预测并评估结果\"\"\"\n",
    "    # 1. 加载测试数据\n",
    "    print(f\"正在加载测试数据: {TEST_FILE}\")\n",
    "    \n",
    "    # 收集所有可能的列\n",
    "    all_columns = set(['VWC (kg/m²)', 'LAI_Satellite', 'SM'])\n",
    "    # 添加所有PFT列\n",
    "    all_columns.update(PFT_MAPPING.keys())\n",
    "    # 添加所有VOD列\n",
    "    for band in BANDS:\n",
    "        all_columns.add(f'{band.lower()}_vod_H')\n",
    "        all_columns.add(f'{band.lower()}_vod_V')\n",
    "    \n",
    "    # 读取Excel文件\n",
    "    test_df = pd.read_excel(TEST_FILE, usecols=list(all_columns))\n",
    "    print(f\"加载完成，总样本数: {len(test_df)}\")\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    results = pd.DataFrame(index=test_df.index)\n",
    "    results['Actual_VWC'] = test_df['VWC (kg/m²)']\n",
    "    \n",
    "    # 为每个极化类型存储预测结果\n",
    "    predictions_by_pol = {\n",
    "        'H': {band: None for band in BANDS},\n",
    "        'V': {band: None for band in BANDS},\n",
    "        'HV': {band: None for band in BANDS}\n",
    "    }\n",
    "    \n",
    "    # 2. 对每个模型进行预测\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            model_name = f\"RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "            model_path = os.path.join(MODEL_DIR, model_name)\n",
    "            \n",
    "            print(f\"\\n处理 {band}-{pol} 模型: {model_name}\")\n",
    "            \n",
    "            # 准备输入数据\n",
    "            model_cols = get_model_columns(band, pol)\n",
    "            model_data = test_df[model_cols].copy()\n",
    "            \n",
    "            # 删除缺失值\n",
    "            clean_data = model_data.dropna()\n",
    "            print(f\"  有效样本数: {len(clean_data)} (删除缺失值后)\")\n",
    "            \n",
    "            if len(clean_data) == 0:\n",
    "                print(\"  警告: 无有效样本可用于此模型!\")\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "                continue\n",
    "            \n",
    "            # 预处理输入数据\n",
    "            try:\n",
    "                X_input = prepare_input_data(clean_data, band, pol)\n",
    "                \n",
    "                # 加载模型并进行预测\n",
    "                if os.path.exists(model_path):\n",
    "                    model = joblib.load(model_path)\n",
    "                    predictions = model.predict(X_input)\n",
    "                    \n",
    "                    # 存储预测结果\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    results.loc[clean_data.index, f\"{band}_{pol}_Predicted\"] = predictions\n",
    "                    \n",
    "                    # 存储到对应极化类型的字典\n",
    "                    predictions_by_pol[pol][band] = results[f\"{band}_{pol}_Predicted\"].copy()\n",
    "                    \n",
    "                    # 计算评估指标\n",
    "                    actual = clean_data['VWC (kg/m²)']\n",
    "                    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "                    r2 = r2_score(actual, predictions)\n",
    "                    print(f\"  预测完成 - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  警告: 未找到模型文件 {model_path}!\")\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    predictions_by_pol[pol][band] = None\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"  预测失败: {str(e)}\")\n",
    "                # 打印更详细的错误信息\n",
    "                traceback.print_exc()\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "    \n",
    "    # 3. 保存结果\n",
    "    results.to_excel(SAVE_RESULTS)\n",
    "    print(f\"\\n所有预测结果已保存至: {SAVE_RESULTS}\")\n",
    "    \n",
    "    # 4. 绘制组合散点图\n",
    "    print(\"\\n正在绘制组合散点图...\")\n",
    "    plot_combined_scatter(\n",
    "        results['Actual_VWC'], \n",
    "        predictions_by_pol\n",
    "    )\n",
    "    \n",
    "    return results, predictions_by_pol\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    results, predictions_by_pol = predict_and_evaluate()\n",
    "    print(\"\\n所有处理完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14087c55-c058-412b-837a-27b664e3efe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载测试数据: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
      "加载完成，总样本数: 22\n",
      "\n",
      "处理 Ku-H 模型: RFR_Ku_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1272, R²: -0.4410\n",
      "\n",
      "处理 Ku-V 模型: RFR_Ku_Vpol_Type1.pkl\n",
      "  有效样本数: 7 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.8424, R²: -101.4697\n",
      "\n",
      "处理 Ku-HV 模型: RFR_Ku_HVpol_Type1.pkl\n",
      "  有效样本数: 7 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.4431, R²: -61.8683\n",
      "\n",
      "处理 C-H 模型: RFR_C_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.4028, R²: -0.8387\n",
      "\n",
      "处理 C-V 模型: RFR_C_Vpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.5623, R²: -1.0909\n",
      "\n",
      "处理 C-HV 模型: RFR_C_HVpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1126, R²: -0.4214\n",
      "\n",
      "处理 X-H 模型: RFR_X_Hpol_Type1.pkl\n",
      "  有效样本数: 17 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.1898, R²: -0.5271\n",
      "\n",
      "处理 X-V 模型: RFR_X_Vpol_Type1.pkl\n",
      "  有效样本数: 11 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.7433, R²: -3.8789\n",
      "\n",
      "处理 X-HV 模型: RFR_X_HVpol_Type1.pkl\n",
      "  有效样本数: 11 (删除缺失值后)\n",
      "  预测完成 - RMSE: 1.5107, R²: -2.6636\n",
      "\n",
      "所有预测结果已保存至: model_predictions_results.xlsx\n",
      "\n",
      "正在绘制分组箱线图...\n",
      "  分组散点图已保存至: figures\\CLASIC07_VWC_GroupedScatter.png\n",
      "\n",
      "所有处理完成!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39497d31-93fa-48c6-bb31-ad38a24e5f68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.SMAPVEX08 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63258d63-a5f9-4d68-954f-51f7248759f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始转换 FST 到 TIFF (GDAL-only方法)\n",
      "输入文件: E:\\data\\VWC\\test-VWC\\SMEX08\\SV08VWC_vwc.fst\n",
      "输出文件: E:\\data\\VWC\\test-VWC\\SMEX08\\SV08VWC_vwc_gdal.tif\n",
      "文件信息:\n",
      "  尺寸: 8885×7956像素\n",
      "  波段数: 1\n",
      "  数据类型: 4\n",
      "  交错方式: bsq\n",
      "  总像素数: 70,689,060\n",
      "  总字节数: 282,756,240\n",
      "  每个像素大小: 4字节\n",
      "  处理进度: 1/7956行 (0.0%)\n",
      "  处理进度: 101/7956行 (1.3%)\n",
      "  处理进度: 201/7956行 (2.5%)\n",
      "  处理进度: 301/7956行 (3.8%)\n",
      "  处理进度: 401/7956行 (5.0%)\n",
      "  处理进度: 501/7956行 (6.3%)\n",
      "  处理进度: 601/7956行 (7.6%)\n",
      "  处理进度: 701/7956行 (8.8%)\n",
      "  处理进度: 801/7956行 (10.1%)\n",
      "  处理进度: 901/7956行 (11.3%)\n",
      "  处理进度: 1001/7956行 (12.6%)\n",
      "  处理进度: 1101/7956行 (13.8%)\n",
      "  处理进度: 1201/7956行 (15.1%)\n",
      "  处理进度: 1301/7956行 (16.4%)\n",
      "  处理进度: 1401/7956行 (17.6%)\n",
      "  处理进度: 1501/7956行 (18.9%)\n",
      "  处理进度: 1601/7956行 (20.1%)\n",
      "  处理进度: 1701/7956行 (21.4%)\n",
      "  处理进度: 1801/7956行 (22.6%)\n",
      "  处理进度: 1901/7956行 (23.9%)\n",
      "  处理进度: 2001/7956行 (25.2%)\n",
      "  处理进度: 2101/7956行 (26.4%)\n",
      "  处理进度: 2201/7956行 (27.7%)\n",
      "  处理进度: 2301/7956行 (28.9%)\n",
      "  处理进度: 2401/7956行 (30.2%)\n",
      "  处理进度: 2501/7956行 (31.4%)\n",
      "  处理进度: 2601/7956行 (32.7%)\n",
      "  处理进度: 2701/7956行 (33.9%)\n",
      "  处理进度: 2801/7956行 (35.2%)\n",
      "  处理进度: 2901/7956行 (36.5%)\n",
      "  处理进度: 3001/7956行 (37.7%)\n",
      "  处理进度: 3101/7956行 (39.0%)\n",
      "  处理进度: 3201/7956行 (40.2%)\n",
      "  处理进度: 3301/7956行 (41.5%)\n",
      "  处理进度: 3401/7956行 (42.7%)\n",
      "  处理进度: 3501/7956行 (44.0%)\n",
      "  处理进度: 3601/7956行 (45.3%)\n",
      "  处理进度: 3701/7956行 (46.5%)\n",
      "  处理进度: 3801/7956行 (47.8%)\n",
      "  处理进度: 3901/7956行 (49.0%)\n",
      "  处理进度: 4001/7956行 (50.3%)\n",
      "  处理进度: 4101/7956行 (51.5%)\n",
      "  处理进度: 4201/7956行 (52.8%)\n",
      "  处理进度: 4301/7956行 (54.1%)\n",
      "  处理进度: 4401/7956行 (55.3%)\n",
      "  处理进度: 4501/7956行 (56.6%)\n",
      "  处理进度: 4601/7956行 (57.8%)\n",
      "  处理进度: 4701/7956行 (59.1%)\n",
      "  处理进度: 4801/7956行 (60.3%)\n",
      "  处理进度: 4901/7956行 (61.6%)\n",
      "  处理进度: 5001/7956行 (62.9%)\n",
      "  处理进度: 5101/7956行 (64.1%)\n",
      "  处理进度: 5201/7956行 (65.4%)\n",
      "  处理进度: 5301/7956行 (66.6%)\n",
      "  处理进度: 5401/7956行 (67.9%)\n",
      "  处理进度: 5501/7956行 (69.1%)\n",
      "  处理进度: 5601/7956行 (70.4%)\n",
      "  处理进度: 5701/7956行 (71.7%)\n",
      "  处理进度: 5801/7956行 (72.9%)\n",
      "  处理进度: 5901/7956行 (74.2%)\n",
      "  处理进度: 6001/7956行 (75.4%)\n",
      "  处理进度: 6101/7956行 (76.7%)\n",
      "  处理进度: 6201/7956行 (77.9%)\n",
      "  处理进度: 6301/7956行 (79.2%)\n",
      "  处理进度: 6401/7956行 (80.5%)\n",
      "  处理进度: 6501/7956行 (81.7%)\n",
      "  处理进度: 6601/7956行 (83.0%)\n",
      "  处理进度: 6701/7956行 (84.2%)\n",
      "  处理进度: 6801/7956行 (85.5%)\n",
      "  处理进度: 6901/7956行 (86.7%)\n",
      "  处理进度: 7001/7956行 (88.0%)\n",
      "  处理进度: 7101/7956行 (89.3%)\n",
      "  处理进度: 7201/7956行 (90.5%)\n",
      "  处理进度: 7301/7956行 (91.8%)\n",
      "  处理进度: 7401/7956行 (93.0%)\n",
      "  处理进度: 7501/7956行 (94.3%)\n",
      "  处理进度: 7601/7956行 (95.5%)\n",
      "  处理进度: 7701/7956行 (96.8%)\n",
      "  处理进度: 7801/7956行 (98.1%)\n",
      "  处理进度: 7901/7956行 (99.3%)\n",
      "成功创建: E:\\data\\VWC\\test-VWC\\SMEX08\\SV08VWC_vwc_gdal.tif\n",
      "\n",
      "转换成功完成!\n",
      "请检查输出文件: E:\\data\\VWC\\test-VWC\\SMEX08\\SV08VWC_vwc_gdal.tif\n",
      "\n",
      "输出文件验证:\n",
      "  尺寸: 8885x7956\n",
      "  波段数: 1\n",
      "  数据类型: Float32\n",
      "  第一行前10个值: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# SMEX08 VWC Map数据数据处理为tif文件\n",
    "import os\n",
    "import struct\n",
    "import array\n",
    "from osgeo import gdal, osr\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_envi_header(header_path):\n",
    "    \"\"\"解析 ENVI 头文件 (.hdr)\"\"\"\n",
    "    params = {}\n",
    "    try:\n",
    "        with open(header_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or line.startswith(';'):\n",
    "                    continue\n",
    "                \n",
    "                if '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    key = key.strip()\n",
    "                    value = value.strip()\n",
    "                    \n",
    "                    # 处理特殊字符\n",
    "                    if '{' in value and '}' in value:\n",
    "                        value = value.split('{')[1].split('}')[0].strip()\n",
    "                    \n",
    "                    # 解析数值\n",
    "                    if value.replace('.', '', 1).replace('-', '', 1).isdigit():\n",
    "                        if '.' in value:\n",
    "                            value = float(value)\n",
    "                        else:\n",
    "                            value = int(value)\n",
    "                    \n",
    "                    params[key] = value\n",
    "    except Exception as e:\n",
    "        print(f\"头文件解析错误: {str(e)}\")\n",
    "    \n",
    "    return {\n",
    "        'samples': params.get('samples', 8885),\n",
    "        'lines': params.get('lines', 7956),\n",
    "        'bands': params.get('bands', 1),\n",
    "        'data_type': params.get('data type', 4),  # float32\n",
    "        'byte_order': params.get('byte order', 0),  # 小端\n",
    "        'header_offset': params.get('header offset', 0),\n",
    "        'interleave': params.get('interleave', 'bsq'),\n",
    "        'map_info': params.get('map info', None)\n",
    "    }\n",
    "\n",
    "def get_gdal_type(data_type):\n",
    "    \"\"\"映射ENVI数据类型到GDAL类型\"\"\"\n",
    "    type_map = {\n",
    "        1: gdal.GDT_Byte,     # byte\n",
    "        2: gdal.GDT_Int16,    # int16\n",
    "        3: gdal.GDT_Int32,    # int32\n",
    "        4: gdal.GDT_Float32,  # float32\n",
    "        5: gdal.GDT_Float64,  # float64\n",
    "        12: gdal.GDT_UInt16,  # uint16\n",
    "        13: gdal.GDT_UInt32   # uint32\n",
    "    }\n",
    "    return type_map.get(data_type, gdal.GDT_Float32)\n",
    "\n",
    "def get_data_size(data_type):\n",
    "    \"\"\"获取每种数据类型的字节大小\"\"\"\n",
    "    size_map = {\n",
    "        1: 1,  # byte\n",
    "        2: 2,  # int16\n",
    "        3: 4,  # int32\n",
    "        4: 4,  # float32\n",
    "        5: 8,  # float64\n",
    "        12: 2, # uint16\n",
    "        13: 4  # uint32\n",
    "    }\n",
    "    return size_map.get(data_type, 4)\n",
    "\n",
    "def get_struct_format(byte_order, data_type):\n",
    "    \"\"\"生成struct格式字符串\"\"\"\n",
    "    endian_char = '<' if byte_order == 0 else '>'  # <小端 >大端\n",
    "    \n",
    "    type_char_map = {\n",
    "        1: 'B',  # 无符号字节\n",
    "        2: 'h',  # 短整型\n",
    "        3: 'i',  # 整型\n",
    "        4: 'f',  # 浮点数\n",
    "        5: 'd',  # 双精度\n",
    "        12: 'H', # 无符号短整型\n",
    "        13: 'I'  # 无符号整型\n",
    "    }\n",
    "    \n",
    "    return endian_char + type_char_map.get(data_type, 'f')\n",
    "\n",
    "def fst_to_tif_no_numpy(input_fst_path, output_tif_path):\n",
    "    \"\"\"不使用NumPy转换ENVI FST文件为GeoTIFF\"\"\"\n",
    "    # 获取相关文件路径\n",
    "    input_dir = os.path.dirname(input_fst_path)\n",
    "    input_name = os.path.splitext(os.path.basename(input_fst_path))[0]\n",
    "    \n",
    "    header_path = os.path.join(input_dir, f\"{input_name}.hdr\")\n",
    "    xml_path = os.path.join(input_dir, f\"{input_name}.xml\")\n",
    "    \n",
    "    # 解析头文件\n",
    "    header_info = parse_envi_header(header_path)\n",
    "    \n",
    "    # 提取关键参数\n",
    "    samples = header_info['samples']\n",
    "    lines = header_info['lines']\n",
    "    bands = header_info['bands']\n",
    "    data_type = header_info['data_type']\n",
    "    byte_order = header_info['byte_order']\n",
    "    header_offset = header_info['header_offset']\n",
    "    interleave = header_info['interleave'].lower()\n",
    "    \n",
    "    # 计算数据大小\n",
    "    data_size = get_data_size(data_type)\n",
    "    total_pixels = samples * lines * bands\n",
    "    total_bytes = total_pixels * data_size\n",
    "    \n",
    "    print(f\"文件信息:\")\n",
    "    print(f\"  尺寸: {samples}×{lines}像素\")\n",
    "    print(f\"  波段数: {bands}\")\n",
    "    print(f\"  数据类型: {data_type}\")\n",
    "    print(f\"  交错方式: {interleave}\")\n",
    "    print(f\"  总像素数: {total_pixels:,}\")\n",
    "    print(f\"  总字节数: {total_bytes:,}\")\n",
    "    \n",
    "    # 创建GDAL驱动\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    gdal_type = get_gdal_type(data_type)\n",
    "    ds = driver.Create(\n",
    "        output_tif_path,\n",
    "        samples,\n",
    "        lines,\n",
    "        bands,\n",
    "        gdal_type\n",
    "    )\n",
    "    \n",
    "    if ds is None:\n",
    "        print(f\"无法创建输出文件: {output_tif_path}\")\n",
    "        return False\n",
    "    \n",
    "    # 设置地理变换\n",
    "    x_min = 375325.0\n",
    "    y_max = 4361460.0\n",
    "    pixel_width = 10.0\n",
    "    pixel_height = -10.0  # 负值因为Y轴从北向南\n",
    "    transform = (x_min, pixel_width, 0, y_max, 0, pixel_height)\n",
    "    ds.SetGeoTransform(transform)\n",
    "    \n",
    "    # 设置投影\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(32618)  # UTM zone 18N, WGS84\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "    \n",
    "    # 准备读取数据\n",
    "    struct_format = get_struct_format(byte_order, data_type)\n",
    "    pixel_size = struct.calcsize(struct_format)\n",
    "    print(f\"  每个像素大小: {pixel_size}字节\")\n",
    "    \n",
    "    # 打开FST文件\n",
    "    with open(input_fst_path, 'rb') as f:\n",
    "        # 跳过头部偏移\n",
    "        f.seek(header_offset)\n",
    "        \n",
    "        # 逐行读取数据\n",
    "        for line_idx in range(lines):\n",
    "            if line_idx % 100 == 0:\n",
    "                print(f\"  处理进度: {line_idx+1}/{lines}行 ({((line_idx+1)/lines)*100:.1f}%)\")\n",
    "            \n",
    "            # 根据交错格式读取数据\n",
    "            band_data = {}\n",
    "            \n",
    "            if interleave == 'bsq':\n",
    "                # 对每个波段顺序读取整行\n",
    "                for band in range(bands):\n",
    "                    # 读取整行数据\n",
    "                    line_bytes = f.read(samples * data_size)\n",
    "                    \n",
    "                    if len(line_bytes) != samples * data_size:\n",
    "                        print(f\"错误: 行数据不完整 (预期 {samples*data_size}字节, 实际 {len(line_bytes)}字节)\")\n",
    "                        return False\n",
    "                    \n",
    "                    band_data[band] = line_bytes\n",
    "            \n",
    "            elif interleave == 'bil':\n",
    "                # 整行包含所有波段\n",
    "                line_bytes = f.read(samples * bands * data_size)\n",
    "                \n",
    "                if len(line_bytes) != samples * bands * data_size:\n",
    "                    print(f\"错误: 行数据不完整 (预期 {samples*bands*data_size}字节, 实际 {len(line_bytes)}字节)\")\n",
    "                    return False\n",
    "                \n",
    "                # 分割到各波段\n",
    "                for band in range(bands):\n",
    "                    band_bytes = bytearray()\n",
    "                    for sample in range(samples):\n",
    "                        # 提取当前像素在当前波段的数据\n",
    "                        start = (sample * bands + band) * data_size\n",
    "                        end = start + data_size\n",
    "                        band_bytes.extend(line_bytes[start:end])\n",
    "                    band_data[band] = bytes(band_bytes)\n",
    "            \n",
    "            elif interleave == 'bip':\n",
    "                # 逐像素读取\n",
    "                line_bytes = f.read(samples * bands * data_size)\n",
    "                \n",
    "                if len(line_bytes) != samples * bands * data_size:\n",
    "                    print(f\"错误: 行数据不完整 (预期 {samples*bands*data_size}字节, 实际 {len(line_bytes)}字节)\")\n",
    "                    return False\n",
    "                \n",
    "                # 分割到各波段\n",
    "                for band in range(bands):\n",
    "                    band_bytes = bytearray()\n",
    "                    for sample in range(samples):\n",
    "                        # 提取当前像素在当前波段的数据\n",
    "                        start = (sample * bands + band) * data_size\n",
    "                        end = start + data_size\n",
    "                        band_bytes.extend(line_bytes[start:end])\n",
    "                    band_data[band] = bytes(band_bytes)\n",
    "            \n",
    "            else:\n",
    "                print(f\"错误: 不支持的interleave类型: {interleave}\")\n",
    "                return False\n",
    "            \n",
    "            # 写入GDAL\n",
    "            for band_idx, data_bytes in band_data.items():\n",
    "                band = ds.GetRasterBand(band_idx + 1)\n",
    "                band.WriteRaster(0, line_idx, samples, 1, data_bytes)\n",
    "    \n",
    "    # 设置元数据\n",
    "    for band_idx in range(bands):\n",
    "        band = ds.GetRasterBand(band_idx + 1)\n",
    "        band.SetDescription(f\"Band {band_idx+1}\")\n",
    "        band.SetMetadataItem(\"DESCRIPTION\", \"Soil Volumetric Water Content\")\n",
    "        band.SetNoDataValue(0.0)\n",
    "    \n",
    "    # 添加全局元数据\n",
    "    ds.SetMetadata({\n",
    "        \"Source_File\": os.path.basename(input_fst_path),\n",
    "        \"Rows\": str(lines),\n",
    "        \"Columns\": str(samples),\n",
    "        \"Bands\": str(bands),\n",
    "        \"Data_Type\": str(data_type),\n",
    "        \"Processed_By\": \"GDAL-only FST Converter\"\n",
    "    })\n",
    "    \n",
    "    # 清理\n",
    "    ds.FlushCache()\n",
    "    ds = None\n",
    "    \n",
    "    print(f\"成功创建: {output_tif_path}\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入和输出路径\n",
    "    input_dir = r\"E:\\data\\VWC\\test-VWC\\SMEX08\"\n",
    "    fst_file = \"SV08VWC_vwc.fst\"\n",
    "    input_path = os.path.join(input_dir, fst_file)\n",
    "    output_path = os.path.join(input_dir, fst_file.replace('.fst', '_gdal.tif'))\n",
    "    \n",
    "    print(f\"开始转换 FST 到 TIFF (GDAL-only方法)\")\n",
    "    print(f\"输入文件: {input_path}\")\n",
    "    print(f\"输出文件: {output_path}\")\n",
    "    \n",
    "    # 确保文件存在\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"错误: 输入文件不存在 - {input_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 检查头文件\n",
    "    header_path = input_path.replace('.fst', '.hdr')\n",
    "    if not os.path.exists(header_path):\n",
    "        print(f\"错误: ENVI头文件不存在 - {header_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 转换文件\n",
    "    success = fst_to_tif_no_numpy(input_path, output_path)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n转换成功完成!\")\n",
    "        print(f\"请检查输出文件: {output_path}\")\n",
    "        \n",
    "        # 验证结果\n",
    "        if os.path.exists(output_path):\n",
    "            print(\"\\n输出文件验证:\")\n",
    "            try:\n",
    "                ds = gdal.Open(output_path)\n",
    "                if ds:\n",
    "                    print(f\"  尺寸: {ds.RasterXSize}x{ds.RasterYSize}\")\n",
    "                    print(f\"  波段数: {ds.RasterCount}\")\n",
    "                    print(f\"  数据类型: {gdal.GetDataTypeName(ds.GetRasterBand(1).DataType)}\")\n",
    "                    \n",
    "                    # 简单数据采样\n",
    "                    band = ds.GetRasterBand(1)\n",
    "                    scanline = band.ReadRaster(0, 0, min(10, ds.RasterXSize), 1)\n",
    "                    values = struct.unpack('f' * min(10, ds.RasterXSize), scanline)\n",
    "                    print(f\"  第一行前10个值: {values}\")\n",
    "                    \n",
    "                    ds = None\n",
    "                else:\n",
    "                    print(\"  警告: 无法打开输出文件进行验证\")\n",
    "            except Exception as e:\n",
    "                print(f\"  验证时出错: {str(e)}\")\n",
    "        else:\n",
    "            print(\"  错误: 输出文件未创建\")\n",
    "    else:\n",
    "        print(\"转换过程中出现错误\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045f4780-d48c-47bd-8913-2e1e56d99354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "开始处理SMAPVEX数据插值任务\n",
      "============================================================\n",
      "输入文件: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_Sum_VEG_SMAPVEX.xlsx\n",
      "输出将保存到: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\n",
      "读取原始Excel文件: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_Sum_VEG_SMAPVEX.xlsx\n",
      "成功读取 10 条记录\n",
      "\n",
      "处理PFT数据: E:\\data\\ESACCI PFT\\Resample\\Data\\2008.mat\n",
      "  文件中可用的PFT变量: water, bare, snowice, built, grassnat, grassman, shrubbd, shrubbe, shrubnd, shrubne, treebd, treebe, treend, treene\n",
      "  已添加列: PFT_water\n",
      "  已添加列: PFT_bare\n",
      "  已添加列: PFT_snowice\n",
      "  已添加列: PFT_built\n",
      "  已添加列: PFT_grassnat\n",
      "  已添加列: PFT_grassman\n",
      "  已添加列: PFT_shrubbd\n",
      "  已添加列: PFT_shrubbe\n",
      "  已添加列: PFT_shrubnd\n",
      "  已添加列: PFT_shrubne\n",
      "  已添加列: PFT_treebd\n",
      "  已添加列: PFT_treebe\n",
      "  已添加列: PFT_treend\n",
      "  已添加列: PFT_treene\n",
      "\n",
      "处理VOD数据:\n",
      "  处理日期: 20081002, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20081002_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20081004, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20081004_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20081006, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20081006_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20081007, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20081007_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "\n",
      "处理LAI卫星数据...\n",
      "  加载9月LAI数据 (视为9月15日): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2008-09-01.tif.mat\n",
      "    读取的数据形状: (1800, 3600)\n",
      "  加载10月LAI数据 (视为10月15日): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2008-10-01.tif.mat\n",
      "    读取的数据形状: (1800, 3600)\n",
      "  已处理日期: 2008-10-02, 权重: 0.57, 平均LAI: 1.0333\n",
      "  已处理日期: 2008-10-04, 权重: 0.63, 平均LAI: 1.0197\n",
      "  已处理日期: 2008-10-06, 权重: 0.70, 平均LAI: 1.0061\n",
      "  已处理日期: 2008-10-07, 权重: 0.73, 平均LAI: 0.9993\n",
      "\n",
      "处理植被高度数据...\n",
      "  加载植被高度数据: E:\\data\\CanopyHeight\\CH.mat\n",
      "  已添加植被高度列，数据形状: (1800, 3600)\n",
      "\n",
      "保存结果到: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\n",
      "插值详细信息保存到: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\interpolation_details.xlsx\n",
      "\n",
      "处理完成!\n",
      "总记录数: 10\n",
      "插值操作次数: 230\n",
      "\n",
      "前3次插值的详细信息:\n",
      "\n",
      "插值 #1\n",
      "  类型: bilinear\n",
      "  目标位置: (38.992080, -75.940920)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 509, 列 1040 - 位置 (39.050000, -75.950000) - 值: 0.000000\n",
      "    点2: 行 509, 列 1041 - 位置 (39.050000, -75.850000) - 值: 0.001327\n",
      "    点3: 行 510, 列 1040 - 位置 (38.950000, -75.950000) - 值: 0.001991\n",
      "    点4: 行 510, 列 1041 - 位置 (38.950000, -75.850000) - 值: 0.002816\n",
      "\n",
      "插值 #2\n",
      "  类型: bilinear\n",
      "  目标位置: (39.019230, -76.003620)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 509, 列 1039 - 位置 (39.050000, -76.050000) - 值: 0.019552\n",
      "    点2: 行 509, 列 1040 - 位置 (39.050000, -75.950000) - 值: 0.000000\n",
      "    点3: 行 510, 列 1039 - 位置 (38.950000, -76.050000) - 值: 0.000000\n",
      "    点4: 行 510, 列 1040 - 位置 (38.950000, -75.950000) - 值: 0.001991\n",
      "\n",
      "插值 #3\n",
      "  类型: bilinear\n",
      "  目标位置: (38.985470, -75.967110)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 509, 列 1039 - 位置 (39.050000, -76.050000) - 值: 0.019552\n",
      "    点2: 行 509, 列 1040 - 位置 (39.050000, -75.950000) - 值: 0.000000\n",
      "    点3: 行 510, 列 1039 - 位置 (38.950000, -76.050000) - 值: 0.000000\n",
      "    点4: 行 510, 列 1040 - 位置 (38.950000, -75.950000) - 值: 0.001991\n",
      "\n",
      "==============================\n",
      "任务成功完成!\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 数据填充以收集自变量\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 全局变量记录插值详细信息\n",
    "interpolation_details = []\n",
    "\n",
    "# ====================== 改进的MAT文件读取函数 ======================\n",
    "def read_hdf5_mat(file_path, expected_keys=None):\n",
    "    \"\"\"读取MATLAB v7.3格式的HDF5文件，优先查找特定变量\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = {}\n",
    "            \n",
    "            def visitor_func(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    if h5py.check_string_dtype(obj.dtype):\n",
    "                        value = ''.join(chr(c) for c in obj[:])\n",
    "                    else:\n",
    "                        value = np.array(obj)\n",
    "                    if value.ndim >= 2:\n",
    "                        value = value.T\n",
    "                    base_name = name.split('/')[-1]\n",
    "                    data[base_name] = value\n",
    "            \n",
    "            f.visititems(visitor_func)\n",
    "            \n",
    "            # 优先查找预期变量\n",
    "            if expected_keys:\n",
    "                for key in expected_keys:\n",
    "                    if key in data:\n",
    "                        return {key: data[key]}\n",
    "            \n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"  读取HDF5 MAT文件失败: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# ====================== 改进的双线性插值函数 ======================\n",
    "def bilinear_interpolation_with_details(lat_grid, lon_grid, target_lat, target_lon, grid_data):\n",
    "    \"\"\"\n",
    "    执行双线性插值并记录详细信息\n",
    "    :param lat_grid: 网格纬度数组 (1D, 从北向南递减)\n",
    "    :param lon_grid: 网格经度数组 (1D, 从西向东递增)\n",
    "    :param target_lat: 目标点纬度\n",
    "    :param target_lon: 目标点经度\n",
    "    :param grid_data: 网格数据 (2D数组, 形状为(len(lat_grid), len(lon_grid)))\n",
    "    :return: 插值值\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        # 记录网格形状\n",
    "        grid_shape = grid_data.shape\n",
    "        \n",
    "        # 验证网格尺寸\n",
    "        if len(lat_grid) != grid_shape[0] or len(lon_grid) != grid_shape[1]:\n",
    "            print(f\"警告: 网格尺寸不匹配! 纬度网格: {len(lat_grid)}, 经度网格: {len(lon_grid)}, 数据形状: {grid_shape}\")\n",
    "            return np.nan\n",
    "        \n",
    "        # 查找最近的纬度索引（纬度从北向南递减）\n",
    "        # 纬度网格: 89.95 (北) -> -89.95 (南)\n",
    "        lat_idx = np.argmin(np.abs(lat_grid - target_lat))\n",
    "        \n",
    "        # 查找最近的经度索引（经度从西向东递增）\n",
    "        # 经度网格: -179.95 (西) -> 179.95 (东)\n",
    "        lon_idx = np.argmin(np.abs(lon_grid - target_lon))\n",
    "        \n",
    "        # 确定四个角点索引\n",
    "        # 纬度处理：目标点位于两个纬度网格点之间\n",
    "        if lat_idx == 0:\n",
    "            lat_idx0, lat_idx1 = 0, 1\n",
    "        elif lat_idx == len(lat_grid) - 1:\n",
    "            lat_idx0, lat_idx1 = len(lat_grid) - 2, len(lat_grid) - 1\n",
    "        else:\n",
    "            if target_lat > lat_grid[lat_idx]:\n",
    "                # 目标纬度大于当前网格点纬度（更北）\n",
    "                if lat_idx > 0:\n",
    "                    lat_idx0 = lat_idx - 1\n",
    "                    lat_idx1 = lat_idx\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "            else:\n",
    "                # 目标纬度小于当前网格点纬度（更南）\n",
    "                if lat_idx < len(lat_grid) - 1:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx + 1\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "        \n",
    "        # 经度处理：目标点位于两个经度网格点之间\n",
    "        if lon_idx == 0:\n",
    "            lon_idx0, lon_idx1 = 0, 1\n",
    "        elif lon_idx == len(lon_grid) - 1:\n",
    "            lon_idx0, lon_idx1 = len(lon_grid) - 2, len(lon_grid) - 1\n",
    "        else:\n",
    "            if target_lon > lon_grid[lon_idx]:\n",
    "                # 目标经度大于当前网格点经度（更东）\n",
    "                if lon_idx < len(lon_grid) - 1:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx + 1\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "            else:\n",
    "                # 目标经度小于当前网格点经度（更西）\n",
    "                if lon_idx > 0:\n",
    "                    lon_idx0 = lon_idx - 1\n",
    "                    lon_idx1 = lon_idx\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "        \n",
    "        # 获取四个角点值\n",
    "        Q00 = grid_data[lat_idx0, lon_idx0]\n",
    "        Q01 = grid_data[lat_idx0, lon_idx1]\n",
    "        Q10 = grid_data[lat_idx1, lon_idx0]\n",
    "        Q11 = grid_data[lat_idx1, lon_idx1]\n",
    "        \n",
    "        # 四个角点坐标\n",
    "        y0 = lat_grid[lat_idx0]\n",
    "        y1 = lat_grid[lat_idx1]\n",
    "        x0 = lon_grid[lon_idx0]\n",
    "        x1 = lon_grid[lon_idx1]\n",
    "        \n",
    "        # 如果有NaN，使用最接近的点\n",
    "        if np.isnan(Q00) or np.isnan(Q01) or np.isnan(Q10) or np.isnan(Q11):\n",
    "            result = grid_data[lat_idx, lon_idx]\n",
    "            details = {\n",
    "                'type': 'nearest',\n",
    "                'row': lat_idx,\n",
    "                'col': lon_idx,\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [grid_data[lat_idx, lon_idx]],\n",
    "                'lat_values': [lat_grid[lat_idx]],\n",
    "                'lon_values': [lon_grid[lon_idx]]\n",
    "            }\n",
    "        else:\n",
    "            # 双线性插值公式\n",
    "            dx = (target_lon - x0) / (x1 - x0) if (x1 - x0) != 0 else 0\n",
    "            dy = (target_lat - y0) / (y1 - y0) if (y1 - y0) != 0 else 0\n",
    "            result = (1 - dx) * (1 - dy) * Q00 + dx * (1 - dy) * Q01 + (1 - dx) * dy * Q10 + dx * dy * Q11\n",
    "            \n",
    "            details = {\n",
    "                'type': 'bilinear',\n",
    "                'rows': [lat_idx0, lat_idx0, lat_idx1, lat_idx1],\n",
    "                'cols': [lon_idx0, lon_idx1, lon_idx0, lon_idx1],\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [Q00, Q01, Q10, Q11],\n",
    "                'lat_values': [y0, y0, y1, y1],\n",
    "                'lon_values': [x0, x1, x0, x1]\n",
    "            }\n",
    "        \n",
    "        # 保存插值详细信息\n",
    "        interpolation_details.append(details)\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"插值错误: {str(e)}\")\n",
    "        return np.nan\n",
    "\n",
    "# ====================== 主处理函数 ======================\n",
    "def process_smapvex_data(input_file_path):\n",
    "    \"\"\"\n",
    "    处理SMAPVEX数据，执行多种插值操作\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        interpolation_details = []  # 重置插值详情\n",
    "        \n",
    "        # ========== 1. 读取原始数据 ==========\n",
    "        print(f\"读取原始Excel文件: {input_file_path}\")\n",
    "        df = pd.read_excel(input_file_path)\n",
    "        \n",
    "        # 定义标准经纬度网格 (0.1°分辨率)\n",
    "        # 纬度: 北纬89.95°(0) -> 南纬-89.95°(1799)\n",
    "        lat_grid = np.linspace(89.95, -89.95, 1800)\n",
    "        \n",
    "        # 经度: -179.95°(0) -> 179.95°(3599)\n",
    "        lon_grid = np.linspace(-179.95, 179.95, 3600)\n",
    "        \n",
    "        print(f\"成功读取 {len(df)} 条记录\")\n",
    "        \n",
    "        # ========== 2. 准备PFT数据 (14个类别) ==========\n",
    "        pft_file = r\"E:\\data\\ESACCI PFT\\Resample\\Data\\2008.mat\"\n",
    "        if os.path.exists(pft_file):\n",
    "            print(f\"\\n处理PFT数据: {pft_file}\")\n",
    "            mat_data = read_hdf5_mat(pft_file)\n",
    "            \n",
    "            pft_columns = ['water','bare','snowice','built','grassnat','grassman',\n",
    "                          'shrubbd','shrubbe','shrubnd','shrubne',\n",
    "                          'treebd','treebe','treend','treene']\n",
    "            \n",
    "            available_pft = [col for col in pft_columns if col in mat_data]\n",
    "            print(f\"  文件中可用的PFT变量: {', '.join(available_pft)}\")\n",
    "            \n",
    "            # 处理每个可用的PFT类别\n",
    "            for col in available_pft:\n",
    "                grid_data = mat_data[col] / 100.0\n",
    "                df[f'PFT_{col}'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        grid_data\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加列: PFT_{col}\")\n",
    "        else:\n",
    "            print(f\"\\n警告: PFT文件不存在 - {pft_file}\")\n",
    "        \n",
    "        # ========== 3. 处理VOD数据 (7个变量) ==========\n",
    "        vod_base_dir = r\"E:\\data\\VOD\\mat\\kuxcVOD\\ASC\"\n",
    "        vod_cols = ['SM','ku_vod_H', 'ku_vod_V', 'x_vod_H','x_vod_V', 'c_vod_H','c_vod_V']\n",
    "        \n",
    "        for col in vod_cols:\n",
    "            df[col] = np.nan\n",
    "        \n",
    "        print(\"\\n处理VOD数据:\")\n",
    "        \n",
    "        # 收集所有唯一日期并排序\n",
    "        unique_dates = sorted(df['Date'].unique())\n",
    "        vod_files_found = 0\n",
    "        \n",
    "        for date in unique_dates:\n",
    "            # 转换为字符串格式YYYYMMDD\n",
    "            try:\n",
    "                if isinstance(date, pd.Timestamp):\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "                else:\n",
    "                    date_str = datetime.strptime(str(date)[:10], \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
    "            except:\n",
    "                print(f\"  无法解析日期: {date}\")\n",
    "                continue\n",
    "            \n",
    "            vod_file = os.path.join(vod_base_dir, f\"MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "            if os.path.exists(vod_file):\n",
    "                vod_files_found += 1\n",
    "                print(f\"  处理日期: {date_str}, 文件: {os.path.basename(vod_file)}\")\n",
    "                vod_data = read_hdf5_mat(vod_file)\n",
    "                \n",
    "                for col in vod_cols:\n",
    "                    if col in vod_data:\n",
    "                        grid_data = vod_data[col]\n",
    "                        mask = df['Date'] == date\n",
    "                        df.loc[mask, col] = df[mask].apply(\n",
    "                            lambda row: bilinear_interpolation_with_details(\n",
    "                                lat_grid, lon_grid, \n",
    "                                row['Latitude'], row['Longitude'], \n",
    "                                grid_data\n",
    "                            ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                            else np.nan, axis=1\n",
    "                        )\n",
    "                        print(f\"    已更新: {col}\")\n",
    "                    else:\n",
    "                        print(f\"    警告: VOD变量 {col} 不存在于文件中\")\n",
    "            else:\n",
    "                print(f\"  警告: VOD文件不存在 - {os.path.basename(vod_file)}\")\n",
    "                \n",
    "        if vod_files_found == 0:\n",
    "            print(\"  警告: 没有找到任何VOD文件，VOD列将保留为空\")\n",
    "        \n",
    "        # ========== 4. 处理LAI卫星数据 (时间插值) ==========\n",
    "        print(\"\\n处理LAI卫星数据...\")\n",
    "        df['LAI_Satellite'] = np.nan\n",
    "        \n",
    "        # 预期可能的LAI变量名\n",
    "        expected_lai_keys = ['lai', 'LAI', 'data']\n",
    "        \n",
    "        lai_sep_file = r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2008-09-01.tif.mat\"\n",
    "        lai_oct_file = r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2008-10-01.tif.mat\"\n",
    "        \n",
    "        if os.path.exists(lai_sep_file) and os.path.exists(lai_oct_file):\n",
    "            print(f\"  加载9月LAI数据 (视为9月15日): {lai_sep_file}\")\n",
    "            sep_data = read_hdf5_mat(lai_sep_file, expected_keys=expected_lai_keys)\n",
    "            \n",
    "            # 直接获取LAI数据\n",
    "            lai_sep_data = list(sep_data.values())[0] if sep_data else np.zeros((1800, 3600))\n",
    "            print(f\"    读取的数据形状: {lai_sep_data.shape}\")\n",
    "            \n",
    "            print(f\"  加载10月LAI数据 (视为10月15日): {lai_oct_file}\")\n",
    "            oct_data = read_hdf5_mat(lai_oct_file, expected_keys=expected_lai_keys)\n",
    "            lai_oct_data = list(oct_data.values())[0] if oct_data else np.zeros((1800, 3600))\n",
    "            print(f\"    读取的数据形状: {lai_oct_data.shape}\")\n",
    "            \n",
    "            # 定义月中日期\n",
    "            sep_mid_date = datetime(2008, 9, 15)  # 9月15日\n",
    "            oct_mid_date = datetime(2008, 10, 15)  # 10月15日\n",
    "            \n",
    "            total_days = (oct_mid_date - sep_mid_date).days\n",
    "            \n",
    "            # 处理每个日期的数据\n",
    "            for date in unique_dates:\n",
    "                try:\n",
    "                    # 确保日期为datetime对象\n",
    "                    if isinstance(date, pd.Timestamp):\n",
    "                        date_dt = date.to_pydatetime()\n",
    "                    elif isinstance(date, str):\n",
    "                        date_dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "                    else:\n",
    "                        date_dt = date\n",
    "                    \n",
    "                    # 计算时间权重\n",
    "                    if date_dt <= sep_mid_date:\n",
    "                        weight = 0.0\n",
    "                    elif date_dt >= oct_mid_date:\n",
    "                        weight = 1.0\n",
    "                    else:\n",
    "                        weight = (date_dt - sep_mid_date).days / total_days\n",
    "                    \n",
    "                    # 应用时间插值\n",
    "                    interpolated_lai = (1 - weight) * lai_sep_data + weight * lai_oct_data\n",
    "                    \n",
    "                    mask = df['Date'] == date\n",
    "                    df.loc[mask, 'LAI_Satellite'] = df[mask].apply(\n",
    "                        lambda row: bilinear_interpolation_with_details(\n",
    "                            lat_grid, lon_grid, \n",
    "                            row['Latitude'], row['Longitude'], \n",
    "                            interpolated_lai\n",
    "                        ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                        else np.nan, axis=1\n",
    "                    )\n",
    "                    \n",
    "                    # 验证插值结果\n",
    "                    mean_lai = np.nanmean(interpolated_lai)\n",
    "                    print(f\"  已处理日期: {date_dt.strftime('%Y-%m-%d')}, 权重: {weight:.2f}, 平均LAI: {mean_lai:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  处理日期{date}时出错: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"  警告: LAI文件不存在 - {' 或 '.join([lai_sep_file, lai_oct_file])}\")\n",
    "            print(\"  将使用固定值0作为LAI卫星数据\")\n",
    "            df['LAI_Satellite'] = 0.0\n",
    "        \n",
    "        # ========== 5. 处理植被高度数据 ==========\n",
    "        print(\"\\n处理植被高度数据...\")\n",
    "        df['Hveg'] = np.nan\n",
    "        \n",
    "        hveg_file = r\"E:\\data\\CanopyHeight\\CH.mat\"\n",
    "        if os.path.exists(hveg_file):\n",
    "            print(f\"  加载植被高度数据: {hveg_file}\")\n",
    "            hveg_data = read_hdf5_mat(hveg_file, expected_keys=['CH', 'ch'])\n",
    "            \n",
    "            # 直接获取高度数据\n",
    "            hveg_key = list(hveg_data.keys())[0] if hveg_data else None\n",
    "            \n",
    "            if hveg_key:\n",
    "                hveg_values = hveg_data[hveg_key]\n",
    "                df['Hveg'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        hveg_values\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加植被高度列，数据形状: {hveg_values.shape}\")\n",
    "            else:\n",
    "                print(f\"  警告: 无法找到Hveg变量\")\n",
    "                df['Hveg'] = np.nan\n",
    "        else:\n",
    "            print(f\"  警告: Hveg文件不存在 - {hveg_file}\")\n",
    "            df['Hveg'] = np.nan\n",
    "        \n",
    "        # ========== 6. 保存结果 ==========\n",
    "        output_file_path = r\"E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\"\n",
    "        print(f\"\\n保存结果到: {output_file_path}\")\n",
    "        df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        # 保存插值详细信息到Excel\n",
    "        if interpolation_details:\n",
    "            details_df = pd.DataFrame(interpolation_details)\n",
    "            details_path = r\"E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\interpolation_details.xlsx\"\n",
    "            details_df.to_excel(details_path, index=False)\n",
    "            print(f\"插值详细信息保存到: {details_path}\")\n",
    "        else:\n",
    "            print(\"警告: 没有插值详细信息可保存\")\n",
    "        \n",
    "        # ========== 7. 统计报告 ==========\n",
    "        print(\"\\n处理完成!\")\n",
    "        print(f\"总记录数: {len(df)}\")\n",
    "        print(f\"插值操作次数: {len(interpolation_details)}\")\n",
    "        \n",
    "        if interpolation_details:\n",
    "            # 显示前3次插值的详细信息\n",
    "            print(\"\\n前3次插值的详细信息:\")\n",
    "            for i, detail in enumerate(interpolation_details[:3]):\n",
    "                print(f\"\\n插值 #{i+1}\")\n",
    "                print(f\"  类型: {detail['type']}\")\n",
    "                print(f\"  目标位置: ({detail['target_lat']:.6f}, {detail['target_lon']:.6f})\")\n",
    "                print(f\"  网格形状: {detail['grid_shape']}\")\n",
    "                \n",
    "                if detail['type'] == 'bilinear':\n",
    "                    print(f\"  使用的4个网格点:\")\n",
    "                    for j in range(4):\n",
    "                        print(f\"    点{j+1}: 行 {detail['rows'][j]}, 列 {detail['cols'][j]} - \" +\n",
    "                              f\"位置 ({detail['lat_values'][j]:.6f}, {detail['lon_values'][j]:.6f}) - \" +\n",
    "                              f\"值: {detail['values'][j]:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  最近邻点: 行 {detail['row']}, 列 {detail['col']} - \" +\n",
    "                          f\"位置 ({detail['lat_values'][0]:.6f}, {detail['lon_values'][0]:.6f}) - \" +\n",
    "                          f\"值: {detail['values'][0]:.6f}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"错误详细信息:\")\n",
    "        print(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "# ========================== 主程序 ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_Sum_VEG_SMAPVEX.xlsx\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"开始处理SMAPVEX数据插值任务\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"错误: 输入文件不存在 - {input_file}\")\n",
    "        print(f\"请检查路径: {os.path.abspath(input_file)}\")\n",
    "    else:\n",
    "        print(f\"输入文件: {input_file}\")\n",
    "        print(f\"输出将保存到: E:\\\\data\\\\VWC\\\\test-VWC\\\\Insitu SMEX08\\\\processed_SV08V_ML.xlsx\")\n",
    "        \n",
    "        success = process_smapvex_data(input_file)\n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务成功完成!\")\n",
    "            print(\"=\"*30)\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务失败，请检查错误信息\")\n",
    "            print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1782f20-2b97-46cc-9748-631abfb121ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载测试数据: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\n",
      "加载完成，总样本数: 10\n",
      "\n",
      "处理 Ku-H 模型: RFR_Ku_Hpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.3100, R²: -4.9195\n",
      "\n",
      "处理 Ku-V 模型: RFR_Ku_Vpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.9155, R²: -7.2834\n",
      "\n",
      "处理 Ku-HV 模型: RFR_Ku_HVpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.3757, R²: -5.1570\n",
      "\n",
      "处理 C-H 模型: RFR_C_Hpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.8144, R²: -6.8610\n",
      "\n",
      "处理 C-V 模型: RFR_C_Vpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.9438, R²: -7.4035\n",
      "\n",
      "处理 C-HV 模型: RFR_C_HVpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.0439, R²: -7.8357\n",
      "\n",
      "处理 X-H 模型: RFR_X_Hpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.3705, R²: -5.1378\n",
      "\n",
      "处理 X-V 模型: RFR_X_Vpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.6296, R²: -6.1180\n",
      "\n",
      "处理 X-HV 模型: RFR_X_HVpol_Type1.pkl\n",
      "  有效样本数: 10 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.5702, R²: -5.8867\n",
      "\n",
      "所有预测结果已保存至: model_predictions_results_SMEX08.xlsx\n",
      "\n",
      "正在绘制组合散点图...\n",
      "  组合散点图已保存至: figures\\SMEX08_VWC_Scatter.png\n",
      "\n",
      "所有处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 机器学习结果填充，和实测值对比\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# 设置常量\n",
    "TEST_FILE = r\"E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\"\n",
    "MODEL_DIR = \"models\"\n",
    "SAVE_RESULTS = \"model_predictions_results_SMEX08.xlsx\"\n",
    "FIG_DIR = \"figures\"\n",
    "\n",
    "# 定义波段和极化组合\n",
    "BANDS = ['Ku', 'C', 'X']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 波段颜色定义\n",
    "BAND_COLORS = {\n",
    "    'Ku': (253/255, 173/255, 115/255, 0.7),\n",
    "    'C': (178/255, 125/255, 104/255, 0.7),\n",
    "    'X': (224/255, 104/255, 46/255, 0.7)\n",
    "}\n",
    "\n",
    "# 极化类型标记定义\n",
    "POL_MARKERS = {\n",
    "    'H': 's',  # 方形\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 'o'  # 圆形\n",
    "}\n",
    "\n",
    "def normalize_LAI(lai_series):\n",
    "    \"\"\"对LAI进行归一化\"\"\"\n",
    "    return lai_series.clip(0, 6) / 6\n",
    "\n",
    "def normalize_VOD(vod_series):\n",
    "    \"\"\"对VOD进行归一化\"\"\"\n",
    "    return vod_series.clip(0, 2) / 2\n",
    "\n",
    "# PFT列名映射字典\n",
    "PFT_MAPPING = {\n",
    "    'PFT_grassnat': 'Grass_nat',\n",
    "    'PFT_grassman': 'Grass_man',\n",
    "    'PFT_shrubbd': 'Shrub_bd',\n",
    "    'PFT_shrubbe': 'Shrub_be',\n",
    "    'PFT_shrubnd': 'Shrub_nd',\n",
    "    'PFT_shrubne': 'Shrub_ne',\n",
    "    'PFT_treebd': 'Tree_bd',\n",
    "    'PFT_treebe': 'Tree_be',\n",
    "    'PFT_treend': 'Tree_nd',\n",
    "    'PFT_treene': 'Tree_ne'\n",
    "}\n",
    "\n",
    "def get_model_columns(band, pol):\n",
    "    \"\"\"获取指定模型所需的列名\"\"\"\n",
    "    base_columns = [\n",
    "        'VWC',  # 实际值\n",
    "        'LAI',  # LAI\n",
    "        'SM'  # 土壤湿度\n",
    "    ]\n",
    "    \n",
    "    # 添加所有PFT列\n",
    "    base_columns.extend(PFT_MAPPING.keys())\n",
    "    \n",
    "    # 根据极化类型添加VOD列\n",
    "    if pol == 'H':\n",
    "        return base_columns + [f'{band.lower()}_vod_H']\n",
    "    elif pol == 'V':\n",
    "        return base_columns + [f'{band.lower()}_vod_V']\n",
    "    elif pol == 'HV':\n",
    "        return base_columns + [f'{band.lower()}_vod_H', f'{band.lower()}_vod_V']\n",
    "\n",
    "def get_feature_order(pol):\n",
    "    \"\"\"获取特征列的顺序（模型期望的列顺序）\"\"\"\n",
    "    base_features = [\n",
    "        'LAI', 'SM',\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    if pol in ['H', 'V']:\n",
    "        return ['VOD'] + base_features\n",
    "    elif pol == 'HV':\n",
    "        return ['VOD-Hpol', 'VOD-Vpol'] + base_features\n",
    "\n",
    "def prepare_input_data(df, band, pol):\n",
    "    \"\"\"为指定模型准备输入数据\"\"\"\n",
    "    # 创建数据副本\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 归一化处理\n",
    "    data['LAI'] = normalize_LAI(data['LAI'])\n",
    "    \n",
    "    # 2. 处理VOD列\n",
    "    if pol == 'H':\n",
    "        vod_col = f'{band.lower()}_vod_H'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'V':\n",
    "        vod_col = f'{band.lower()}_vod_V'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'HV':\n",
    "        # 重命名列以匹配模型训练时的特征名\n",
    "        data = data.rename(columns={\n",
    "            f'{band.lower()}_vod_H': 'VOD-Hpol',\n",
    "            f'{band.lower()}_vod_V': 'VOD-Vpol'\n",
    "        })\n",
    "        # 归一化处理\n",
    "        data['VOD-Hpol'] = normalize_VOD(data['VOD-Hpol'])\n",
    "        data['VOD-Vpol'] = normalize_VOD(data['VOD-Vpol'])\n",
    "    \n",
    "    # 3. 重命名PFT列为模型期望的名称\n",
    "    data = data.rename(columns=PFT_MAPPING)\n",
    "    \n",
    "    # 4. 按模型要求排序特征列\n",
    "    feature_order = get_feature_order(pol)\n",
    "    \n",
    "    return data[feature_order]\n",
    "\n",
    "def plot_combined_scatter(actual, predictions_dict):\n",
    "    \"\"\"\n",
    "    绘制组合散点图，包含所有波段和极化类型\n",
    "    \n",
    "    参数:\n",
    "    actual -- 实际值 (Series)\n",
    "    predictions_dict -- 字典结构: {\n",
    "        'H': {band: pred_series},\n",
    "        'V': {band: pred_series},\n",
    "        'HV': {band: pred_series}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # 存储所有组合的RMSE值\n",
    "    rmse_values = {}\n",
    "    \n",
    "    # 收集所有数据点\n",
    "    max_val = 0\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            pred_series = predictions_dict[pol].get(band)\n",
    "            \n",
    "            if pred_series is not None and not pred_series.isnull().all():\n",
    "                # 创建实际值和预测值的临时DF\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'actual': actual,\n",
    "                    'pred': pred_series\n",
    "                }).dropna()\n",
    "                \n",
    "                if not temp_df.empty:\n",
    "                    # 计算RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(temp_df['actual'], temp_df['pred']))\n",
    "                    rmse_values[f\"{band}-{pol}\"] = rmse\n",
    "                    \n",
    "                    # 更新最大值\n",
    "                    band_max = max(temp_df['actual'].max(), temp_df['pred'].max())\n",
    "                    if band_max > max_val:\n",
    "                        max_val = band_max\n",
    "                    \n",
    "                    # 绘制散点\n",
    "                    plt.scatter(\n",
    "                        temp_df['actual'], temp_df['pred'], \n",
    "                        alpha=0.7, \n",
    "                        color=BAND_COLORS[band],\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        s=50,\n",
    "                        edgecolors='none',\n",
    "                        zorder=2,\n",
    "                        label=f\"{band}-{pol}\"\n",
    "                    )\n",
    "    \n",
    "    # 如果没有数据可绘制，直接返回\n",
    "    if not rmse_values:\n",
    "        print(\"  警告: 没有有效的预测数据!\")\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val *= 1.05\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围\n",
    "    plt.xlim(0, max_val)\n",
    "    plt.ylim(0, max_val)\n",
    "    \n",
    "    # 设置坐标轴标签\n",
    "    plt.xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('RF VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title('SMEX08 Insitu VWC', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "    \n",
    "    # # 添加图例\n",
    "    # plt.legend(loc='lower right', frameon=True, fontsize=10, ncol=3)\n",
    "    \n",
    "    # 添加RMSE文本（左上角，3×3网格布局）\n",
    "    if rmse_values:\n",
    "        # 设置文本位置\n",
    "        x_pos = 0.05\n",
    "        y_pos = 0.95\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.text(x_pos, y_pos, 'RMSE (kg/m²):', \n",
    "                 transform=ax.transAxes,\n",
    "                 fontsize=12,\n",
    "                 fontweight='bold',\n",
    "                 verticalalignment='top')\n",
    "        \n",
    "        y_pos -= 0.05\n",
    "        \n",
    "        # 遍历每个波段\n",
    "        for band_idx, band in enumerate(BANDS):\n",
    "            # 遍历每个极化类型\n",
    "            for pol_idx, pol in enumerate(POLS):\n",
    "                # 计算位置\n",
    "                text_x = x_pos + pol_idx * 0.15\n",
    "                text_y = y_pos - band_idx * 0.08\n",
    "                \n",
    "                # 获取RMSE值\n",
    "                rmse = rmse_values.get(f\"{band}-{pol}\", None)\n",
    "                \n",
    "                if rmse is not None:\n",
    "                    # 绘制标记\n",
    "                    plt.scatter(\n",
    "                        text_x, text_y, \n",
    "                        transform=ax.transAxes,\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        color=BAND_COLORS[band],\n",
    "                        s=80,\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                    \n",
    "                    # 添加文本\n",
    "                    plt.text(\n",
    "                        text_x + 0.01, text_y, \n",
    "                        f\"{band}-{pol}: {rmse:.3f}\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center'\n",
    "                    )\n",
    "                else:\n",
    "                    # 添加缺失值标记\n",
    "                    plt.text(\n",
    "                        text_x, text_y, \n",
    "                        f\"{band}-{pol}: N/A\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center',\n",
    "                        color='gray'\n",
    "                    )\n",
    "    \n",
    "    # 添加网格线\n",
    "    plt.grid(True, linestyle='--', alpha=0.3, zorder=0)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(FIG_DIR, exist_ok=True)\n",
    "    \n",
    "    # 保存图像\n",
    "    fig_path = os.path.join(FIG_DIR, 'SMEX08_VWC_Scatter.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  组合散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def predict_and_evaluate():\n",
    "    \"\"\"主函数：加载所有模型进行预测并评估结果\"\"\"\n",
    "    # 1. 加载测试数据\n",
    "    print(f\"正在加载测试数据: {TEST_FILE}\")\n",
    "    \n",
    "    # 收集所有可能的列\n",
    "    all_columns = set(['VWC', 'LAI', 'SM'])\n",
    "    # 添加所有PFT列\n",
    "    all_columns.update(PFT_MAPPING.keys())\n",
    "    # 添加所有VOD列\n",
    "    for band in BANDS:\n",
    "        all_columns.add(f'{band.lower()}_vod_H')\n",
    "        all_columns.add(f'{band.lower()}_vod_V')\n",
    "    \n",
    "    # 读取Excel文件\n",
    "    test_df = pd.read_excel(TEST_FILE, usecols=list(all_columns))\n",
    "    print(f\"加载完成，总样本数: {len(test_df)}\")\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    results = pd.DataFrame(index=test_df.index)\n",
    "    results['Actual_VWC'] = test_df['VWC']\n",
    "    \n",
    "    # 为每个极化类型存储预测结果\n",
    "    predictions_by_pol = {\n",
    "        'H': {band: None for band in BANDS},\n",
    "        'V': {band: None for band in BANDS},\n",
    "        'HV': {band: None for band in BANDS}\n",
    "    }\n",
    "    \n",
    "    # 2. 对每个模型进行预测\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            model_name = f\"RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "            model_path = os.path.join(MODEL_DIR, model_name)\n",
    "            \n",
    "            print(f\"\\n处理 {band}-{pol} 模型: {model_name}\")\n",
    "            \n",
    "            # 准备输入数据\n",
    "            model_cols = get_model_columns(band, pol)\n",
    "            model_data = test_df[model_cols].copy()\n",
    "            \n",
    "            # 删除缺失值\n",
    "            clean_data = model_data.dropna()\n",
    "            print(f\"  有效样本数: {len(clean_data)} (删除缺失值后)\")\n",
    "            \n",
    "            if len(clean_data) == 0:\n",
    "                print(\"  警告: 无有效样本可用于此模型!\")\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "                continue\n",
    "            \n",
    "            # 预处理输入数据\n",
    "            try:\n",
    "                X_input = prepare_input_data(clean_data, band, pol)\n",
    "                \n",
    "                # 加载模型并进行预测\n",
    "                if os.path.exists(model_path):\n",
    "                    model = joblib.load(model_path)\n",
    "                    predictions = model.predict(X_input)\n",
    "                    \n",
    "                    # 存储预测结果\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    results.loc[clean_data.index, f\"{band}_{pol}_Predicted\"] = predictions\n",
    "                    \n",
    "                    # 存储到对应极化类型的字典\n",
    "                    predictions_by_pol[pol][band] = results[f\"{band}_{pol}_Predicted\"].copy()\n",
    "                    \n",
    "                    # 计算评估指标\n",
    "                    actual = clean_data['VWC']\n",
    "                    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "                    r2 = r2_score(actual, predictions)\n",
    "                    print(f\"  预测完成 - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  警告: 未找到模型文件 {model_path}!\")\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    predictions_by_pol[pol][band] = None\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"  预测失败: {str(e)}\")\n",
    "                # 打印更详细的错误信息\n",
    "                traceback.print_exc()\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "    \n",
    "    # 3. 保存结果\n",
    "    results.to_excel(SAVE_RESULTS)\n",
    "    print(f\"\\n所有预测结果已保存至: {SAVE_RESULTS}\")\n",
    "    \n",
    "    # 4. 绘制组合散点图\n",
    "    print(\"\\n正在绘制组合散点图...\")\n",
    "    plot_combined_scatter(\n",
    "        results['Actual_VWC'], \n",
    "        predictions_by_pol\n",
    "    )\n",
    "    \n",
    "    return results, predictions_by_pol\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    results, predictions_by_pol = predict_and_evaluate()\n",
    "    print(\"\\n所有处理完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5410b-1b6f-41f9-8536-3266ee795b16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4.NSIDC（SMEX02）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f71da0b-9f99-4de9-b40e-0bec6f53488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除前数据行数: 1400\n",
      "移除后数据行数: 0\n",
      "包含日期列的前5行数据：\n",
      "Empty DataFrame\n",
      "Columns: [Date, Year, Month, Day, UTM-E, UTM-N, Longitude, Latitude]\n",
      "Index: []\n",
      "\n",
      "================================================================================\n",
      "\n",
      "文件总行数: 0\n",
      "日期范围: nan 到 nan\n",
      "经纬度范围:\n",
      "  经度: nan° 到 nan°\n",
      "  纬度: nan° 到 nan°\n"
     ]
    }
   ],
   "source": [
    "# CLASIC07 050（没有保留的数据行，不使用）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# 文件路径\n",
    "file_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\NSIDC0666_matchup_pals_grid_v107_111012_CLASIC07_050.txt\"\n",
    "\n",
    "# 读取数据文件\n",
    "df = pd.read_csv(file_path, sep='\\s+', header=0, na_values=['NaN'])\n",
    "\n",
    "# 创建日期列 (YYYYMMDD格式)\n",
    "df['Date'] = df.apply(\n",
    "    lambda row: f\"{int(row['Year'])}{int(row['Month']):02d}{int(row['Day']):02d}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 创建UTM到WGS84转换器 (UTM zone 14N - EPSG:32614)\n",
    "transformer = Transformer.from_crs(\"EPSG:32614\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# 坐标转换函数\n",
    "def convert_utm_to_wgs84(easting, northing):\n",
    "    try:\n",
    "        lon, lat = transformer.transform(easting, northing)\n",
    "        return pd.Series([lon, lat])\n",
    "    except Exception as e:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# 应用坐标转换\n",
    "df[['Longitude', 'Latitude']] = df.apply(\n",
    "    lambda row: convert_utm_to_wgs84(row['UTM-E'], row['UTM-N']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"移除前数据行数: {len(df)}\")\n",
    "df = df.dropna(subset=['VWC-Field'])\n",
    "print(f\"移除后数据行数: {len(df)}\")\n",
    "\n",
    "# 打印包含日期列的前5行数据\n",
    "print(\"包含日期列的前5行数据：\")\n",
    "print(df[['Date', 'Year', 'Month', 'Day', 'UTM-E', 'UTM-N', 'Longitude', 'Latitude']].head(5).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"文件总行数: {len(df)}\")\n",
    "print(f\"日期范围: {df['Date'].min()} 到 {df['Date'].max()}\")\n",
    "print(f\"经纬度范围:\")\n",
    "print(f\"  经度: {df['Longitude'].min():.6f}° 到 {df['Longitude'].max():.6f}°\")\n",
    "print(f\"  纬度: {df['Latitude'].min():.6f}° 到 {df['Latitude'].max():.6f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f3b57d9-24de-44ed-96ef-b4a1dc3d410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除前数据行数: 4032\n",
      "移除后数据行数: 0\n",
      "包含日期列的前5行数据：\n",
      "Empty DataFrame\n",
      "Columns: [Date, Year, Month, Day, UTM-E, UTM-N, Longitude, Latitude]\n",
      "Index: []\n",
      "\n",
      "================================================================================\n",
      "\n",
      "文件总行数: 0\n",
      "日期范围: nan 到 nan\n",
      "经纬度范围:\n",
      "  经度: nan° 到 nan°\n",
      "  纬度: nan° 到 nan°\n"
     ]
    }
   ],
   "source": [
    "# CLASIC07 060（没有保留的数据行，不使用）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# 文件路径\n",
    "file_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\NSIDC0666_matchup_pals_grid_v107_111012_CLASIC07_060.txt\"\n",
    "\n",
    "# 读取数据文件\n",
    "df = pd.read_csv(file_path, sep='\\s+', header=0, na_values=['NaN'])\n",
    "\n",
    "# 创建日期列 (YYYYMMDD格式)\n",
    "df['Date'] = df.apply(\n",
    "    lambda row: f\"{int(row['Year'])}{int(row['Month']):02d}{int(row['Day']):02d}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 创建UTM到WGS84转换器 (UTM zone 14N - EPSG:32614)\n",
    "transformer = Transformer.from_crs(\"EPSG:32614\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# 坐标转换函数\n",
    "def convert_utm_to_wgs84(easting, northing):\n",
    "    try:\n",
    "        lon, lat = transformer.transform(easting, northing)\n",
    "        return pd.Series([lon, lat])\n",
    "    except Exception as e:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# 应用坐标转换\n",
    "df[['Longitude', 'Latitude']] = df.apply(\n",
    "    lambda row: convert_utm_to_wgs84(row['UTM-E'], row['UTM-N']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"移除前数据行数: {len(df)}\")\n",
    "df = df.dropna(subset=['VWC-Field'])\n",
    "print(f\"移除后数据行数: {len(df)}\")\n",
    "\n",
    "# 打印包含日期列的前5行数据\n",
    "print(\"包含日期列的前5行数据：\")\n",
    "print(df[['Date', 'Year', 'Month', 'Day', 'UTM-E', 'UTM-N', 'Longitude', 'Latitude']].head(5).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"文件总行数: {len(df)}\")\n",
    "print(f\"日期范围: {df['Date'].min()} 到 {df['Date'].max()}\")\n",
    "print(f\"经纬度范围:\")\n",
    "print(f\"  经度: {df['Longitude'].min():.6f}° 到 {df['Longitude'].max():.6f}°\")\n",
    "print(f\"  纬度: {df['Latitude'].min():.6f}° 到 {df['Latitude'].max():.6f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c756e340-bf2e-4b01-a5dd-8ab3829c9ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除前数据行数: 9800\n",
      "移除后数据行数: 5\n",
      "包含日期列的前5行数据：\n",
      "    Date  Year  Month  Day    UTM-E     UTM-N  Longitude  Latitude\n",
      "20081002  2008     10    2 413099.2 4319526.1 -76.003847 39.020458\n",
      "20081002  2008     10    2 418699.2 4316326.1 -75.938785 38.992164\n",
      "20081004  2008     10    4 416299.2 4315526.1 -75.966397 38.984729\n",
      "20081006  2008     10    6 412299.2 4317926.1 -76.012882 39.005962\n",
      "20081006  2008     10    6 414699.2 4317926.1 -75.985167 39.006199\n",
      "\n",
      "================================================================================\n",
      "\n",
      "文件总行数: 5\n",
      "日期范围: 20081002 到 20081006\n",
      "经纬度范围:\n",
      "  经度: -76.012882° 到 -75.938785°\n",
      "  纬度: 38.984729° 到 39.020458°\n"
     ]
    }
   ],
   "source": [
    "# SMAPVEX08（保留的数据行很少，不使用）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# 文件路径\n",
    "file_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\NSIDC0666_matchup_pals_grid_v107_111012_SMAPVEX08.txt\"\n",
    "\n",
    "# 读取数据文件\n",
    "df = pd.read_csv(file_path, sep='\\s+', header=0, na_values=['NaN'])\n",
    "\n",
    "# 创建日期列 (YYYYMMDD格式)\n",
    "df['Date'] = df.apply(\n",
    "    lambda row: f\"{int(row['Year'])}{int(row['Month']):02d}{int(row['Day']):02d}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 创建UTM到WGS84转换器 (UTM zone 18N - EPSG:32618)\n",
    "transformer = Transformer.from_crs(\"EPSG:32618\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# 坐标转换函数\n",
    "def convert_utm_to_wgs84(easting, northing):\n",
    "    try:\n",
    "        lon, lat = transformer.transform(easting, northing)\n",
    "        return pd.Series([lon, lat])\n",
    "    except Exception as e:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# 应用坐标转换\n",
    "df[['Longitude', 'Latitude']] = df.apply(\n",
    "    lambda row: convert_utm_to_wgs84(row['UTM-E'], row['UTM-N']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"移除前数据行数: {len(df)}\")\n",
    "df = df.dropna(subset=['VWC-Field'])\n",
    "print(f\"移除后数据行数: {len(df)}\")\n",
    "\n",
    "# 打印包含日期列的前5行数据\n",
    "print(\"包含日期列的前5行数据：\")\n",
    "print(df[['Date', 'Year', 'Month', 'Day', 'UTM-E', 'UTM-N', 'Longitude', 'Latitude']].head(5).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"文件总行数: {len(df)}\")\n",
    "print(f\"日期范围: {df['Date'].min()} 到 {df['Date'].max()}\")\n",
    "print(f\"经纬度范围:\")\n",
    "print(f\"  经度: {df['Longitude'].min():.6f}° 到 {df['Longitude'].max():.6f}°\")\n",
    "print(f\"  纬度: {df['Latitude'].min():.6f}° 到 {df['Latitude'].max():.6f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2399c7-45fd-4512-a336-381710737911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除前数据行数: 3440\n",
      "移除后数据行数: 104\n",
      "包含日期列的前5行数据：\n",
      "      Date  Year  Month  Day    UTM-E     UTM-N  Longitude  Latitude\n",
      "2002-06-25  2002      6   25 437375.2 4642453.2 -93.755366 41.931559\n",
      "2002-06-25  2002      6   25 437375.2 4643253.2 -93.755451 41.938764\n",
      "2002-06-25  2002      6   25 437375.2 4646453.2 -93.755791 41.967583\n",
      "2002-06-25  2002      6   25 437375.2 4648053.2 -93.755962 41.981992\n",
      "2002-06-25  2002      6   25 438975.2 4645653.2 -93.736400 41.960503\n",
      "\n",
      "================================================================================\n",
      "\n",
      "文件总行数: 104\n",
      "日期范围: 2002-06-25 到 2002-07-08\n",
      "经纬度范围:\n",
      "  经度: -93.755962° 到 -93.688057°\n",
      "  纬度: 41.924601° 到 41.982417°\n",
      "处理后的数据已保存到: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx\n"
     ]
    }
   ],
   "source": [
    "# SMEX02\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "file_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\NSIDC0666_matchup_pals_grid_v107_111012_SMEX02.txt\"\n",
    "\n",
    "# 读取数据文件\n",
    "df = pd.read_csv(file_path, sep='\\s+', header=0, na_values=['NaN'])\n",
    "\n",
    "# 创建日期列 (YYYYMMDD格式)\n",
    "df['Date'] = pd.to_datetime(df.apply(\n",
    "    lambda row: f\"{int(row['Year'])}{int(row['Month']):02d}{int(row['Day']):02d}\", \n",
    "    axis=1\n",
    "), format='%Y%m%d')\n",
    "\n",
    "# 创建UTM到WGS84转换器 (UTM zone 15N - EPSG:32615)\n",
    "transformer = Transformer.from_crs(\"EPSG:32615\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# 坐标转换函数\n",
    "def convert_utm_to_wgs84(easting, northing):\n",
    "    try:\n",
    "        lon, lat = transformer.transform(easting, northing)\n",
    "        return pd.Series([lon, lat])\n",
    "    except Exception as e:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# 应用坐标转换\n",
    "df[['Longitude', 'Latitude']] = df.apply(\n",
    "    lambda row: convert_utm_to_wgs84(row['UTM-E'], row['UTM-N']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"移除前数据行数: {len(df)}\")\n",
    "df = df.dropna(subset=['VWC-Field'])\n",
    "print(f\"移除后数据行数: {len(df)}\")\n",
    "\n",
    "# 打印包含日期列的前5行数据\n",
    "print(\"包含日期列的前5行数据：\")\n",
    "print(df[['Date', 'Year', 'Month', 'Day', 'UTM-E', 'UTM-N', 'Longitude', 'Latitude']].head(5).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"文件总行数: {len(df)}\")\n",
    "print(f\"日期范围: {df['Date'].min().strftime('%Y-%m-%d')} 到 {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"经纬度范围:\")\n",
    "print(f\"  经度: {df['Longitude'].min():.6f}° 到 {df['Longitude'].max():.6f}°\")\n",
    "print(f\"  纬度: {df['Latitude'].min():.6f}° 到 {df['Latitude'].max():.6f}°\")\n",
    "\n",
    "# 保存为xlsx文件\n",
    "output_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx\"\n",
    "\n",
    "# 创建输出目录（如果不存在）\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# 保存DataFrame到Excel文件\n",
    "df.to_excel(\n",
    "    output_path, \n",
    "    index=False,\n",
    "    sheet_name='SMEX02_VWC',\n",
    "    engine='openpyxl'\n",
    ")\n",
    "\n",
    "print(f\"处理后的数据已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fd76e5-765a-4224-acb1-f5a434ff7ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "开始处理SMEX02数据插值任务\n",
      "============================================================\n",
      "输入文件: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx\n",
      "输出将保存到: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\n",
      "读取原始Excel文件: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx\n",
      "成功读取 104 条记录\n",
      "\n",
      "处理PFT数据: E:\\data\\ESACCI PFT\\Resample\\Data\\2002.mat\n",
      "  文件中可用的PFT变量: water, bare, snowice, built, grassnat, grassman, shrubbd, shrubbe, shrubnd, shrubne, treebd, treebe, treend, treene\n",
      "  已添加列: PFT_water\n",
      "  已添加列: PFT_bare\n",
      "  已添加列: PFT_snowice\n",
      "  已添加列: PFT_built\n",
      "  已添加列: PFT_grassnat\n",
      "  已添加列: PFT_grassman\n",
      "  已添加列: PFT_shrubbd\n",
      "  已添加列: PFT_shrubbe\n",
      "  已添加列: PFT_shrubnd\n",
      "  已添加列: PFT_shrubne\n",
      "  已添加列: PFT_treebd\n",
      "  已添加列: PFT_treebe\n",
      "  已添加列: PFT_treend\n",
      "  已添加列: PFT_treene\n",
      "\n",
      "处理VOD数据:\n",
      "  处理日期: 20020625, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020625_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020627, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020627_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020701, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020701_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020702, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020702_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020705, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020705_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020706, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020706_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020707, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020707_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20020708, 文件: MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_20020708_V0.nc4.mat\n",
      "    已更新: sm\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "\n",
      "处理LAI卫星数据...\n",
      "  加载6月LAI数据 (视为6月15日): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2002-06-01.tif.mat\n",
      "    读取的数据形状: (1800, 3600)\n",
      "  加载7月LAI数据 (视为7月15日): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2002-07-01.tif.mat\n",
      "    读取的数据形状: (1800, 3600)\n",
      "  已处理日期: 2002-06-25, 权重: 0.33, 平均LAI: 1.4753\n",
      "  已处理日期: 2002-06-27, 权重: 0.40, 平均LAI: 1.4834\n",
      "  已处理日期: 2002-07-01, 权重: 0.53, 平均LAI: 1.4996\n",
      "  已处理日期: 2002-07-02, 权重: 0.57, 平均LAI: 1.5036\n",
      "  已处理日期: 2002-07-05, 权重: 0.67, 平均LAI: 1.5158\n",
      "  已处理日期: 2002-07-06, 权重: 0.70, 平均LAI: 1.5198\n",
      "  已处理日期: 2002-07-07, 权重: 0.73, 平均LAI: 1.5239\n",
      "  已处理日期: 2002-07-08, 权重: 0.77, 平均LAI: 1.5279\n",
      "\n",
      "处理植被高度数据...\n",
      "  加载植被高度数据: E:\\data\\CanopyHeight\\CH.mat\n",
      "  已添加植被高度列，数据形状: (1800, 3600)\n",
      "\n",
      "保存结果到: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\n",
      "插值详细信息保存到: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\interpolation_details.xlsx\n",
      "\n",
      "处理完成!\n",
      "总记录数: 104\n",
      "插值操作次数: 2392\n",
      "\n",
      "前3次插值的详细信息:\n",
      "\n",
      "插值 #1\n",
      "  类型: bilinear\n",
      "  目标位置: (41.931559, -93.755366)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 480, 列 861 - 位置 (41.950000, -93.850000) - 值: 0.031188\n",
      "    点2: 行 480, 列 862 - 位置 (41.950000, -93.750000) - 值: 0.000000\n",
      "    点3: 行 481, 列 861 - 位置 (41.850000, -93.850000) - 值: 0.090247\n",
      "    点4: 行 481, 列 862 - 位置 (41.850000, -93.750000) - 值: 0.046080\n",
      "\n",
      "插值 #2\n",
      "  类型: bilinear\n",
      "  目标位置: (41.938764, -93.755451)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 480, 列 861 - 位置 (41.950000, -93.850000) - 值: 0.031188\n",
      "    点2: 行 480, 列 862 - 位置 (41.950000, -93.750000) - 值: 0.000000\n",
      "    点3: 行 481, 列 861 - 位置 (41.850000, -93.850000) - 值: 0.090247\n",
      "    点4: 行 481, 列 862 - 位置 (41.850000, -93.750000) - 值: 0.046080\n",
      "\n",
      "插值 #3\n",
      "  类型: bilinear\n",
      "  目标位置: (41.967583, -93.755791)\n",
      "  网格形状: (1800, 3600)\n",
      "  使用的4个网格点:\n",
      "    点1: 行 479, 列 861 - 位置 (42.050000, -93.850000) - 值: 0.000085\n",
      "    点2: 行 479, 列 862 - 位置 (42.050000, -93.750000) - 值: 0.000000\n",
      "    点3: 行 480, 列 861 - 位置 (41.950000, -93.850000) - 值: 0.031188\n",
      "    点4: 行 480, 列 862 - 位置 (41.950000, -93.750000) - 值: 0.000000\n",
      "\n",
      "==============================\n",
      "任务成功完成!\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 数据填充以收集自变量\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 全局变量记录插值详细信息\n",
    "interpolation_details = []\n",
    "\n",
    "# ====================== 改进的MAT文件读取函数 ======================\n",
    "def read_hdf5_mat(file_path, expected_keys=None):\n",
    "    \"\"\"读取MATLAB v7.3格式的HDF5文件，优先查找特定变量\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = {}\n",
    "            \n",
    "            def visitor_func(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    if h5py.check_string_dtype(obj.dtype):\n",
    "                        value = ''.join(chr(c) for c in obj[:])\n",
    "                    else:\n",
    "                        value = np.array(obj)\n",
    "                    if value.ndim >= 2:\n",
    "                        value = value.T\n",
    "                    base_name = name.split('/')[-1]\n",
    "                    data[base_name] = value\n",
    "            \n",
    "            f.visititems(visitor_func)\n",
    "            \n",
    "            # 优先查找预期变量\n",
    "            if expected_keys:\n",
    "                for key in expected_keys:\n",
    "                    if key in data:\n",
    "                        return {key: data[key]}\n",
    "            \n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"  读取HDF5 MAT文件失败: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# ====================== 改进的双线性插值函数 ======================\n",
    "def bilinear_interpolation_with_details(lat_grid, lon_grid, target_lat, target_lon, grid_data):\n",
    "    \"\"\"\n",
    "    执行双线性插值并记录详细信息\n",
    "    :param lat_grid: 网格纬度数组 (1D, 从北向南递减)\n",
    "    :param lon_grid: 网格经度数组 (1D, 从西向东递增)\n",
    "    :param target_lat: 目标点纬度\n",
    "    :param target_lon: 目标点经度\n",
    "    :param grid_data: 网格数据 (2D数组, 形状为(len(lat_grid), len(lon_grid)))\n",
    "    :return: 插值值\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        # 记录网格形状\n",
    "        grid_shape = grid_data.shape\n",
    "        \n",
    "        # 验证网格尺寸\n",
    "        if len(lat_grid) != grid_shape[0] or len(lon_grid) != grid_shape[1]:\n",
    "            print(f\"警告: 网格尺寸不匹配! 纬度网格: {len(lat_grid)}, 经度网格: {len(lon_grid)}, 数据形状: {grid_shape}\")\n",
    "            return np.nan\n",
    "        \n",
    "        # 查找最近的纬度索引（纬度从北向南递减）\n",
    "        # 纬度网格: 89.95 (北) -> -89.95 (南)\n",
    "        lat_idx = np.argmin(np.abs(lat_grid - target_lat))\n",
    "        \n",
    "        # 查找最近的经度索引（经度从西向东递增）\n",
    "        # 经度网格: -179.95 (西) -> 179.95 (东)\n",
    "        lon_idx = np.argmin(np.abs(lon_grid - target_lon))\n",
    "        \n",
    "        # 确定四个角点索引\n",
    "        # 纬度处理：目标点位于两个纬度网格点之间\n",
    "        if lat_idx == 0:\n",
    "            lat_idx0, lat_idx1 = 0, 1\n",
    "        elif lat_idx == len(lat_grid) - 1:\n",
    "            lat_idx0, lat_idx1 = len(lat_grid) - 2, len(lat_grid) - 1\n",
    "        else:\n",
    "            if target_lat > lat_grid[lat_idx]:\n",
    "                # 目标纬度大于当前网格点纬度（更北）\n",
    "                if lat_idx > 0:\n",
    "                    lat_idx0 = lat_idx - 1\n",
    "                    lat_idx1 = lat_idx\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "            else:\n",
    "                # 目标纬度小于当前网格点纬度（更南）\n",
    "                if lat_idx < len(lat_grid) - 1:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx + 1\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "        \n",
    "        # 经度处理：目标点位于两个经度网格点之间\n",
    "        if lon_idx == 0:\n",
    "            lon_idx0, lon_idx1 = 0, 1\n",
    "        elif lon_idx == len(lon_grid) - 1:\n",
    "            lon_idx0, lon_idx1 = len(lon_grid) - 2, len(lon_grid) - 1\n",
    "        else:\n",
    "            if target_lon > lon_grid[lon_idx]:\n",
    "                # 目标经度大于当前网格点经度（更东）\n",
    "                if lon_idx < len(lon_grid) - 1:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx + 1\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "            else:\n",
    "                # 目标经度小于当前网格点经度（更西）\n",
    "                if lon_idx > 0:\n",
    "                    lon_idx0 = lon_idx - 1\n",
    "                    lon_idx1 = lon_idx\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "        \n",
    "        # 获取四个角点值\n",
    "        Q00 = grid_data[lat_idx0, lon_idx0]\n",
    "        Q01 = grid_data[lat_idx0, lon_idx1]\n",
    "        Q10 = grid_data[lat_idx1, lon_idx0]\n",
    "        Q11 = grid_data[lat_idx1, lon_idx1]\n",
    "        \n",
    "        # 四个角点坐标\n",
    "        y0 = lat_grid[lat_idx0]\n",
    "        y1 = lat_grid[lat_idx1]\n",
    "        x0 = lon_grid[lon_idx0]\n",
    "        x1 = lon_grid[lon_idx1]\n",
    "        \n",
    "        # 如果有NaN，使用最接近的点\n",
    "        if np.isnan(Q00) or np.isnan(Q01) or np.isnan(Q10) or np.isnan(Q11):\n",
    "            result = grid_data[lat_idx, lon_idx]\n",
    "            details = {\n",
    "                'type': 'nearest',\n",
    "                'row': lat_idx,\n",
    "                'col': lon_idx,\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [grid_data[lat_idx, lon_idx]],\n",
    "                'lat_values': [lat_grid[lat_idx]],\n",
    "                'lon_values': [lon_grid[lon_idx]]\n",
    "            }\n",
    "        else:\n",
    "            # 双线性插值公式\n",
    "            dx = (target_lon - x0) / (x1 - x0) if (x1 - x0) != 0 else 0\n",
    "            dy = (target_lat - y0) / (y1 - y0) if (y1 - y0) != 0 else 0\n",
    "            result = (1 - dx) * (1 - dy) * Q00 + dx * (1 - dy) * Q01 + (1 - dx) * dy * Q10 + dx * dy * Q11\n",
    "            \n",
    "            details = {\n",
    "                'type': 'bilinear',\n",
    "                'rows': [lat_idx0, lat_idx0, lat_idx1, lat_idx1],\n",
    "                'cols': [lon_idx0, lon_idx1, lon_idx0, lon_idx1],\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [Q00, Q01, Q10, Q11],\n",
    "                'lat_values': [y0, y0, y1, y1],\n",
    "                'lon_values': [x0, x1, x0, x1]\n",
    "            }\n",
    "        \n",
    "        # 保存插值详细信息\n",
    "        interpolation_details.append(details)\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"插值错误: {str(e)}\")\n",
    "        return np.nan\n",
    "\n",
    "# ====================== 主处理函数 ======================\n",
    "def process_smapvex_data(input_file_path):\n",
    "    \"\"\"\n",
    "    处理SMAPVEX数据，执行多种插值操作\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        interpolation_details = []  # 重置插值详情\n",
    "        \n",
    "        # ========== 1. 读取原始数据 ==========\n",
    "        print(f\"读取原始Excel文件: {input_file_path}\")\n",
    "        df = pd.read_excel(input_file_path)\n",
    "        \n",
    "        # 定义标准经纬度网格 (0.1°分辨率)\n",
    "        # 纬度: 北纬89.95°(0) -> 南纬-89.95°(1799)\n",
    "        lat_grid = np.linspace(89.95, -89.95, 1800)\n",
    "        \n",
    "        # 经度: -179.95°(0) -> 179.95°(3599)\n",
    "        lon_grid = np.linspace(-179.95, 179.95, 3600)\n",
    "        \n",
    "        print(f\"成功读取 {len(df)} 条记录\")\n",
    "        \n",
    "        # ========== 2. 准备PFT数据 (14个类别) ==========\n",
    "        pft_file = r\"E:\\data\\ESACCI PFT\\Resample\\Data\\2002.mat\"\n",
    "        if os.path.exists(pft_file):\n",
    "            print(f\"\\n处理PFT数据: {pft_file}\")\n",
    "            mat_data = read_hdf5_mat(pft_file)\n",
    "            \n",
    "            pft_columns = ['water','bare','snowice','built','grassnat','grassman',\n",
    "                          'shrubbd','shrubbe','shrubnd','shrubne',\n",
    "                          'treebd','treebe','treend','treene']\n",
    "            \n",
    "            available_pft = [col for col in pft_columns if col in mat_data]\n",
    "            print(f\"  文件中可用的PFT变量: {', '.join(available_pft)}\")\n",
    "            \n",
    "            # 处理每个可用的PFT类别\n",
    "            for col in available_pft:\n",
    "                grid_data = mat_data[col] / 100.0\n",
    "                df[f'PFT_{col}'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        grid_data\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加列: PFT_{col}\")\n",
    "        else:\n",
    "            print(f\"\\n警告: PFT文件不存在 - {pft_file}\")\n",
    "        \n",
    "        # ========== 3. 处理VOD数据 (7个变量) ==========\n",
    "        vod_base_dir = r\"E:\\data\\VOD\\mat\\kuxcVOD\\ASC\"\n",
    "        vod_cols = ['sm','ku_vod_H', 'ku_vod_V', 'x_vod_H','x_vod_V', 'c_vod_H','c_vod_V']\n",
    "        \n",
    "        for col in vod_cols:\n",
    "            df[col] = np.nan\n",
    "        \n",
    "        print(\"\\n处理VOD数据:\")\n",
    "        \n",
    "        # 收集所有唯一日期并排序\n",
    "        unique_dates = sorted(df['Date'].unique())\n",
    "        vod_files_found = 0\n",
    "        \n",
    "        for date in unique_dates:\n",
    "            # 转换为字符串格式YYYYMMDD\n",
    "            try:\n",
    "                if isinstance(date, pd.Timestamp):\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "                else:\n",
    "                    date_str = datetime.strptime(str(date)[:10], \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
    "            except:\n",
    "                print(f\"  无法解析日期: {date}\")\n",
    "                continue\n",
    "            \n",
    "            vod_file = os.path.join(vod_base_dir, f\"MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "            if os.path.exists(vod_file):\n",
    "                vod_files_found += 1\n",
    "                print(f\"  处理日期: {date_str}, 文件: {os.path.basename(vod_file)}\")\n",
    "                vod_data = read_hdf5_mat(vod_file)\n",
    "                \n",
    "                for col in vod_cols:\n",
    "                    vod_var_name = col\n",
    "                    if col == 'sm':\n",
    "                        vod_var_name = 'SM'  # 实际文件中的变量名是大写的 SM\n",
    "                    if vod_var_name in vod_data:\n",
    "                        grid_data = vod_data[vod_var_name]\n",
    "                        mask = df['Date'] == date\n",
    "                        df.loc[mask, col] = df[mask].apply(\n",
    "                            lambda row: bilinear_interpolation_with_details(\n",
    "                                lat_grid, lon_grid, \n",
    "                                row['Latitude'], row['Longitude'], \n",
    "                                grid_data\n",
    "                            ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                            else np.nan, axis=1\n",
    "                        )\n",
    "                        print(f\"    已更新: {col}\")\n",
    "                    else:\n",
    "                        print(f\"    警告: VOD变量 {vod_var_name} (映射自 {col}) 不存在于文件中\")\n",
    "            else:\n",
    "                print(f\"  警告: VOD文件不存在 - {os.path.basename(vod_file)}\")\n",
    "                \n",
    "        if vod_files_found == 0:\n",
    "            print(\"  警告: 没有找到任何VOD文件，VOD列将保留为空\")\n",
    "        \n",
    "        # ========== 4. 处理LAI卫星数据 (时间插值) ==========\n",
    "        print(\"\\n处理LAI卫星数据...\")\n",
    "        df['LAI_Satellite'] = np.nan\n",
    "        \n",
    "        # 预期可能的LAI变量名\n",
    "        expected_lai_keys = ['lai', 'LAI', 'data']\n",
    "        \n",
    "        lai_sep_file = r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2002-06-01.tif.mat\"\n",
    "        lai_oct_file = r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2002-07-01.tif.mat\"\n",
    "        \n",
    "        if os.path.exists(lai_sep_file) and os.path.exists(lai_oct_file):\n",
    "            print(f\"  加载6月LAI数据 (视为6月15日): {lai_sep_file}\")\n",
    "            sep_data = read_hdf5_mat(lai_sep_file, expected_keys=expected_lai_keys)\n",
    "            \n",
    "            # 直接获取LAI数据\n",
    "            lai_sep_data = list(sep_data.values())[0] if sep_data else np.zeros((1800, 3600))\n",
    "            print(f\"    读取的数据形状: {lai_sep_data.shape}\")\n",
    "            \n",
    "            print(f\"  加载7月LAI数据 (视为7月15日): {lai_oct_file}\")\n",
    "            oct_data = read_hdf5_mat(lai_oct_file, expected_keys=expected_lai_keys)\n",
    "            lai_oct_data = list(oct_data.values())[0] if oct_data else np.zeros((1800, 3600))\n",
    "            print(f\"    读取的数据形状: {lai_oct_data.shape}\")\n",
    "            \n",
    "            # 定义月中日期\n",
    "            sep_mid_date = datetime(2002, 6, 15)  # 9月15日\n",
    "            oct_mid_date = datetime(2002, 7, 15)  # 10月15日\n",
    "            \n",
    "            total_days = (oct_mid_date - sep_mid_date).days\n",
    "            \n",
    "            # 处理每个日期的数据\n",
    "            for date in unique_dates:\n",
    "                try:\n",
    "                    # 确保日期为datetime对象\n",
    "                    if isinstance(date, pd.Timestamp):\n",
    "                        date_dt = date.to_pydatetime()\n",
    "                    elif isinstance(date, str):\n",
    "                        date_dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "                    else:\n",
    "                        date_dt = date\n",
    "                    \n",
    "                    # 计算时间权重\n",
    "                    if date_dt <= sep_mid_date:\n",
    "                        weight = 0.0\n",
    "                    elif date_dt >= oct_mid_date:\n",
    "                        weight = 1.0\n",
    "                    else:\n",
    "                        weight = (date_dt - sep_mid_date).days / total_days\n",
    "                    \n",
    "                    # 应用时间插值\n",
    "                    interpolated_lai = (1 - weight) * lai_sep_data + weight * lai_oct_data\n",
    "                    \n",
    "                    mask = df['Date'] == date\n",
    "                    df.loc[mask, 'LAI_Satellite'] = df[mask].apply(\n",
    "                        lambda row: bilinear_interpolation_with_details(\n",
    "                            lat_grid, lon_grid, \n",
    "                            row['Latitude'], row['Longitude'], \n",
    "                            interpolated_lai\n",
    "                        ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                        else np.nan, axis=1\n",
    "                    )\n",
    "                    \n",
    "                    # 验证插值结果\n",
    "                    mean_lai = np.nanmean(interpolated_lai)\n",
    "                    print(f\"  已处理日期: {date_dt.strftime('%Y-%m-%d')}, 权重: {weight:.2f}, 平均LAI: {mean_lai:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  处理日期{date}时出错: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"  警告: LAI文件不存在 - {' 或 '.join([lai_sep_file, lai_oct_file])}\")\n",
    "            print(\"  将使用固定值0作为LAI卫星数据\")\n",
    "            df['LAI_Satellite'] = 0.0\n",
    "        \n",
    "        # ========== 5. 处理植被高度数据 ==========\n",
    "        print(\"\\n处理植被高度数据...\")\n",
    "        df['Hveg'] = np.nan\n",
    "        \n",
    "        hveg_file = r\"E:\\data\\CanopyHeight\\CH.mat\"\n",
    "        if os.path.exists(hveg_file):\n",
    "            print(f\"  加载植被高度数据: {hveg_file}\")\n",
    "            hveg_data = read_hdf5_mat(hveg_file, expected_keys=['CH', 'ch'])\n",
    "            \n",
    "            # 直接获取高度数据\n",
    "            hveg_key = list(hveg_data.keys())[0] if hveg_data else None\n",
    "            \n",
    "            if hveg_key:\n",
    "                hveg_values = hveg_data[hveg_key]\n",
    "                df['Hveg'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        hveg_values\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加植被高度列，数据形状: {hveg_values.shape}\")\n",
    "            else:\n",
    "                print(f\"  警告: 无法找到Hveg变量\")\n",
    "                df['Hveg'] = np.nan\n",
    "        else:\n",
    "            print(f\"  警告: Hveg文件不存在 - {hveg_file}\")\n",
    "            df['Hveg'] = np.nan\n",
    "        \n",
    "        # ========== 6. 保存结果 ==========\n",
    "        output_file_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\"\n",
    "        print(f\"\\n保存结果到: {output_file_path}\")\n",
    "        df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        # 保存插值详细信息到Excel\n",
    "        if interpolation_details:\n",
    "            details_df = pd.DataFrame(interpolation_details)\n",
    "            details_path = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\interpolation_details.xlsx\"\n",
    "            details_df.to_excel(details_path, index=False)\n",
    "            print(f\"插值详细信息保存到: {details_path}\")\n",
    "        else:\n",
    "            print(\"警告: 没有插值详细信息可保存\")\n",
    "        \n",
    "        # ========== 7. 统计报告 ==========\n",
    "        print(\"\\n处理完成!\")\n",
    "        print(f\"总记录数: {len(df)}\")\n",
    "        print(f\"插值操作次数: {len(interpolation_details)}\")\n",
    "        \n",
    "        if interpolation_details:\n",
    "            # 显示前3次插值的详细信息\n",
    "            print(\"\\n前3次插值的详细信息:\")\n",
    "            for i, detail in enumerate(interpolation_details[:3]):\n",
    "                print(f\"\\n插值 #{i+1}\")\n",
    "                print(f\"  类型: {detail['type']}\")\n",
    "                print(f\"  目标位置: ({detail['target_lat']:.6f}, {detail['target_lon']:.6f})\")\n",
    "                print(f\"  网格形状: {detail['grid_shape']}\")\n",
    "                \n",
    "                if detail['type'] == 'bilinear':\n",
    "                    print(f\"  使用的4个网格点:\")\n",
    "                    for j in range(4):\n",
    "                        print(f\"    点{j+1}: 行 {detail['rows'][j]}, 列 {detail['cols'][j]} - \" +\n",
    "                              f\"位置 ({detail['lat_values'][j]:.6f}, {detail['lon_values'][j]:.6f}) - \" +\n",
    "                              f\"值: {detail['values'][j]:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  最近邻点: 行 {detail['row']}, 列 {detail['col']} - \" +\n",
    "                          f\"位置 ({detail['lat_values'][0]:.6f}, {detail['lon_values'][0]:.6f}) - \" +\n",
    "                          f\"值: {detail['values'][0]:.6f}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"错误详细信息:\")\n",
    "        print(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "# ========================== 主程序 ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"开始处理SMEX02数据插值任务\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"错误: 输入文件不存在 - {input_file}\")\n",
    "        print(f\"请检查路径: {os.path.abspath(input_file)}\")\n",
    "    else:\n",
    "        print(f\"输入文件: {input_file}\")\n",
    "        print(f\"输出将保存到: E:\\\\data\\\\VWC\\\\test-VWC\\\\NSIDC_0666\\\\SMEX02\\\\processed_SMEX02V_ML.xlsx\")\n",
    "        \n",
    "        success = process_smapvex_data(input_file)\n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务成功完成!\")\n",
    "            print(\"=\"*30)\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务失败，请检查错误信息\")\n",
    "            print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0c1e55-6cd3-4fa8-bf0a-714786fdcec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载测试数据: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\n",
      "加载完成，总样本数: 104\n",
      "  合并SM和sm列...\n",
      "  合并完成，保留SM列\n",
      "\n",
      "处理 Ku-H 模型: RFR_Ku_Hpol_Type1.pkl\n",
      "  有效样本数: 61 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.4445, R²: -2.9965\n",
      "\n",
      "处理 Ku-V 模型: RFR_Ku_Vpol_Type1.pkl\n",
      "  有效样本数: 35 (删除缺失值后)\n",
      "  预测完成 - RMSE: 5.0307, R²: -6.8198\n",
      "\n",
      "处理 Ku-HV 模型: RFR_Ku_HVpol_Type1.pkl\n",
      "  有效样本数: 35 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.4030, R²: -2.5782\n",
      "\n",
      "处理 C-H 模型: RFR_C_Hpol_Type1.pkl\n",
      "  有效样本数: 35 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.2484, R²: -4.5769\n",
      "\n",
      "处理 C-V 模型: RFR_C_Vpol_Type1.pkl\n",
      "  有效样本数: 13 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.7594, R²: -3.5016\n",
      "\n",
      "处理 C-HV 模型: RFR_C_HVpol_Type1.pkl\n",
      "  有效样本数: 13 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.2189, R²: -2.3003\n",
      "\n",
      "处理 X-H 模型: RFR_X_Hpol_Type1.pkl\n",
      "  有效样本数: 65 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.2207, R²: -5.0884\n",
      "\n",
      "处理 X-V 模型: RFR_X_Vpol_Type1.pkl\n",
      "  有效样本数: 43 (删除缺失值后)\n",
      "  预测完成 - RMSE: 3.2505, R²: -2.5602\n",
      "\n",
      "处理 X-HV 模型: RFR_X_HVpol_Type1.pkl\n",
      "  有效样本数: 43 (删除缺失值后)\n",
      "  预测完成 - RMSE: 2.9027, R²: -1.8390\n",
      "\n",
      "所有预测结果已保存至: model_predictions_results_SMEX02.xlsx\n",
      "\n",
      "正在绘制组合散点图...\n",
      "  组合散点图已保存至: figures\\SMEX02_VWC_Scatter.png\n",
      "\n",
      "所有处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 机器学习结果填充，和实测值对比\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# 设置常量\n",
    "TEST_FILE = r\"E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\"\n",
    "MODEL_DIR = \"models\"\n",
    "SAVE_RESULTS = \"model_predictions_results_SMEX02.xlsx\"\n",
    "FIG_DIR = \"figures\"\n",
    "\n",
    "# 定义波段和极化组合\n",
    "BANDS = ['Ku', 'C', 'X']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 波段颜色定义\n",
    "BAND_COLORS = {\n",
    "    'Ku': (253/255, 173/255, 115/255, 0.7),\n",
    "    'C': (178/255, 125/255, 104/255, 0.7),\n",
    "    'X': (224/255, 104/255, 46/255, 0.7)\n",
    "}\n",
    "\n",
    "# 极化类型标记定义\n",
    "POL_MARKERS = {\n",
    "    'H': 's',  # 方形\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 'o'  # 圆形\n",
    "}\n",
    "\n",
    "def normalize_LAI(lai_series):\n",
    "    \"\"\"对LAI进行归一化\"\"\"\n",
    "    return lai_series.clip(0, 6) / 6\n",
    "\n",
    "def normalize_VOD(vod_series):\n",
    "    \"\"\"对VOD进行归一化\"\"\"\n",
    "    return vod_series.clip(0, 2) / 2\n",
    "\n",
    "# PFT列名映射字典\n",
    "PFT_MAPPING = {\n",
    "    'PFT_grassnat': 'Grass_nat',\n",
    "    'PFT_grassman': 'Grass_man',\n",
    "    'PFT_shrubbd': 'Shrub_bd',\n",
    "    'PFT_shrubbe': 'Shrub_be',\n",
    "    'PFT_shrubnd': 'Shrub_nd',\n",
    "    'PFT_shrubne': 'Shrub_ne',\n",
    "    'PFT_treebd': 'Tree_bd',\n",
    "    'PFT_treebe': 'Tree_be',\n",
    "    'PFT_treend': 'Tree_nd',\n",
    "    'PFT_treene': 'Tree_ne'\n",
    "}\n",
    "\n",
    "def get_model_columns(band, pol):\n",
    "    \"\"\"获取指定模型所需的列名\"\"\"\n",
    "    base_columns = [\n",
    "        'VWC-Field',  # 修改点1: VWC改为VWC-Field\n",
    "        'LAI_Satellite',  # 修改点2: LAI改为LAI_Satellite\n",
    "        'SM'  # 处理后合并的土壤湿度列\n",
    "    ]\n",
    "    \n",
    "    # 添加所有PFT列\n",
    "    base_columns.extend(PFT_MAPPING.keys())\n",
    "    \n",
    "    # 根据极化类型添加VOD列\n",
    "    if pol == 'H':\n",
    "        return base_columns + [f'{band.lower()}_vod_H']\n",
    "    elif pol == 'V':\n",
    "        return base_columns + [f'{band.lower()}_vod_V']\n",
    "    elif pol == 'HV':\n",
    "        return base_columns + [f'{band.lower()}_vod_H', f'{band.lower()}_vod_V']\n",
    "\n",
    "def get_feature_order(pol):\n",
    "    \"\"\"获取特征列的顺序（模型期望的列顺序）\"\"\"\n",
    "    base_features = [\n",
    "        'LAI', 'SM',  # 注意：准备时会重命名LAI_Satellite为LAI\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    if pol in ['H', 'V']:\n",
    "        return ['VOD'] + base_features\n",
    "    elif pol == 'HV':\n",
    "        return ['VOD-Hpol', 'VOD-Vpol'] + base_features\n",
    "\n",
    "def prepare_input_data(df, band, pol):\n",
    "    \"\"\"为指定模型准备输入数据\"\"\"\n",
    "    # 创建数据副本\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 归一化处理 - 使用新的LAI_Satellite列\n",
    "    data['LAI'] = normalize_LAI(data['LAI_Satellite'])  # 修改点4: 使用LAI_Satellite\n",
    "    \n",
    "    # 2. 处理VOD列\n",
    "    if pol == 'H':\n",
    "        vod_col = f'{band.lower()}_vod_H'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'V':\n",
    "        vod_col = f'{band.lower()}_vod_V'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'HV':\n",
    "        # 重命名列以匹配模型训练时的特征名\n",
    "        data = data.rename(columns={\n",
    "            f'{band.lower()}_vod_H': 'VOD-Hpol',\n",
    "            f'{band.lower()}_vod_V': 'VOD-Vpol'\n",
    "        })\n",
    "        # 归一化处理\n",
    "        data['VOD-Hpol'] = normalize_VOD(data['VOD-Hpol'])\n",
    "        data['VOD-Vpol'] = normalize_VOD(data['VOD-Vpol'])\n",
    "    \n",
    "    # 3. 重命名PFT列为模型期望的名称\n",
    "    data = data.rename(columns=PFT_MAPPING)\n",
    "    \n",
    "    # 4. 按模型要求排序特征列\n",
    "    feature_order = get_feature_order(pol)\n",
    "    \n",
    "    # 5. 确保特征顺序与模型训练时一致\n",
    "    # 获取实际存在的列\n",
    "    existing_columns = [col for col in feature_order if col in data.columns]\n",
    "    \n",
    "    # 检查是否有缺失的特征\n",
    "    missing_features = set(feature_order) - set(existing_columns)\n",
    "    if missing_features:\n",
    "        print(f\"  警告: 缺少特征列: {', '.join(missing_features)}\")\n",
    "        # 为缺失的特征添加空列\n",
    "        for col in missing_features:\n",
    "            data[col] = np.nan\n",
    "    \n",
    "    # 返回按正确顺序排列的特征\n",
    "    return data[feature_order]\n",
    "\n",
    "def plot_combined_scatter(actual, predictions_dict):\n",
    "    \"\"\"\n",
    "    绘制组合散点图，包含所有波段和极化类型\n",
    "    \n",
    "    参数:\n",
    "    actual -- 实际值 (Series)\n",
    "    predictions_dict -- 字典结构: {\n",
    "        'H': {band: pred_series},\n",
    "        'V': {band: pred_series},\n",
    "        'HV': {band: pred_series}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # 存储所有组合的RMSE值\n",
    "    rmse_values = {}\n",
    "    \n",
    "    # 收集所有数据点\n",
    "    max_val = 0\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            pred_series = predictions_dict[pol].get(band)\n",
    "            \n",
    "            if pred_series is not None and not pred_series.isnull().all():\n",
    "                # 创建实际值和预测值的临时DF\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'actual': actual,\n",
    "                    'pred': pred_series\n",
    "                }).dropna()\n",
    "                \n",
    "                if not temp_df.empty:\n",
    "                    # 计算RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(temp_df['actual'], temp_df['pred']))\n",
    "                    rmse_values[f\"{band}-{pol}\"] = rmse\n",
    "                    \n",
    "                    # 更新最大值\n",
    "                    band_max = max(temp_df['actual'].max(), temp_df['pred'].max())\n",
    "                    if band_max > max_val:\n",
    "                        max_val = band_max\n",
    "                    \n",
    "                    # 绘制散点\n",
    "                    plt.scatter(\n",
    "                        temp_df['actual'], temp_df['pred'], \n",
    "                        alpha=0.7, \n",
    "                        color=BAND_COLORS[band],\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        s=50,\n",
    "                        edgecolors='none',\n",
    "                        zorder=2,\n",
    "                        label=f\"{band}-{pol}\"\n",
    "                    )\n",
    "    \n",
    "    # 如果没有数据可绘制，直接返回\n",
    "    if not rmse_values:\n",
    "        print(\"  警告: 没有有效的预测数据!\")\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val *= 1.05\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围\n",
    "    plt.xlim(0, max_val)\n",
    "    plt.ylim(0, max_val)\n",
    "    \n",
    "    # 设置坐标轴标签\n",
    "    plt.xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('RF VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title('SMEX08 Insitu VWC', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "    \n",
    "    # 添加RMSE文本（左上角，3×3网格布局）\n",
    "    if rmse_values:\n",
    "        # 设置文本位置\n",
    "        x_pos = 0.05\n",
    "        y_pos = 0.95\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.text(x_pos, y_pos, 'RMSE (kg/m²):', \n",
    "                 transform=ax.transAxes,\n",
    "                 fontsize=12,\n",
    "                 fontweight='bold',\n",
    "                 verticalalignment='top')\n",
    "        \n",
    "        y_pos -= 0.05\n",
    "        \n",
    "        # 遍历每个波段\n",
    "        for band_idx, band in enumerate(BANDS):\n",
    "            # 遍历每个极化类型\n",
    "            for pol_idx, pol in enumerate(POLS):\n",
    "                # 计算位置\n",
    "                text_x = x_pos + pol_idx * 0.15\n",
    "                text_y = y_pos - band_idx * 0.08\n",
    "                \n",
    "                # 获取RMSE值\n",
    "                rmse = rmse_values.get(f\"{band}-{pol}\", None)\n",
    "                \n",
    "                if rmse is not None:\n",
    "                    # 绘制标记\n",
    "                    plt.scatter(\n",
    "                        text_x, text_y, \n",
    "                        transform=ax.transAxes,\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        color=BAND_COLORS[band],\n",
    "                        s=80,\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                    \n",
    "                    # 添加文本\n",
    "                    plt.text(\n",
    "                        text_x + 0.01, text_y, \n",
    "                        f\"{band}-{pol}: {rmse:.3f}\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center'\n",
    "                    )\n",
    "                else:\n",
    "                    # 添加缺失值标记\n",
    "                    plt.text(\n",
    "                        text_x, text_y, \n",
    "                        f\"{band}-{pol}: N/A\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center',\n",
    "                        color='gray'\n",
    "                    )\n",
    "    \n",
    "    # 添加网格线\n",
    "    plt.grid(True, linestyle='--', alpha=0.3, zorder=0)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(FIG_DIR, exist_ok=True)\n",
    "    \n",
    "    # 保存图像\n",
    "    fig_path = os.path.join(FIG_DIR, 'SMEX02_VWC_Scatter.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  组合散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def predict_and_evaluate():\n",
    "    \"\"\"主函数：加载所有模型进行预测并评估结果\"\"\"\n",
    "    # 1. 加载测试数据\n",
    "    print(f\"正在加载测试数据: {TEST_FILE}\")\n",
    "    \n",
    "    # 收集所有可能的列\n",
    "    all_columns = set(['VWC-Field', 'LAI_Satellite'])  # 修改点3: 更新列名\n",
    "    \n",
    "    # 添加土壤湿度相关列 (修改点5: 添加sm列)\n",
    "    all_columns.update(['SM', 'sm'])\n",
    "    \n",
    "    # 添加所有PFT列\n",
    "    all_columns.update(PFT_MAPPING.keys())\n",
    "    \n",
    "    # 添加所有VOD列\n",
    "    for band in BANDS:\n",
    "        all_columns.add(f'{band.lower()}_vod_H')\n",
    "        all_columns.add(f'{band.lower()}_vod_V')\n",
    "    \n",
    "    # 读取Excel文件\n",
    "    test_df = pd.read_excel(TEST_FILE, usecols=list(all_columns))\n",
    "    print(f\"加载完成，总样本数: {len(test_df)}\")\n",
    "    \n",
    "    # 修改点6: 土壤湿度合并逻辑\n",
    "    # 优先使用SM，如果SM没有值则使用sm\n",
    "    if 'SM' in test_df.columns and 'sm' in test_df.columns:\n",
    "        print(\"  合并SM和sm列...\")\n",
    "        # 合并土壤湿度：优先使用SM，如果SM没有值则使用sm\n",
    "        test_df['SM'] = test_df['SM'].combine_first(test_df['sm'])\n",
    "        # 删除多余的sm列\n",
    "        test_df = test_df.drop(columns=['sm'])\n",
    "        print(\"  合并完成，保留SM列\")\n",
    "    elif 'sm' in test_df.columns:\n",
    "        print(\"  只有sm列，重命名为SM\")\n",
    "        test_df = test_df.rename(columns={'sm': 'SM'})\n",
    "    elif 'SM' in test_df.columns:\n",
    "        print(\"  只有SM列，无需处理\")\n",
    "    else:\n",
    "        print(\"  警告: 没有找到任何土壤湿度列!\")\n",
    "        # 添加一个空的SM列\n",
    "        test_df['SM'] = np.nan\n",
    "    \n",
    "    # 确保只有一个SM列\n",
    "    if sum(col == 'SM' for col in test_df.columns) > 1:\n",
    "        print(\"  警告: 存在多个SM列，删除重复列\")\n",
    "        # 保留第一个SM列，删除其他SM列\n",
    "        sm_cols = [col for col in test_df.columns if col == 'SM']\n",
    "        for col in sm_cols[1:]:\n",
    "            test_df = test_df.drop(columns=[col])\n",
    "    # 存储所有预测结果\n",
    "    results = pd.DataFrame(index=test_df.index)\n",
    "    results['Actual_VWC'] = test_df['VWC-Field']  # 修改点7: 使用新列名\n",
    "    \n",
    "    # 为每个极化类型存储预测结果\n",
    "    predictions_by_pol = {\n",
    "        'H': {band: None for band in BANDS},\n",
    "        'V': {band: None for band in BANDS},\n",
    "        'HV': {band: None for band in BANDS}\n",
    "    }\n",
    "    \n",
    "    # 2. 对每个模型进行预测\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            model_name = f\"RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "            model_path = os.path.join(MODEL_DIR, model_name)\n",
    "            \n",
    "            print(f\"\\n处理 {band}-{pol} 模型: {model_name}\")\n",
    "            \n",
    "            # 准备输入数据\n",
    "            model_cols = get_model_columns(band, pol)\n",
    "            model_data = test_df[model_cols].copy()\n",
    "            \n",
    "            # 修改点8: 在土壤湿度合并后，跳过两个值都没有的行\n",
    "            # 如果某行的两个土壤湿度都没有值，则不把这行输入至模型\n",
    "            model_data = model_data.dropna(subset=['SM'])\n",
    "            \n",
    "            # 删除其他缺失值\n",
    "            clean_data = model_data.dropna()\n",
    "            print(f\"  有效样本数: {len(clean_data)} (删除缺失值后)\")\n",
    "            \n",
    "            if len(clean_data) == 0:\n",
    "                print(\"  警告: 无有效样本可用于此模型!\")\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "                continue\n",
    "            \n",
    "            # 预处理输入数据\n",
    "            try:\n",
    "                X_input = prepare_input_data(clean_data, band, pol)\n",
    "                \n",
    "                # 加载模型并进行预测\n",
    "                if os.path.exists(model_path):\n",
    "                    model = joblib.load(model_path)\n",
    "                    # 添加特征顺序验证\n",
    "                    if hasattr(model, 'feature_names_in_'):\n",
    "                        # 获取模型期望的特征顺序\n",
    "                        expected_features = model.feature_names_in_\n",
    "                        \n",
    "                        # 验证特征顺序\n",
    "                        if list(X_input.columns) != list(expected_features):\n",
    "                            print(f\"  调整特征顺序以匹配模型期望...\")\n",
    "                            print(f\"  当前特征顺序: {list(X_input.columns)}\")\n",
    "                            print(f\"  模型期望顺序: {list(expected_features)}\")\n",
    "                            \n",
    "                            # 调整特征顺序\n",
    "                            X_input = X_input[expected_features]\n",
    "                    \n",
    "                    predictions = model.predict(X_input)\n",
    "                    \n",
    "                    # 存储预测结果\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    results.loc[clean_data.index, f\"{band}_{pol}_Predicted\"] = predictions\n",
    "                    \n",
    "                    # 存储到对应极化类型的字典\n",
    "                    predictions_by_pol[pol][band] = results[f\"{band}_{pol}_Predicted\"].copy()\n",
    "                    \n",
    "                    # 计算评估指标\n",
    "                    actual = clean_data['VWC-Field']  # 修改点9: 使用新列名\n",
    "                    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "                    r2 = r2_score(actual, predictions)\n",
    "                    print(f\"  预测完成 - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  警告: 未找到模型文件 {model_path}!\")\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    predictions_by_pol[pol][band] = None\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"  预测失败: {str(e)}\")\n",
    "                # 打印更详细的错误信息\n",
    "                traceback.print_exc()\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "    \n",
    "    # 3. 保存结果\n",
    "    results.to_excel(SAVE_RESULTS)\n",
    "    print(f\"\\n所有预测结果已保存至: {SAVE_RESULTS}\")\n",
    "    \n",
    "    # 4. 绘制组合散点图\n",
    "    print(\"\\n正在绘制组合散点图...\")\n",
    "    plot_combined_scatter(\n",
    "        results['Actual_VWC'], \n",
    "        predictions_by_pol\n",
    "    )\n",
    "    \n",
    "    return results, predictions_by_pol\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    results, predictions_by_pol = predict_and_evaluate()\n",
    "    print(\"\\n所有处理完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92495c0a-b33c-45cb-9b42-c8a423218e39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.SMAPVEX2016-Manitoba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7424c7-5a46-4701-b9b8-fb46941b9abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1：处理KMZ站点文件...\n",
      "步骤2：读取并转换坐标系...\n",
      "步骤3：提取经纬度...\n",
      "步骤4：处理CSV站点数据...\n",
      "处理: SV16M_V_CropHeight_Vers3.csv\n",
      "已添加经纬度: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropHeight_Vers3_with_coords.csv\n",
      "处理: SV16M_V_CropBiomass_Vers4.csv\n",
      "已添加经纬度: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords.csv\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 将kml文件的经纬度信息整合至表格中。\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# 配置路径\n",
    "base_path = Path(r\"E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\")\n",
    "output_dir = base_path / \"Processed_Results\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def extract_kmz(kmz_path, output_name):\n",
    "    \"\"\"安全解压KMZ文件\"\"\"\n",
    "    extract_dir = output_dir / output_name\n",
    "    extract_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(kmz_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    \n",
    "    for file in extract_dir.glob(\"**/*.kml\"):\n",
    "        return file\n",
    "    raise FileNotFoundError(f\"在 {kmz_path} 中未找到KML文件\")\n",
    "\n",
    "def process_field_sites():\n",
    "    \"\"\"处理站点数据并添加经纬度\"\"\"\n",
    "    print(\"步骤1：处理KMZ站点文件...\")\n",
    "    sites_kml = extract_kmz(\n",
    "        base_path / \"SV16M_V_FieldSites.kmz\",\n",
    "        \"FieldSites_Extracted\"\n",
    "    )\n",
    "    \n",
    "    print(\"步骤2：读取并转换坐标系...\")\n",
    "    # 读取KML数据\n",
    "    sites = gpd.read_file(str(sites_kml))\n",
    "    \n",
    "    # 转换为文档指定的原始坐标系 (EPSG:3158)\n",
    "    sites_nad83 = sites.to_crs(\"EPSG:3158\")\n",
    "    \n",
    "    # 转换为WGS84 (EPSG:4326)\n",
    "    sites_wgs = sites_nad83.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    print(\"步骤3：提取经纬度...\")\n",
    "    # 创建包含坐标的DataFrame\n",
    "    sites_coords = pd.DataFrame({\n",
    "        'Name': sites_wgs['Name'],\n",
    "        'Longitude': sites_wgs.geometry.x,\n",
    "        'Latitude': sites_wgs.geometry.y\n",
    "    })\n",
    "    \n",
    "    print(\"步骤4：处理CSV站点数据...\")\n",
    "    # 扫描所有CSV文件\n",
    "    csv_files = [\n",
    "        \"SV16M_V_CropHeight_Vers3.csv\",\n",
    "        \"SV16M_V_CropBiomass_Vers4.csv\"\n",
    "    ]\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        csv_path = base_path / csv_file\n",
    "        if not csv_path.exists():\n",
    "            print(f\"警告: 文件不存在 {csv_file}\")\n",
    "            continue\n",
    "            \n",
    "        # 读取CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 检查是否包含SITE_ID列\n",
    "        if 'SITE_ID' not in df.columns:\n",
    "            print(f\"跳过: {csv_file} 不包含SITE_ID列\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"处理: {csv_file}\")\n",
    "        \n",
    "        # 合并坐标数据\n",
    "        merged = df.merge(\n",
    "            sites_coords, \n",
    "            left_on='SITE_ID', \n",
    "            right_on='Name',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # 移除辅助列\n",
    "        merged = merged.drop(columns=['Name'], errors='ignore')\n",
    "        merged['SITE_ID'] = merged['SITE_ID'].astype(str)\n",
    "        \n",
    "        # 保存结果\n",
    "        output_path = output_dir / f\"{csv_path.stem}_with_coords.csv\"\n",
    "        merged.to_csv(output_path, index=False, sep='\\t')\n",
    "        print(f\"已添加经纬度: {output_path}\")\n",
    "    \n",
    "    print(\"处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_field_sites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eeff289-4c72-4654-8032-c6140f783fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "开始处理SMAPVEX16 Manitoba数据插值任务\n",
      "============================================================\n",
      "输入文件: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords.csv\n",
      "输出将保存到: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\n",
      "读取原始CSV文件: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords.csv\n",
      "成功读取 1400 条记录\n",
      "日期范围: 2016-06-13 至 2016-07-21\n",
      "\n",
      "处理PFT数据: E:\\data\\ESACCI PFT\\Resample\\Data\\2016.mat\n",
      "  文件中可用的PFT变量: water, bare, snowice, built, grassnat, grassman, shrubbd, shrubbe, shrubnd, shrubne, treebd, treebe, treend, treene\n",
      "  已添加列: PFT_water\n",
      "  已添加列: PFT_bare\n",
      "  已添加列: PFT_snowice\n",
      "  已添加列: PFT_built\n",
      "  已添加列: PFT_grassnat\n",
      "  已添加列: PFT_grassman\n",
      "  已添加列: PFT_shrubbd\n",
      "  已添加列: PFT_shrubbe\n",
      "  已添加列: PFT_shrubnd\n",
      "  已添加列: PFT_shrubne\n",
      "  已添加列: PFT_treebd\n",
      "  已添加列: PFT_treebe\n",
      "  已添加列: PFT_treend\n",
      "  已添加列: PFT_treene\n",
      "\n",
      "处理VOD数据:\n",
      "  处理日期: 20160613, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160613_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160615, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160615_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160618, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160618_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160620, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160620_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160627, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160627_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160628, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160628_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160705, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160705_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160706, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160706_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160711, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160711_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160712, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160712_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160717, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160717_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160720, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160720_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "  处理日期: 20160721, 文件: MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_20160721_V0.nc4.mat\n",
      "    已更新: SM\n",
      "    已更新: ku_vod_H\n",
      "    已更新: ku_vod_V\n",
      "    已更新: x_vod_H\n",
      "    已更新: x_vod_V\n",
      "    已更新: c_vod_H\n",
      "    已更新: c_vod_V\n",
      "\n",
      "处理LAI卫星数据...\n",
      "根据数据日期范围 (2016-06-13 至 2016-07-21)\n",
      "确定需要 4 个LAI文件: 2016-05, 2016-06, 2016-07, 2016-08\n",
      "  加载LAI数据 (2016-05-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2016-05-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  加载LAI数据 (2016-06-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2016-06-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  加载LAI数据 (2016-07-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2016-07-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "  加载LAI数据 (2016-08-15): E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2016-08-01.tif.mat\n",
      "    成功读取LAI变量 'lai'，数据形状: (1800, 3600)\n",
      "\n",
      "插值LAI数据到观测点...\n",
      "  处理日期: 2016-06-13, 使用日期: 2016-05-15 和 2016-06-15, 权重: 0.94\n",
      "    平均LAI: 1.5521, 成功插值 96 条记录\n",
      "  处理日期: 2016-06-15, 使用日期: 2016-05-15 和 2016-06-15, 权重: 1.00\n",
      "    平均LAI: 1.5750, 成功插值 83 条记录\n",
      "  处理日期: 2016-06-18, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.10\n",
      "    平均LAI: 1.5877, 成功插值 102 条记录\n",
      "  处理日期: 2016-06-20, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.17\n",
      "    平均LAI: 1.5962, 成功插值 88 条记录\n",
      "  处理日期: 2016-06-27, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.40\n",
      "    平均LAI: 1.6258, 成功插值 66 条记录\n",
      "  处理日期: 2016-06-28, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.43\n",
      "    平均LAI: 1.6300, 成功插值 92 条记录\n",
      "  处理日期: 2016-07-05, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.67\n",
      "    平均LAI: 1.6597, 成功插值 68 条记录\n",
      "  处理日期: 2016-07-06, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.70\n",
      "    平均LAI: 1.6639, 成功插值 85 条记录\n",
      "  处理日期: 2016-07-11, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.87\n",
      "    平均LAI: 1.6851, 成功插值 173 条记录\n",
      "  处理日期: 2016-07-12, 使用日期: 2016-06-15 和 2016-07-15, 权重: 0.90\n",
      "    平均LAI: 1.6893, 成功插值 166 条记录\n",
      "  处理日期: 2016-07-17, 使用日期: 2016-07-15 和 2016-08-15, 权重: 0.06\n",
      "    平均LAI: 1.6909, 成功插值 188 条记录\n",
      "  处理日期: 2016-07-20, 使用日期: 2016-07-15 和 2016-08-15, 权重: 0.16\n",
      "    平均LAI: 1.6742, 成功插值 152 条记录\n",
      "  处理日期: 2016-07-21, 使用日期: 2016-07-15 和 2016-08-15, 权重: 0.19\n",
      "    平均LAI: 1.6686, 成功插值 16 条记录\n",
      "\n",
      "处理植被高度数据...\n",
      "  加载植被高度数据: E:\\data\\CanopyHeight\\CH.mat\n",
      "  已添加植被高度列，数据形状: (1800, 3600)\n",
      "\n",
      "保存结果到: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\n",
      "插值详细信息保存到: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\interpolation_details.csv\n",
      "\n",
      "处理完成!\n",
      "总记录数: 1400\n",
      "插值操作次数: 31625\n",
      "填充的LAI值数量: 1375\n",
      "填充的VOD值数量: 1375\n",
      "\n",
      "==============================\n",
      "任务成功完成!\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 数据填充\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 全局变量记录插值详细信息\n",
    "interpolation_details = []\n",
    "\n",
    "# ====================== 改进的MAT文件读取函数 ======================\n",
    "def read_hdf5_mat(file_path, expected_keys=None):\n",
    "    \"\"\"读取MATLAB v7.3格式的HDF5文件，优先查找特定变量\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = {}\n",
    "            \n",
    "            def visitor_func(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    if h5py.check_string_dtype(obj.dtype):\n",
    "                        value = ''.join(chr(c) for c in obj[:])\n",
    "                    else:\n",
    "                        value = np.array(obj)\n",
    "                    if value.ndim >= 2:\n",
    "                        value = value.T\n",
    "                    base_name = name.split('/')[-1]\n",
    "                    data[base_name] = value\n",
    "            \n",
    "            f.visititems(visitor_func)\n",
    "            \n",
    "            # 优先查找预期变量\n",
    "            if expected_keys:\n",
    "                for key in expected_keys:\n",
    "                    if key in data:\n",
    "                        return {key: data[key]}\n",
    "            \n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"  读取HDF5 MAT文件失败: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# ====================== 改进的双线性插值函数 ======================\n",
    "def bilinear_interpolation_with_details(lat_grid, lon_grid, target_lat, target_lon, grid_data):\n",
    "    \"\"\"\n",
    "    执行双线性插值并记录详细信息\n",
    "    :param lat_grid: 网格纬度数组 (1D, 从北向南递减)\n",
    "    :param lon_grid: 网格经度数组 (1D, 从西向东递增)\n",
    "    :param target_lat: 目标点纬度\n",
    "    :param target_lon: 目标点经度\n",
    "    :param grid_data: 网格数据 (2D数组, 形状为(len(lat_grid), len(lon_grid)))\n",
    "    :return: 插值值\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        # 记录网格形状\n",
    "        grid_shape = grid_data.shape\n",
    "        \n",
    "        # 验证网格尺寸\n",
    "        if len(lat_grid) != grid_shape[0] or len(lon_grid) != grid_shape[1]:\n",
    "            print(f\"警告: 网格尺寸不匹配! 纬度网格: {len(lat_grid)}, 经度网格: {len(lon_grid)}, 数据形状: {grid_shape}\")\n",
    "            return np.nan\n",
    "        \n",
    "        # 查找最近的纬度索引（纬度从北向南递减）\n",
    "        # 纬度网格: 89.95 (北) -> -89.95 (南)\n",
    "        lat_idx = np.argmin(np.abs(lat_grid - target_lat))\n",
    "        \n",
    "        # 查找最近的经度索引（经度从西向东递增）\n",
    "        # 经度网格: -179.95 (西) -> 179.95 (东)\n",
    "        lon_idx = np.argmin(np.abs(lon_grid - target_lon))\n",
    "        \n",
    "        # 确定四个角点索引\n",
    "        # 纬度处理：目标点位于两个纬度网格点之间\n",
    "        if lat_idx == 0:\n",
    "            lat_idx0, lat_idx1 = 0, 1\n",
    "        elif lat_idx == len(lat_grid) - 1:\n",
    "            lat_idx0, lat_idx1 = len(lat_grid) - 2, len(lat_grid) - 1\n",
    "        else:\n",
    "            if target_lat > lat_grid[lat_idx]:\n",
    "                # 目标纬度大于当前网格点纬度（更北）\n",
    "                if lat_idx > 0:\n",
    "                    lat_idx0 = lat_idx - 1\n",
    "                    lat_idx1 = lat_idx\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "            else:\n",
    "                # 目标纬度小于当前网格点纬度（更南）\n",
    "                if lat_idx < len(lat_grid) - 1:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx + 1\n",
    "                else:\n",
    "                    lat_idx0 = lat_idx\n",
    "                    lat_idx1 = lat_idx\n",
    "        \n",
    "        # 经度处理：目标点位于两个经度网格点之间\n",
    "        if lon_idx == 0:\n",
    "            lon_idx0, lon_idx1 = 0, 1\n",
    "        elif lon_idx == len(lon_grid) - 1:\n",
    "            lon_idx0, lon_idx1 = len(lon_grid) - 2, len(lon_grid) - 1\n",
    "        else:\n",
    "            if target_lon > lon_grid[lon_idx]:\n",
    "                # 目标经度大于当前网格点经度（更东）\n",
    "                if lon_idx < len(lon_grid) - 1:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx + 1\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "            else:\n",
    "                # 目标经度小于当前网格点经度（更西）\n",
    "                if lon_idx > 0:\n",
    "                    lon_idx0 = lon_idx - 1\n",
    "                    lon_idx1 = lon_idx\n",
    "                else:\n",
    "                    lon_idx0 = lon_idx\n",
    "                    lon_idx1 = lon_idx\n",
    "        \n",
    "        # 获取四个角点值\n",
    "        Q00 = grid_data[lat_idx0, lon_idx0]\n",
    "        Q01 = grid_data[lat_idx0, lon_idx1]\n",
    "        Q10 = grid_data[lat_idx1, lon_idx0]\n",
    "        Q11 = grid_data[lat_idx1, lon_idx1]\n",
    "        \n",
    "        # 四个角点坐标\n",
    "        y0 = lat_grid[lat_idx0]\n",
    "        y1 = lat_grid[lat_idx1]\n",
    "        x0 = lon_grid[lon_idx0]\n",
    "        x1 = lon_grid[lon_idx1]\n",
    "        \n",
    "        # 如果有NaN，使用最接近的点\n",
    "        if np.isnan(Q00) or np.isnan(Q01) or np.isnan(Q10) or np.isnan(Q11):\n",
    "            result = grid_data[lat_idx, lon_idx]\n",
    "            details = {\n",
    "                'type': 'nearest',\n",
    "                'row': lat_idx,\n",
    "                'col': lon_idx,\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [grid_data[lat_idx, lon_idx]],\n",
    "                'lat_values': [lat_grid[lat_idx]],\n",
    "                'lon_values': [lon_grid[lon_idx]]\n",
    "            }\n",
    "        else:\n",
    "            # 双线性插值公式\n",
    "            dx = (target_lon - x0) / (x1 - x0) if (x1 - x0) != 0 else 0\n",
    "            dy = (target_lat - y0) / (y1 - y0) if (y1 - y0) != 0 else 0\n",
    "            result = (1 - dx) * (1 - dy) * Q00 + dx * (1 - dy) * Q01 + (1 - dx) * dy * Q10 + dx * dy * Q11\n",
    "            \n",
    "            details = {\n",
    "                'type': 'bilinear',\n",
    "                'rows': [lat_idx0, lat_idx0, lat_idx1, lat_idx1],\n",
    "                'cols': [lon_idx0, lon_idx1, lon_idx0, lon_idx1],\n",
    "                'target_lat': target_lat,\n",
    "                'target_lon': target_lon,\n",
    "                'grid_shape': grid_shape,\n",
    "                'values': [Q00, Q01, Q10, Q11],\n",
    "                'lat_values': [y0, y0, y1, y1],\n",
    "                'lon_values': [x0, x1, x0, x1]\n",
    "            }\n",
    "        \n",
    "        # 保存插值详细信息\n",
    "        interpolation_details.append(details)\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"插值错误: {str(e)}\")\n",
    "        return np.nan\n",
    "\n",
    "# ====================== 主处理函数 ======================\n",
    "def process_smapvex16_manitoba(input_file_path):\n",
    "    \"\"\"\n",
    "    处理SMAPVEX16 Manitoba数据，执行多种插值操作\n",
    "    \"\"\"\n",
    "    global interpolation_details\n",
    "    \n",
    "    try:\n",
    "        interpolation_details = []  # 重置插值详情\n",
    "        \n",
    "        # ========== 1. 读取原始数据 ==========\n",
    "        print(f\"读取原始CSV文件: {input_file_path}\")\n",
    "        df = pd.read_csv(input_file_path)\n",
    "        \n",
    "        # 重命名列以保持一致性\n",
    "        df.rename(columns={\n",
    "            'DATE': 'Date',\n",
    "            'Latitude': 'Latitude',\n",
    "            'Longitude': 'Longitude'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # 转换日期格式\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        print(f\"成功读取 {len(df)} 条记录\")\n",
    "        print(f\"日期范围: {df['Date'].min().strftime('%Y-%m-%d')} 至 {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # 定义标准经纬度网格 (0.1°分辨率)\n",
    "        # 纬度: 北纬89.95°(0) -> 南纬-89.95°(1799)\n",
    "        lat_grid = np.linspace(89.95, -89.95, 1800)\n",
    "        \n",
    "        # 经度: -179.95°(0) -> 179.95°(3599)\n",
    "        lon_grid = np.linspace(-179.95, 179.95, 3600)\n",
    "        \n",
    "        # ========== 2. 准备PFT数据 (14个类别) ==========\n",
    "        pft_file = r\"E:\\data\\ESACCI PFT\\Resample\\Data\\2016.mat\"\n",
    "        if os.path.exists(pft_file):\n",
    "            print(f\"\\n处理PFT数据: {pft_file}\")\n",
    "            mat_data = read_hdf5_mat(pft_file)\n",
    "            \n",
    "            pft_columns = ['water','bare','snowice','built','grassnat','grassman',\n",
    "                          'shrubbd','shrubbe','shrubnd','shrubne',\n",
    "                          'treebd','treebe','treend','treene']\n",
    "            \n",
    "            available_pft = [col for col in pft_columns if col in mat_data]\n",
    "            print(f\"  文件中可用的PFT变量: {', '.join(available_pft)}\")\n",
    "            \n",
    "            # 处理每个可用的PFT类别\n",
    "            for col in available_pft:\n",
    "                grid_data = mat_data[col] / 100.0\n",
    "                df[f'PFT_{col}'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        grid_data\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加列: PFT_{col}\")\n",
    "        else:\n",
    "            print(f\"\\n警告: PFT文件不存在 - {pft_file}\")\n",
    "        \n",
    "        # ========== 3. 处理VOD数据 (7个变量) ==========\n",
    "        vod_base_dir = r\"E:\\data\\VOD\\mat\\kuxcVOD\\ASC\"\n",
    "        vod_cols = ['SM','ku_vod_H', 'ku_vod_V', 'x_vod_H','x_vod_V', 'c_vod_H','c_vod_V']\n",
    "        \n",
    "        for col in vod_cols:\n",
    "            df[col] = np.nan\n",
    "        \n",
    "        print(\"\\n处理VOD数据:\")\n",
    "        \n",
    "        # 收集所有唯一日期并排序\n",
    "        unique_dates = sorted(df['Date'].unique())\n",
    "        vod_files_found = 0\n",
    "        \n",
    "        for date in unique_dates:\n",
    "            # 转换为字符串格式YYYYMMDD\n",
    "            try:\n",
    "                if isinstance(date, pd.Timestamp):\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "                else:\n",
    "                    date_str = date.strftime(\"%Y%m%d\")\n",
    "            except:\n",
    "                print(f\"  无法解析日期: {date}\")\n",
    "                continue\n",
    "            \n",
    "            # SMAPVEX16 使用 AMSR2 传感器\n",
    "            vod_file = os.path.join(vod_base_dir, f\"MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "            if not os.path.exists(vod_file):\n",
    "                # 尝试备用命名格式\n",
    "                vod_file = os.path.join(vod_base_dir, f\"MCCA_AMSR2_010D_{date_str}_V0.nc4.mat\")\n",
    "            \n",
    "            if os.path.exists(vod_file):\n",
    "                vod_files_found += 1\n",
    "                print(f\"  处理日期: {date_str}, 文件: {os.path.basename(vod_file)}\")\n",
    "                vod_data = read_hdf5_mat(vod_file)\n",
    "                \n",
    "                for col in vod_cols:\n",
    "                    if col in vod_data:\n",
    "                        grid_data = vod_data[col]\n",
    "                        mask = df['Date'] == date\n",
    "                        df.loc[mask, col] = df[mask].apply(\n",
    "                            lambda row: bilinear_interpolation_with_details(\n",
    "                                lat_grid, lon_grid, \n",
    "                                row['Latitude'], row['Longitude'], \n",
    "                                grid_data\n",
    "                            ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                            else np.nan, axis=1\n",
    "                        )\n",
    "                        print(f\"    已更新: {col}\")\n",
    "                    else:\n",
    "                        print(f\"    警告: VOD变量 {col} 不存在于文件中\")\n",
    "            else:\n",
    "                print(f\"  警告: VOD文件不存在 - {os.path.basename(vod_file)}\")\n",
    "                \n",
    "        if vod_files_found == 0:\n",
    "            print(\"  警告: 没有找到任何VOD文件，VOD列将保留为空\")\n",
    "        \n",
    "        # ========== 4. 处理LAI卫星数据 (动态日期范围) ==========\n",
    "        print(\"\\n处理LAI卫星数据...\")\n",
    "        df['LAI_Satellite'] = np.nan\n",
    "        \n",
    "        # 确定日期范围\n",
    "        min_date = df['Date'].min().to_pydatetime()\n",
    "        max_date = df['Date'].max().to_pydatetime()\n",
    "        \n",
    "        # 扩展日期范围（前后各加一个月）\n",
    "        start_month = (min_date - timedelta(days=30)).replace(day=1)\n",
    "        end_month = (max_date + timedelta(days=30)).replace(day=1)\n",
    "        \n",
    "        # 获取所有需要的LAI文件\n",
    "        lai_files = {}\n",
    "        current = start_month\n",
    "        while current <= end_month:\n",
    "            # 每个月15日作为代表日\n",
    "            date_key = current.replace(day=15)\n",
    "            # 文件路径格式: E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\\2016-04-01.tif.mat\n",
    "            file_path = os.path.join(r\"E:\\data\\GLASS LAI\\mat\\0.1Deg\\Dataset\", f\"{date_key.strftime('%Y-%m')}-01.tif.mat\")\n",
    "            lai_files[date_key] = file_path\n",
    "            current = current + timedelta(days=32)  # 移动到下一个月\n",
    "            current = current.replace(day=1)\n",
    "        \n",
    "        print(f\"根据数据日期范围 ({min_date.strftime('%Y-%m-%d')} 至 {max_date.strftime('%Y-%m-%d')})\")\n",
    "        print(f\"确定需要 {len(lai_files)} 个LAI文件: {', '.join([d.strftime('%Y-%m') for d in lai_files.keys()])}\")\n",
    "        \n",
    "        # 加载LAI数据\n",
    "        expected_lai_keys = ['lai', 'LAI', 'data']\n",
    "        lai_data = {}\n",
    "        for date_key, file_path in lai_files.items():\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"  加载LAI数据 ({date_key.strftime('%Y-%m-%d')}): {file_path}\")\n",
    "                file_data = read_hdf5_mat(file_path, expected_keys=expected_lai_keys)\n",
    "                \n",
    "                if file_data:\n",
    "                    # 直接获取LAI数据\n",
    "                    lai_value = list(file_data.values())[0]\n",
    "                    # 验证数据形状\n",
    "                    if lai_value.shape != (1800, 3600):\n",
    "                        print(f\"    警告: 数据形状异常 {lai_value.shape}, 调整为(1800, 3600)\")\n",
    "                        if lai_value.shape[0] < 1800 or lai_value.shape[1] < 3600:\n",
    "                            lai_value = np.pad(lai_value, ((0, 1800-lai_value.shape[0]), (0, 3600-lai_value.shape[1])), 'constant')\n",
    "                        else:\n",
    "                            lai_value = lai_value[:1800, :3600]\n",
    "                    \n",
    "                    print(f\"    成功读取LAI变量 '{list(file_data.keys())[0]}'，数据形状: {lai_value.shape}\")\n",
    "                    lai_data[date_key] = lai_value\n",
    "                else:\n",
    "                    print(\"    警告: 文件中未找到预期LAI变量，使用全零数组\")\n",
    "                    lai_data[date_key] = np.zeros((1800, 3600))\n",
    "            else:\n",
    "                print(f\"  警告: LAI文件不存在 - {file_path}\")\n",
    "                lai_data[date_key] = np.zeros((1800, 3600))\n",
    "        \n",
    "        # 排序关键日期\n",
    "        lai_dates = sorted(lai_data.keys())\n",
    "        \n",
    "        # 处理每个日期的数据\n",
    "        print(\"\\n插值LAI数据到观测点...\")\n",
    "        for date in unique_dates:\n",
    "            try:\n",
    "                date_dt = date.to_pydatetime()\n",
    "                \n",
    "                # 找到观测日期前后的最近关键日期\n",
    "                # 找到第一个大于等于观测日期的关键日期索引\n",
    "                idx = next((i for i, d in enumerate(lai_dates) if d >= date_dt), len(lai_dates))\n",
    "                \n",
    "                if idx == 0:\n",
    "                    # 所有关键日期都在观测日期之后，使用第一个关键日期\n",
    "                    prev_date = next_date = lai_dates[0]\n",
    "                    weight = 0.0\n",
    "                elif idx == len(lai_dates):\n",
    "                    # 所有关键日期都在观测日期之前，使用最后一个关键日期\n",
    "                    prev_date = next_date = lai_dates[-1]\n",
    "                    weight = 0.0\n",
    "                else:\n",
    "                    # 获取前后两个关键日期\n",
    "                    prev_date = lai_dates[idx-1]\n",
    "                    next_date = lai_dates[idx]\n",
    "                    \n",
    "                    # 计算时间权重\n",
    "                    total_days = (next_date - prev_date).days\n",
    "                    days_passed = (date_dt - prev_date).days\n",
    "                    weight = days_passed / total_days if total_days > 0 else 0\n",
    "                \n",
    "                # 应用时间插值\n",
    "                interpolated_lai = (1 - weight) * lai_data[prev_date] + weight * lai_data[next_date]\n",
    "                \n",
    "                print(f\"  处理日期: {date_dt.strftime('%Y-%m-%d')}, 使用日期: {prev_date.strftime('%Y-%m-%d')} 和 {next_date.strftime('%Y-%m-%d')}, 权重: {weight:.2f}\")\n",
    "                \n",
    "                # 应用空间插值\n",
    "                mask = df['Date'] == date\n",
    "                df.loc[mask, 'LAI_Satellite'] = df[mask].apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        interpolated_lai\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                \n",
    "                # 验证插值结果\n",
    "                mean_lai = np.nanmean(interpolated_lai)\n",
    "                valid_count = df.loc[mask, 'LAI_Satellite'].notna().sum()\n",
    "                print(f\"    平均LAI: {mean_lai:.4f}, 成功插值 {valid_count} 条记录\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  处理日期{date_dt.strftime('%Y-%m-%d')}时出错: {str(e)}\")\n",
    "                \n",
    "        # ========== 5. 处理植被高度数据 ==========\n",
    "        print(\"\\n处理植被高度数据...\")\n",
    "        df['Hveg'] = np.nan\n",
    "        \n",
    "        hveg_file = r\"E:\\data\\CanopyHeight\\CH.mat\"\n",
    "        if os.path.exists(hveg_file):\n",
    "            print(f\"  加载植被高度数据: {hveg_file}\")\n",
    "            hveg_data = read_hdf5_mat(hveg_file, expected_keys=['CH', 'ch'])\n",
    "            \n",
    "            # 直接获取高度数据\n",
    "            hveg_key = list(hveg_data.keys())[0] if hveg_data else None\n",
    "            \n",
    "            if hveg_key:\n",
    "                hveg_values = hveg_data[hveg_key]\n",
    "                df['Hveg'] = df.apply(\n",
    "                    lambda row: bilinear_interpolation_with_details(\n",
    "                        lat_grid, lon_grid, \n",
    "                        row['Latitude'], row['Longitude'], \n",
    "                        hveg_values\n",
    "                    ) if not np.isnan(row['Latitude']) and not np.isnan(row['Longitude']) \n",
    "                    else np.nan, axis=1\n",
    "                )\n",
    "                print(f\"  已添加植被高度列，数据形状: {hveg_values.shape}\")\n",
    "            else:\n",
    "                print(f\"  警告: 无法找到Hveg变量\")\n",
    "                df['Hveg'] = np.nan\n",
    "        else:\n",
    "            print(f\"  警告: Hveg文件不存在 - {hveg_file}\")\n",
    "            df['Hveg'] = np.nan\n",
    "        \n",
    "        # ========== 6. 保存结果 ==========\n",
    "        output_file_path = r\"E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\"\n",
    "        print(f\"\\n保存结果到: {output_file_path}\")\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        \n",
    "        # 保存插值详细信息到CSV\n",
    "        if interpolation_details:\n",
    "            details_df = pd.DataFrame(interpolation_details)\n",
    "            details_path = r\"E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\interpolation_details.csv\"\n",
    "            details_df.to_csv(details_path, index=False)\n",
    "            print(f\"插值详细信息保存到: {details_path}\")\n",
    "        \n",
    "        # ========== 7. 统计报告 ==========\n",
    "        print(\"\\n处理完成!\")\n",
    "        print(f\"总记录数: {len(df)}\")\n",
    "        print(f\"插值操作次数: {len(interpolation_details)}\")\n",
    "        print(f\"填充的LAI值数量: {df['LAI_Satellite'].notna().sum()}\")\n",
    "        print(f\"填充的VOD值数量: {df['SM'].notna().sum() if 'SM' in df.columns else 0}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出错: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"错误详细信息:\")\n",
    "        print(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "# ========================== 主程序 ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords.csv\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"开始处理SMAPVEX16 Manitoba数据插值任务\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"错误: 输入文件不存在 - {input_file}\")\n",
    "        print(f\"请检查路径: {os.path.abspath(input_file)}\")\n",
    "    else:\n",
    "        print(f\"输入文件: {input_file}\")\n",
    "        print(f\"输出将保存到: E:\\\\data\\\\VWC\\\\test-VWC\\\\Insitu SMAPVEX16 Manitoba\\\\Processed_Results\\\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\")\n",
    "        \n",
    "        success = process_smapvex16_manitoba(input_file)\n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务成功完成!\")\n",
    "            print(\"=\"*30)\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"任务失败，请检查错误信息\")\n",
    "            print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54682488-2339-4ed7-ae52-f941759113fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载测试数据: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\n",
      "加载完成，总样本数: 1400\n",
      "\n",
      "处理 Ku-H 模型: RFR_Ku_Hpol_Type1.pkl\n",
      "  有效样本数: 1375 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.1583, R²: -8.3293\n",
      "\n",
      "处理 Ku-V 模型: RFR_Ku_Vpol_Type1.pkl\n",
      "  有效样本数: 1080 (删除缺失值后)\n",
      "  预测完成 - RMSE: 5.7038, R²: -16.7305\n",
      "\n",
      "处理 Ku-HV 模型: RFR_Ku_HVpol_Type1.pkl\n",
      "  有效样本数: 1080 (删除缺失值后)\n",
      "  预测完成 - RMSE: 5.2502, R²: -14.0223\n",
      "\n",
      "处理 C-H 模型: RFR_C_Hpol_Type1.pkl\n",
      "  有效样本数: 1375 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.8618, R²: -11.7531\n",
      "\n",
      "处理 C-V 模型: RFR_C_Vpol_Type1.pkl\n",
      "  有效样本数: 855 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.8582, R²: -13.7392\n",
      "\n",
      "处理 C-HV 模型: RFR_C_HVpol_Type1.pkl\n",
      "  有效样本数: 855 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.6950, R²: -12.7658\n",
      "\n",
      "处理 X-H 模型: RFR_X_Hpol_Type1.pkl\n",
      "  有效样本数: 1375 (删除缺失值后)\n",
      "  预测完成 - RMSE: 5.0755, R²: -12.8986\n",
      "\n",
      "处理 X-V 模型: RFR_X_Vpol_Type1.pkl\n",
      "  有效样本数: 1312 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.0062, R²: -7.4932\n",
      "\n",
      "处理 X-HV 模型: RFR_X_HVpol_Type1.pkl\n",
      "  有效样本数: 1312 (删除缺失值后)\n",
      "  预测完成 - RMSE: 4.0201, R²: -7.5520\n",
      "\n",
      "所有预测结果已保存至: model_predictions_results_SMAPVEX16.xlsx\n",
      "\n",
      "正在绘制组合散点图...\n",
      "  组合散点图已保存至: figures\\SMAPVEX16_VWC_Scatter.png\n",
      "\n",
      "所有处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 机器学习结果填充，和实测值对比\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# 设置常量 - 更新为CSV文件路径\n",
    "TEST_FILE = r\"E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "SAVE_RESULTS = \"model_predictions_results_SMAPVEX16.xlsx\"\n",
    "FIG_DIR = \"figures\"\n",
    "\n",
    "# 定义波段和极化组合\n",
    "BANDS = ['Ku', 'C', 'X']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 波段颜色定义\n",
    "BAND_COLORS = {\n",
    "    'Ku': (253/255, 173/255, 115/255, 0.7),\n",
    "    'C': (178/255, 125/255, 104/255, 0.7),\n",
    "    'X': (224/255, 104/255, 46/255, 0.7)\n",
    "}\n",
    "\n",
    "# 极化类型标记定义\n",
    "POL_MARKERS = {\n",
    "    'H': 's',  # 方形\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 'o'  # 圆形\n",
    "}\n",
    "\n",
    "def normalize_LAI(lai_series):\n",
    "    \"\"\"对LAI进行归一化\"\"\"\n",
    "    return lai_series.clip(0, 6) / 6\n",
    "\n",
    "def normalize_VOD(vod_series):\n",
    "    \"\"\"对VOD进行归一化\"\"\"\n",
    "    return vod_series.clip(0, 2) / 2\n",
    "\n",
    "# PFT列名映射字典\n",
    "PFT_MAPPING = {\n",
    "    'PFT_grassnat': 'Grass_nat',\n",
    "    'PFT_grassman': 'Grass_man',\n",
    "    'PFT_shrubbd': 'Shrub_bd',\n",
    "    'PFT_shrubbe': 'Shrub_be',\n",
    "    'PFT_shrubnd': 'Shrub_nd',\n",
    "    'PFT_shrubne': 'Shrub_ne',\n",
    "    'PFT_treebd': 'Tree_bd',\n",
    "    'PFT_treebe': 'Tree_be',\n",
    "    'PFT_treend': 'Tree_nd',\n",
    "    'PFT_treene': 'Tree_ne'\n",
    "}\n",
    "\n",
    "def get_model_columns(band, pol):\n",
    "    \"\"\"获取指定模型所需的列名\"\"\"\n",
    "    base_columns = [\n",
    "        'PLANT_WATER_CONTENT_AREA',  # 实测VWC列名\n",
    "        'LAI_Satellite',             # LAI列名\n",
    "        'SM'                         # 土壤湿度\n",
    "    ]\n",
    "    \n",
    "    # 添加所有PFT列\n",
    "    base_columns.extend(PFT_MAPPING.keys())\n",
    "    \n",
    "    # 根据极化类型添加VOD列\n",
    "    if pol == 'H':\n",
    "        return base_columns + [f'{band.lower()}_vod_H']\n",
    "    elif pol == 'V':\n",
    "        return base_columns + [f'{band.lower()}_vod_V']\n",
    "    elif pol == 'HV':\n",
    "        return base_columns + [f'{band.lower()}_vod_H', f'{band.lower()}_vod_V']\n",
    "\n",
    "def get_feature_order(pol):\n",
    "    \"\"\"获取特征列的顺序（模型期望的列顺序）\"\"\"\n",
    "    base_features = [\n",
    "        'LAI', 'SM',\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    if pol in ['H', 'V']:\n",
    "        return ['VOD'] + base_features\n",
    "    elif pol == 'HV':\n",
    "        return ['VOD-Hpol', 'VOD-Vpol'] + base_features\n",
    "\n",
    "def prepare_input_data(df, band, pol):\n",
    "    \"\"\"为指定模型准备输入数据\"\"\"\n",
    "    # 创建数据副本\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 归一化处理\n",
    "    data['LAI'] = normalize_LAI(data['LAI_Satellite'])\n",
    "    \n",
    "    # 2. 处理VOD列\n",
    "    if pol == 'H':\n",
    "        vod_col = f'{band.lower()}_vod_H'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'V':\n",
    "        vod_col = f'{band.lower()}_vod_V'\n",
    "        data['VOD'] = normalize_VOD(data[vod_col])\n",
    "    elif pol == 'HV':\n",
    "        # 重命名列以匹配模型训练时的特征名\n",
    "        data = data.rename(columns={\n",
    "            f'{band.lower()}_vod_H': 'VOD-Hpol',\n",
    "            f'{band.lower()}_vod_V': 'VOD-Vpol'\n",
    "        })\n",
    "        # 归一化处理\n",
    "        data['VOD-Hpol'] = normalize_VOD(data['VOD-Hpol'])\n",
    "        data['VOD-Vpol'] = normalize_VOD(data['VOD-Vpol'])\n",
    "    \n",
    "    # 3. 重命名PFT列为模型期望的名称\n",
    "    data = data.rename(columns=PFT_MAPPING)\n",
    "    \n",
    "    # 4. 按模型要求排序特征列\n",
    "    feature_order = get_feature_order(pol)\n",
    "    \n",
    "    return data[feature_order]\n",
    "\n",
    "def plot_combined_scatter(actual, predictions_dict):\n",
    "    \"\"\"\n",
    "    绘制组合散点图，包含所有波段和极化类型\n",
    "    \n",
    "    参数:\n",
    "    actual -- 实际值 (Series)\n",
    "    predictions_dict -- 字典结构: {\n",
    "        'H': {band: pred_series},\n",
    "        'V': {band: pred_series},\n",
    "        'HV': {band: pred_series}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # 存储所有组合的RMSE值\n",
    "    rmse_values = {}\n",
    "    \n",
    "    # 收集所有数据点\n",
    "    max_val = 0\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            pred_series = predictions_dict[pol].get(band)\n",
    "            \n",
    "            if pred_series is not None and not pred_series.isnull().all():\n",
    "                # 创建实际值和预测值的临时DF\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'actual': actual,\n",
    "                    'pred': pred_series\n",
    "                }).dropna()\n",
    "                \n",
    "                if not temp_df.empty:\n",
    "                    # 计算RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(temp_df['actual'], temp_df['pred']))\n",
    "                    rmse_values[f\"{band}-{pol}\"] = rmse\n",
    "                    \n",
    "                    # 更新最大值\n",
    "                    band_max = max(temp_df['actual'].max(), temp_df['pred'].max())\n",
    "                    if band_max > max_val:\n",
    "                        max_val = band_max\n",
    "                    \n",
    "                    # 绘制散点\n",
    "                    plt.scatter(\n",
    "                        temp_df['actual'], temp_df['pred'], \n",
    "                        alpha=0.7, \n",
    "                        color=BAND_COLORS[band],\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        s=50,\n",
    "                        edgecolors='none',\n",
    "                        zorder=2,\n",
    "                        label=f\"{band}-{pol}\"\n",
    "                    )\n",
    "    \n",
    "    # 如果没有数据可绘制，直接返回\n",
    "    if not rmse_values:\n",
    "        print(\"  警告: 没有有效的预测数据!\")\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val *= 1.05\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围\n",
    "    plt.xlim(0, max_val)\n",
    "    plt.ylim(0, max_val)\n",
    "    \n",
    "    # 设置坐标轴标签\n",
    "    plt.xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('RF VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title('SMAPVEX16 Insitu VWC', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "    \n",
    "    # 添加RMSE文本（左上角，3×3网格布局）\n",
    "    if rmse_values:\n",
    "        # 设置文本位置\n",
    "        x_pos = 0.05\n",
    "        y_pos = 0.95\n",
    "        \n",
    "        # 计算RMSE表格的边界\n",
    "        min_x = x_pos\n",
    "        max_x = x_pos + 0.3  # 3列 * 0.1\n",
    "        min_y = y_pos - 0.05 - 3 * 0.08  # 3行 * 0.08\n",
    "        max_y = y_pos\n",
    "        \n",
    "        # 添加白色背景矩形框\n",
    "        rect = plt.Rectangle(\n",
    "            (min_x - 0.01, min_y - 0.01),  # 左下角位置\n",
    "            max_x - min_x + 0.02,          # 宽度\n",
    "            max_y - min_y + 0.02,          # 高度\n",
    "            transform=ax.transAxes,\n",
    "            facecolor='white',\n",
    "            edgecolor='black',\n",
    "            linewidth=1.5,\n",
    "            zorder=3\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.text(x_pos, y_pos, 'RMSE (kg/m²):', \n",
    "                 transform=ax.transAxes,\n",
    "                 fontsize=12,\n",
    "                 fontweight='bold',\n",
    "                 verticalalignment='top',\n",
    "                 zorder=4)\n",
    "        \n",
    "        y_pos -= 0.05\n",
    "        \n",
    "        # 添加列标题（极化类型）\n",
    "        for pol_idx, pol in enumerate(POLS):\n",
    "            plt.text(\n",
    "                x_pos + 0.05 + pol_idx * 0.1, y_pos,\n",
    "                f\"{pol}-pol\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment='center',\n",
    "                zorder=4\n",
    "            )\n",
    "        \n",
    "        # 添加行标题（波段）\n",
    "        for band_idx, band in enumerate(BANDS):\n",
    "            plt.text(\n",
    "                x_pos - 0.02, y_pos - (band_idx + 1) * 0.08,\n",
    "                f\"{band} Band:\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment='right',\n",
    "                zorder=4\n",
    "            )\n",
    "        \n",
    "        # 遍历每个波段\n",
    "        for band_idx, band in enumerate(BANDS):\n",
    "            # 遍历每个极化类型\n",
    "            for pol_idx, pol in enumerate(POLS):\n",
    "                # 计算位置\n",
    "                text_x = x_pos + 0.05 + pol_idx * 0.1\n",
    "                text_y = y_pos - (band_idx + 1) * 0.08\n",
    "                \n",
    "                # 获取RMSE值\n",
    "                rmse = rmse_values.get(f\"{band}-{pol}\", None)\n",
    "                \n",
    "                if rmse is not None:\n",
    "                    # 绘制标记\n",
    "                    plt.scatter(\n",
    "                        text_x, text_y, \n",
    "                        transform=ax.transAxes,\n",
    "                        marker=POL_MARKERS[pol],\n",
    "                        color=BAND_COLORS[band],\n",
    "                        s=80,\n",
    "                        alpha=0.7,\n",
    "                        zorder=4\n",
    "                    )\n",
    "                    \n",
    "                    # 添加RMSE值\n",
    "                    plt.text(\n",
    "                        text_x + 0.03, text_y, \n",
    "                        f\"{rmse:.3f}\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center',\n",
    "                        zorder=4\n",
    "                    )\n",
    "                else:\n",
    "                    plt.text(\n",
    "                        text_x, text_y, \n",
    "                        \"N/A\", \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold',\n",
    "                        verticalalignment='center',\n",
    "                        color='gray',\n",
    "                        zorder=4\n",
    "                    )\n",
    "    \n",
    "    # 添加网格线\n",
    "    plt.grid(True, linestyle='--', alpha=0.3, zorder=0)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(FIG_DIR, exist_ok=True)\n",
    "    \n",
    "    # 保存图像\n",
    "    fig_path = os.path.join(FIG_DIR, 'SMAPVEX16_VWC_Scatter.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  组合散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def predict_and_evaluate():\n",
    "    \"\"\"主函数：加载所有模型进行预测并评估结果\"\"\"\n",
    "    # 1. 加载测试数据\n",
    "    print(f\"正在加载测试数据: {TEST_FILE}\")\n",
    "    \n",
    "    # 收集所有可能的列\n",
    "    all_columns = set([\n",
    "        'PLANT_WATER_CONTENT_AREA',  # 实测VWC\n",
    "        'LAI_Satellite',             # LAI\n",
    "        'SM'                         # 土壤湿度\n",
    "    ])\n",
    "    # 添加所有PFT列\n",
    "    all_columns.update(PFT_MAPPING.keys())\n",
    "    # 添加所有VOD列\n",
    "    for band in BANDS:\n",
    "        all_columns.add(f'{band.lower()}_vod_H')\n",
    "        all_columns.add(f'{band.lower()}_vod_V')\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    test_df = pd.read_csv(TEST_FILE, usecols=list(all_columns))\n",
    "    print(f\"加载完成，总样本数: {len(test_df)}\")\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    results = pd.DataFrame(index=test_df.index)\n",
    "    results['Actual_VWC'] = test_df['PLANT_WATER_CONTENT_AREA']\n",
    "    \n",
    "    # 为每个极化类型存储预测结果\n",
    "    predictions_by_pol = {\n",
    "        'H': {band: None for band in BANDS},\n",
    "        'V': {band: None for band in BANDS},\n",
    "        'HV': {band: None for band in BANDS}\n",
    "    }\n",
    "    \n",
    "    # 2. 对每个模型进行预测\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            model_name = f\"RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "            model_path = os.path.join(MODEL_DIR, model_name)\n",
    "            \n",
    "            print(f\"\\n处理 {band}-{pol} 模型: {model_name}\")\n",
    "            \n",
    "            # 准备输入数据\n",
    "            model_cols = get_model_columns(band, pol)\n",
    "            model_data = test_df[model_cols].copy()\n",
    "            \n",
    "            # 删除缺失值\n",
    "            clean_data = model_data.dropna()\n",
    "            print(f\"  有效样本数: {len(clean_data)} (删除缺失值后)\")\n",
    "            \n",
    "            if len(clean_data) == 0:\n",
    "                print(\"  警告: 无有效样本可用于此模型!\")\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "                continue\n",
    "            \n",
    "            # 预处理输入数据\n",
    "            try:\n",
    "                X_input = prepare_input_data(clean_data, band, pol)\n",
    "                \n",
    "                # 加载模型并进行预测\n",
    "                if os.path.exists(model_path):\n",
    "                    model = joblib.load(model_path)\n",
    "                    predictions = model.predict(X_input)\n",
    "                    \n",
    "                    # 存储预测结果\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    results.loc[clean_data.index, f\"{band}_{pol}_Predicted\"] = predictions\n",
    "                    \n",
    "                    # 存储到对应极化类型的字典\n",
    "                    predictions_by_pol[pol][band] = results[f\"{band}_{pol}_Predicted\"].copy()\n",
    "                    \n",
    "                    # 计算评估指标\n",
    "                    actual = clean_data['PLANT_WATER_CONTENT_AREA']\n",
    "                    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "                    r2 = r2_score(actual, predictions)\n",
    "                    print(f\"  预测完成 - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  警告: 未找到模型文件 {model_path}!\")\n",
    "                    results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                    predictions_by_pol[pol][band] = None\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"  预测失败: {str(e)}\")\n",
    "                # 打印更详细的错误信息\n",
    "                traceback.print_exc()\n",
    "                results[f\"{band}_{pol}_Predicted\"] = np.nan\n",
    "                predictions_by_pol[pol][band] = None\n",
    "    \n",
    "    # 3. 保存结果\n",
    "    results.to_excel(SAVE_RESULTS)\n",
    "    print(f\"\\n所有预测结果已保存至: {SAVE_RESULTS}\")\n",
    "    \n",
    "    # 4. 绘制组合散点图\n",
    "    print(\"\\n正在绘制组合散点图...\")\n",
    "    plot_combined_scatter(\n",
    "        results['Actual_VWC'], \n",
    "        predictions_by_pol\n",
    "    )\n",
    "    \n",
    "    return results, predictions_by_pol\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    results, predictions_by_pol = predict_and_evaluate()\n",
    "    print(\"\\n所有处理完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea7d38-89fa-4eeb-b822-0c21e7939b44",
   "metadata": {},
   "source": [
    "# SMEX02+CLASIC07+SMEX08+SMAPVEX16——处理为像元数据来检测，消除像元内出现的强烈的不一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2a13fd-7687-4430-bd8b-025ed338a368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理: SMEX02\n",
      "原始数据行数: 104\n",
      "日期格式成功转换为YYYYMMDD\n",
      "计算网格索引...\n",
      "分组求平均值...\n",
      "添加像元中心坐标...\n",
      "处理完成, 有效数据行数: 16\n",
      "成功保存 SMEX02 数据到Sheet\n",
      "\n",
      "\n",
      "开始处理: CLASIC07\n",
      "原始数据行数: 22\n",
      "日期格式成功转换为YYYYMMDD\n",
      "计算网格索引...\n",
      "分组求平均值...\n",
      "添加像元中心坐标...\n",
      "处理完成, 有效数据行数: 18\n",
      "成功保存 CLASIC07 数据到Sheet\n",
      "\n",
      "\n",
      "开始处理: SMEX08\n",
      "原始数据行数: 10\n",
      "日期格式成功转换为YYYYMMDD\n",
      "计算网格索引...\n",
      "分组求平均值...\n",
      "添加像元中心坐标...\n",
      "处理完成, 有效数据行数: 6\n",
      "成功保存 SMEX08 数据到Sheet\n",
      "\n",
      "\n",
      "开始处理: SMAPVEX16\n",
      "原始数据行数: 1400\n",
      "日期格式成功转换为YYYYMMDD\n",
      "移除 25 行缺失经纬度或日期的数据\n",
      "计算网格索引...\n",
      "分组求平均值...\n",
      "添加像元中心坐标...\n",
      "处理完成, 有效数据行数: 115\n",
      "成功保存 SMAPVEX16 数据到Sheet\n",
      "\n",
      "处理完成! 结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 整合以前处理的数据，计算平均值\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 常量定义\n",
    "LAT_MIN, LAT_MAX = -89.95, 89.95  # 纬度范围\n",
    "LON_MIN, LON_MAX = -179.95, 179.95  # 经度范围\n",
    "RESOLUTION = 0.1  # 像元分辨率\n",
    "\n",
    "def calculate_grid_index(lat, lon):\n",
    "    \"\"\"计算给定经纬度对应的像元行列索引\"\"\"\n",
    "    # 检查NaN值并跳过\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        return (None, None)\n",
    "    \n",
    "    # 确保纬度在有效范围内\n",
    "    if lat < LAT_MIN or lat > LAT_MAX:\n",
    "        # 调整超出范围的纬度\n",
    "        lat = max(min(lat, LAT_MAX), LAT_MIN)\n",
    "    \n",
    "    # 计算纬度索引（行）\n",
    "    lat_index = int(np.round((LAT_MAX - lat) / RESOLUTION))\n",
    "    lat_index = max(0, min(lat_index, 1799))  # 确保在0~1799范围内\n",
    "    \n",
    "    # 调整经度范围 (0-360)\n",
    "    if lon < LON_MIN:\n",
    "        lon += 360\n",
    "    elif lon > LON_MAX:\n",
    "        lon -= 360\n",
    "    \n",
    "    # 计算经度索引（列）\n",
    "    lon_index = int(np.round((lon - LON_MIN) / RESOLUTION)) % 3600\n",
    "    \n",
    "    return lat_index, lon_index\n",
    "\n",
    "def get_center_coordinates(row, col):\n",
    "    \"\"\"根据行列索引计算像元中心经纬度\"\"\"\n",
    "    center_lat = LAT_MAX - row * RESOLUTION\n",
    "    center_lon = LON_MIN + col * RESOLUTION\n",
    "    \n",
    "    # 确保经度在[-180, 180]范围内\n",
    "    if center_lon > 180:\n",
    "        center_lon -= 360\n",
    "    elif center_lon < -180:\n",
    "        center_lon += 360\n",
    "        \n",
    "    return center_lat, center_lon\n",
    "\n",
    "def process_file(file_path, date_col, lat_col, lon_col, dataset_name):\n",
    "    \"\"\"处理单个文件：读取数据、计算像元、聚合平均值\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n开始处理: {dataset_name}\")\n",
    "        # 读取文件\n",
    "        suffix = Path(file_path).suffix.lower()\n",
    "        if suffix == '.csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif suffix in ('.xlsx', '.xls'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的格式: {suffix}\")\n",
    "        \n",
    "        print(f\"原始数据行数: {len(df)}\")\n",
    "        \n",
    "        # 重命名列以统一处理\n",
    "        df = df.rename(columns={\n",
    "            lat_col: 'Latitude',\n",
    "            lon_col: 'Longitude',\n",
    "            date_col: 'Date'\n",
    "        })\n",
    "        \n",
    "        # ======== 新增：日期格式统一转换为YYYYMMDD ========\n",
    "        try:\n",
    "            # 尝试转换为datetime对象\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "            # 格式化为YYYYMMDD字符串\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y%m%d')\n",
    "            print(\"日期格式成功转换为YYYYMMDD\")\n",
    "        except Exception as date_err:\n",
    "            print(f\"日期转换异常: {str(date_err)}\")\n",
    "            print(\"尝试直接处理原始格式...\")\n",
    "            # 备份原始日期列\n",
    "            df['Date_orig'] = df['Date']\n",
    "            # 移除非数字字符并取前8位\n",
    "            df['Date'] = (\n",
    "                df['Date'].astype(str)\n",
    "                .str.replace(r'[^\\d]', '', regex=True)  # 移除非数字\n",
    "                .str[:8]  # 取前8位数字\n",
    "            )\n",
    "            # 检查转换后的格式有效性\n",
    "            invalid_mask = df['Date'].str.len() != 8\n",
    "            if invalid_mask.any():\n",
    "                invalid_count = invalid_mask.sum()\n",
    "                print(f\"警告: {invalid_count}行日期格式无效 (非8位数字)\")\n",
    "                # 恢复无法转换的原始值\n",
    "                df.loc[invalid_mask, 'Date'] = df.loc[invalid_mask, 'Date_orig']\n",
    "            df.drop(columns='Date_orig', inplace=True)\n",
    "        # ======== 日期处理结束 ========\n",
    "        \n",
    "        # 检查并处理缺失值 (包含转换后的日期)\n",
    "        initial_size = len(df)\n",
    "        df = df.dropna(subset=['Latitude', 'Longitude', 'Date'])\n",
    "        na_count = initial_size - len(df)\n",
    "        if na_count > 0:\n",
    "            print(f\"移除 {na_count} 行缺失经纬度或日期的数据\")\n",
    "        if len(df) == 0:\n",
    "            print(\"警告: 删除缺失值后数据集为空!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 计算像元行列索引\n",
    "        print(\"计算网格索引...\")\n",
    "        grid_indices = df.apply(\n",
    "            lambda x: calculate_grid_index(x['Latitude'], x['Longitude']), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 创建包含索引的DataFrame\n",
    "        indices_df = pd.DataFrame(grid_indices.tolist(), columns=['row', 'col'], index=df.index)\n",
    "        \n",
    "        # 处理无效索引\n",
    "        valid_indices = indices_df.notna().all(axis=1)\n",
    "        invalid_count = len(indices_df) - valid_indices.sum()\n",
    "        \n",
    "        if invalid_count > 0:\n",
    "            print(f\"警告: {invalid_count} 行有无效经纬度，将被移除\")\n",
    "            df = df[valid_indices].copy()\n",
    "            indices_df = indices_df[valid_indices]\n",
    "        \n",
    "        # 分配行列索引\n",
    "        df['row'] = indices_df['row']\n",
    "        df['col'] = indices_df['col']\n",
    "        \n",
    "        # 删除原始经纬度列\n",
    "        df.drop(columns=['Latitude', 'Longitude'], inplace=True)\n",
    "        \n",
    "        # 按日期和像元分组求平均值\n",
    "        print(\"分组求平均值...\")\n",
    "        grouped = df.groupby(['Date', 'row', 'col']).mean(numeric_only=True).reset_index()\n",
    "        \n",
    "        # 添加像元中心经纬度\n",
    "        print(\"添加像元中心坐标...\")\n",
    "        center_coords = grouped.apply(\n",
    "            lambda x: get_center_coordinates(x['row'], x['col']), \n",
    "            axis=1\n",
    "        )\n",
    "        # 修改列名以明确表示这是网格中心\n",
    "        grouped[['Center_Latitude', 'Center_Longitude']] = pd.DataFrame(\n",
    "            center_coords.tolist(), \n",
    "            columns=['Center_Latitude', 'Center_Longitude'], \n",
    "            index=grouped.index\n",
    "        )\n",
    "        \n",
    "        # 确保所有计算列都在数据框中\n",
    "        grouped = grouped.reindex(columns=['Date', 'row', 'col', 'Center_Latitude', 'Center_Longitude'] + \n",
    "                                [col for col in grouped.columns if col not in ['Date', 'row', 'col', 'Center_Latitude', 'Center_Longitude']])\n",
    "        \n",
    "        print(f\"处理完成, 有效数据行数: {len(grouped)}\")\n",
    "        return grouped\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"处理 {dataset_name} 时发生错误: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"文件路径: {file_path}\")\n",
    "        print(f\"日期列名: {date_col}, 纬度列名: {lat_col}, 经度列名: {lon_col}\")\n",
    "        return pd.DataFrame()  # 返回空DataFrame避免中断\n",
    "\n",
    "# 文件配置列表\n",
    "files_config = [\n",
    "    {\n",
    "        'name': 'SMEX02',\n",
    "        'path': r'E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V.xlsx',\n",
    "        'date_col': 'Date',\n",
    "        'lat_col': 'Latitude',\n",
    "        'lon_col': 'Longitude'\n",
    "    },\n",
    "    {\n",
    "        'name': 'CLASIC07',\n",
    "        'path': r'E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC.xlsx',\n",
    "        'date_col': 'Date',\n",
    "        'lat_col': 'Latitude (WGS84)',\n",
    "        'lon_col': 'Longitude (WGS84)'\n",
    "    },\n",
    "    {\n",
    "        'name': 'SMEX08',\n",
    "        'path': r'E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_Sum_VEG_SMAPVEX.xlsx',\n",
    "        'date_col': 'Date',\n",
    "        'lat_col': 'Latitude',\n",
    "        'lon_col': 'Longitude'\n",
    "    },\n",
    "    {\n",
    "        'name': 'SMAPVEX16',\n",
    "        'path': r'E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords.csv',\n",
    "        'date_col': 'DATE',\n",
    "        'lat_col': 'Latitude',\n",
    "        'lon_col': 'Longitude'\n",
    "    }\n",
    "]\n",
    "\n",
    "# 主处理过程\n",
    "if __name__ == \"__main__\":\n",
    "    output_path = r'E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel.xlsx'\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)  # 确保目录存在\n",
    "    \n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        for config in files_config:\n",
    "            processed_df = process_file(\n",
    "                config['path'],\n",
    "                config['date_col'],\n",
    "                config['lat_col'],\n",
    "                config['lon_col'],\n",
    "                config['name']\n",
    "            )\n",
    "            \n",
    "            if not processed_df.empty:\n",
    "                processed_df.to_excel(writer, sheet_name=config['name'], index=False)\n",
    "                print(f\"成功保存 {config['name']} 数据到Sheet\\n\")\n",
    "            else:\n",
    "                print(f\"{config['name']} 无有效数据可保存\\n\")\n",
    "    \n",
    "    print(f\"处理完成! 结果已保存至: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b73230-bde8-4608-9754-f2d3c1fe0fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "处理数据集: SMEX02\n",
      "\n",
      "开始处理 SMEX02 数据集...\n",
      "原始数据行数: 16\n",
      "添加VOD及SM数据...\n",
      "添加PFT数据...\n",
      "添加LAI数据...\n",
      "添加Hveg数据...\n",
      "处理完成, 最终数据行数: 16\n",
      "\n",
      "==================================================\n",
      "处理数据集: CLASIC07\n",
      "\n",
      "开始处理 CLASIC07 数据集...\n",
      "原始数据行数: 18\n",
      "添加VOD及SM数据...\n",
      "添加PFT数据...\n",
      "添加LAI数据...\n",
      "添加Hveg数据...\n",
      "处理完成, 最终数据行数: 18\n",
      "\n",
      "==================================================\n",
      "处理数据集: SMEX08\n",
      "处理 SMEX08 时出错: Worksheet named 'SMEX08' not found\n",
      "\n",
      "==================================================\n",
      "处理数据集: SMAPVEX16\n",
      "\n",
      "开始处理 SMAPVEX16 数据集...\n",
      "原始数据行数: 115\n",
      "添加VOD及SM数据...\n",
      "添加PFT数据...\n",
      "添加LAI数据...\n",
      "添加Hveg数据...\n",
      "处理完成, 最终数据行数: 115\n",
      "保存 'SMEX02' 到Excel文件 (16 行)\n",
      "保存 'CLASIC07' 到Excel文件 (18 行)\n",
      "SMEX08 无有效数据，创建空工作表\n",
      "保存 'SMAPVEX16' 到Excel文件 (115 行)\n",
      "\n",
      "==================================================\n",
      "处理完成! 结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\n",
      "文件大小: 0.04 MB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 数据填充\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# 常量定义\n",
    "TOTAL_ROWS = 1800  # 纬度方向像元数\n",
    "TOTAL_COLS = 3600  # 经度方向像元数\n",
    "VOD_VARIABLES = ['SM', 'ku_vod_H', 'ku_vod_V', 'x_vod_H', 'x_vod_V', 'c_vod_H', 'c_vod_V']\n",
    "PFT_VARIABLES = ['water', 'bare', 'snowice', 'built', 'grassnat', 'grassman', \n",
    "                 'shrubbd', 'shrubbe', 'shrubnd', 'shrubne', 'treebd', 'treebe', 'treend', 'treene']\n",
    "\n",
    "def read_mat_file(file_path, variable_names, silent=False):\n",
    "    \"\"\"\n",
    "    读取MAT文件并返回所需变量的数据矩阵\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): MAT文件路径\n",
    "    variable_names (list): 要读取的变量名列表\n",
    "    silent (bool): 是否静默处理错误\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含变量名及其对应的矩阵数据\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 尝试使用h5py读取v7.3格式\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = {}\n",
    "            for var in variable_names:\n",
    "                if var in f:\n",
    "                    dataset = f[var]\n",
    "                    # 如果数据是引用类型，获取实际数据\n",
    "                    if isinstance(dataset, h5py.Reference):\n",
    "                        dataset = f[dataset]\n",
    "                    # 确保是二维数组\n",
    "                    if len(dataset.shape) == 2:\n",
    "                        matrix = dataset[()]\n",
    "                        # 检查矩阵方向是否需要转置\n",
    "                        if matrix.shape == (TOTAL_ROWS, TOTAL_COLS):\n",
    "                            data[var] = matrix\n",
    "                        elif matrix.shape == (TOTAL_COLS, TOTAL_ROWS):\n",
    "                            data[var] = matrix.T\n",
    "                        else:\n",
    "                            # 尝试重塑为正确形状\n",
    "                            try:\n",
    "                                data[var] = matrix.reshape(TOTAL_ROWS, TOTAL_COLS)\n",
    "                            except:\n",
    "                                data[var] = np.full((TOTAL_ROWS, TOTAL_COLS), np.nan)\n",
    "                    else:\n",
    "                        data[var] = np.full((TOTAL_ROWS, TOTAL_COLS), np.nan)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        if not silent:\n",
    "            print(f\"警告: 读取文件 {file_path} 时出错: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def safe_date_to_str(date_val):\n",
    "    \"\"\"安全地将日期值转换为YYYYMMDD格式的字符串\"\"\"\n",
    "    if pd.isna(date_val):\n",
    "        return \"\"\n",
    "    \n",
    "    # 处理不同的日期格式\n",
    "    if isinstance(date_val, datetime):\n",
    "        return date_val.strftime('%Y%m%d')\n",
    "    elif isinstance(date_val, np.datetime64):\n",
    "        return pd.to_datetime(date_val).strftime('%Y%m%d')\n",
    "    elif isinstance(date_val, (int, float)):\n",
    "        # 数字日期 (如20220715.0)\n",
    "        date_str = str(int(date_val))\n",
    "        return date_str[:8] if len(date_str) > 8 else date_str.zfill(8)\n",
    "    else:\n",
    "        # 字符串日期\n",
    "        date_str = str(date_val).replace('-', '').replace('/', '').replace(' ', '')\n",
    "        return date_str[:8] if len(date_str) > 8 else date_str.zfill(8)\n",
    "\n",
    "def calculate_lai_weight(date_str):\n",
    "    \"\"\"计算LAI插值权重（修正版）\"\"\"\n",
    "    if len(date_str) != 8 or not date_str.isdigit():\n",
    "        return None, None, 0.0\n",
    "    \n",
    "    try:\n",
    "        year = int(date_str[:4])\n",
    "        month = int(date_str[4:6])\n",
    "        day = int(date_str[6:8])\n",
    "    except:\n",
    "        return None, None, 0.0\n",
    "    \n",
    "    # 处理无效日期\n",
    "    try:\n",
    "        current_date = datetime(year, month, day)\n",
    "    except ValueError:\n",
    "        # 处理无效日期（如2月31日）\n",
    "        if month == 2 and day > 28:\n",
    "            day = 28\n",
    "        elif day > 30 and month in [4, 6, 9, 11]:\n",
    "            day = 30\n",
    "        elif day > 31 and month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            day = 31\n",
    "            \n",
    "        try:\n",
    "            current_date = datetime(year, month, day)\n",
    "        except:\n",
    "            return None, None, 0.0\n",
    "    \n",
    "    # 确定正确的月份对\n",
    "    if day < 15:\n",
    "        # 如果日期在15日之前，使用前一个月和当前月\n",
    "        prev_month = month - 1\n",
    "        prev_year = year\n",
    "        if prev_month == 0:\n",
    "            prev_month = 12\n",
    "            prev_year = year - 1\n",
    "        \n",
    "        prev_month_mid = datetime(prev_year, prev_month, 15)\n",
    "        current_month_mid = datetime(year, month, 15)\n",
    "        \n",
    "        total_days = (current_month_mid - prev_month_mid).days\n",
    "        days_passed = (current_date - prev_month_mid).days\n",
    "    else:\n",
    "        # 如果日期在15日或之后，使用当前月和下一月\n",
    "        current_month_mid = datetime(year, month, 15)\n",
    "        \n",
    "        next_month = month + 1\n",
    "        next_year = year\n",
    "        if next_month > 12:\n",
    "            next_month = 1\n",
    "            next_year += 1\n",
    "        next_month_mid = datetime(next_year, next_month, 15)\n",
    "        \n",
    "        total_days = (next_month_mid - current_month_mid).days\n",
    "        days_passed = (current_date - current_month_mid).days\n",
    "    \n",
    "    if total_days <= 0:\n",
    "        weight = 0.0\n",
    "    else:\n",
    "        weight = max(0.0, min(1.0, days_passed / total_days))\n",
    "    \n",
    "    # 返回月份对和权重\n",
    "    if day < 15:\n",
    "        return (prev_year, prev_month), (year, month), weight\n",
    "    else:\n",
    "        return (year, month), (next_year, next_month), weight\n",
    "\n",
    "def process_dataset(df, sheet_name):\n",
    "    \"\"\"\n",
    "    处理单个数据集，添加额外的卫星数据列\n",
    "    \n",
    "    参数:\n",
    "    df (pd.DataFrame): 输入数据集\n",
    "    sheet_name (str): sheet名称\n",
    "    \n",
    "    返回:\n",
    "    pd.DataFrame: 处理后的数据集\n",
    "    \"\"\"\n",
    "    print(f\"\\n开始处理 {sheet_name} 数据集...\")\n",
    "    print(f\"原始数据行数: {len(df)}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 步骤1: 添加VOD及SM数据\n",
    "    # ===================================================================\n",
    "    print(\"添加VOD及SM数据...\")\n",
    "    \n",
    "    # 准备结果列\n",
    "    for var in VOD_VARIABLES:\n",
    "        col_name = 'SM_Satellite' if var == 'SM' else var\n",
    "        df[col_name] = np.nan\n",
    "    \n",
    "    # 创建缓存以提高性能\n",
    "    date_vod_map = {}\n",
    "    \n",
    "    # 处理每个日期\n",
    "    dates = df['Date'].apply(safe_date_to_str).unique()\n",
    "    for date_str in dates:\n",
    "        if not date_str or len(date_str) != 8:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            year = int(date_str[:4])\n",
    "            \n",
    "            # 确定文件路径\n",
    "            if year <= 2012:\n",
    "                file_path = f\"E:\\\\data\\\\VOD\\\\mat\\\\kuxcVOD\\\\ASC\\\\MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\"\n",
    "            else:\n",
    "                file_path = f\"E:\\\\data\\\\VOD\\\\mat\\\\kuxcVOD\\\\ASC\\\\MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\"\n",
    "            \n",
    "            # 检查并读取文件\n",
    "            if os.path.exists(file_path):\n",
    "                vod_data = read_mat_file(file_path, VOD_VARIABLES, silent=True)\n",
    "                if vod_data:\n",
    "                    date_vod_map[date_str] = vod_data\n",
    "        except Exception as e:\n",
    "            print(f\"处理日期 {date_str} 的VOD文件时出错: {str(e)}\")\n",
    "    \n",
    "    # 填充数据\n",
    "    for i in df.index:\n",
    "        date_str = safe_date_to_str(df.at[i, 'Date'])\n",
    "        if not date_str or date_str not in date_vod_map:\n",
    "            continue\n",
    "            \n",
    "        vod_data = date_vod_map[date_str]\n",
    "        row_index = int(df.at[i, 'row'])\n",
    "        col_index = int(df.at[i, 'col'])\n",
    "        \n",
    "        for var in VOD_VARIABLES:\n",
    "            col_name = 'SM_Satellite' if var == 'SM' else var\n",
    "            matrix = vod_data.get(var)\n",
    "            if matrix is not None and not np.isnan(matrix[row_index, col_index]):\n",
    "                df.at[i, col_name] = matrix[row_index, col_index]\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 步骤2: 添加PFT数据\n",
    "    # ===================================================================\n",
    "    print(\"添加PFT数据...\")\n",
    "    \n",
    "    # 准备结果列\n",
    "    for var in PFT_VARIABLES:\n",
    "        df[var] = np.nan\n",
    "    \n",
    "    # 获取所有年份\n",
    "    years = set()\n",
    "    for date_str in df['Date'].apply(safe_date_to_str):\n",
    "        if len(date_str) >= 4 and date_str[:4].isdigit():\n",
    "            years.add(int(date_str[:4]))\n",
    "    \n",
    "    # 创建缓存以提高性能\n",
    "    year_pft_map = {}\n",
    "    \n",
    "    # 处理每个年份\n",
    "    for year in years:\n",
    "        file_path = f\"E:\\\\data\\\\ESACCI PFT\\\\Resample\\\\Data\\\\{year}.mat\"\n",
    "        if os.path.exists(file_path):\n",
    "            pft_data = read_mat_file(file_path, PFT_VARIABLES, silent=True)\n",
    "            if pft_data:\n",
    "                year_pft_map[year] = pft_data\n",
    "    \n",
    "    # 填充数据\n",
    "    for i in df.index:\n",
    "        date_str = safe_date_to_str(df.at[i, 'Date'])\n",
    "        if not date_str or len(date_str) < 4:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            year = int(date_str[:4])\n",
    "            pft_data = year_pft_map.get(year)\n",
    "            \n",
    "            if pft_data is None:\n",
    "                continue\n",
    "                \n",
    "            row_index = int(df.at[i, 'row'])\n",
    "            col_index = int(df.at[i, 'col'])\n",
    "            \n",
    "            for var in PFT_VARIABLES:\n",
    "                matrix = pft_data.get(var)\n",
    "                if matrix is not None and not np.isnan(matrix[row_index, col_index]):\n",
    "                    df.at[i, var] = matrix[row_index, col_index]\n",
    "        except Exception as e:\n",
    "            print(f\"处理行 {i} 的PFT数据时出错: {str(e)}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 步骤3: 添加LAI数据\n",
    "    # ===================================================================\n",
    "    print(\"添加LAI数据...\")\n",
    "    df['LAI_Satellite'] = np.nan\n",
    "    \n",
    "    # 创建缓存以提高性能\n",
    "    lai_cache = {}\n",
    "    \n",
    "    # 处理每个日期\n",
    "    for i in df.index:\n",
    "        date_str = safe_date_to_str(df.at[i, 'Date'])\n",
    "        if not date_str or len(date_str) != 8:\n",
    "            continue\n",
    "            \n",
    "        # 计算权重和月份\n",
    "        prev_month, next_month, weight = calculate_lai_weight(date_str)\n",
    "        if prev_month is None:\n",
    "            continue\n",
    "            \n",
    "        # 检查并读取当前月份文件\n",
    "        lai1 = np.nan\n",
    "        file1_path = f\"E:\\\\data\\\\GLASS LAI\\\\mat\\\\0.1Deg\\\\Dataset\\\\{prev_month[0]:04d}-{prev_month[1]:02d}-01.tif.mat\"\n",
    "    \n",
    "       \n",
    "        if file1_path in lai_cache:\n",
    "            lai1 = lai_cache[file1_path]\n",
    "        elif os.path.exists(file1_path):\n",
    "            lai_data1 = read_mat_file(file1_path, ['lai'], silent=True)\n",
    "            if lai_data1 and 'lai' in lai_data1:\n",
    "                matrix = lai_data1['lai']\n",
    "                row_index = int(df.at[i, 'row'])\n",
    "                col_index = int(df.at[i, 'col'])\n",
    "                \n",
    "                try:\n",
    "                    lai1 = matrix[row_index, col_index]\n",
    "                    lai_cache[file1_path] = lai1\n",
    "                except:\n",
    "                    lai_cache[file1_path] = np.nan\n",
    "            else:\n",
    "                lai_cache[file1_path] = np.nan\n",
    "                lai1 = np.nan\n",
    "        else:\n",
    "            lai1 = np.nan\n",
    "            \n",
    "        # 检查并读取下个月份文件\n",
    "        lai2 = np.nan\n",
    "        file2_path = f\"E:\\\\data\\\\GLASS LAI\\\\mat\\\\0.1Deg\\\\Dataset\\\\{next_month[0]:04d}-{next_month[1]:02d}-01.tif.mat\"\n",
    "        \n",
    "        if file2_path in lai_cache:\n",
    "            lai2 = lai_cache[file2_path]\n",
    "        elif os.path.exists(file2_path):\n",
    "            lai_data2 = read_mat_file(file2_path, ['lai'], silent=True)\n",
    "            if lai_data2 and 'lai' in lai_data2:\n",
    "                matrix = lai_data2['lai']\n",
    "                row_index = int(df.at[i, 'row'])\n",
    "                col_index = int(df.at[i, 'col'])\n",
    "                \n",
    "                try:\n",
    "                    lai2 = matrix[row_index, col_index]\n",
    "                    lai_cache[file2_path] = lai2\n",
    "                except:\n",
    "                    lai_cache[file2_path] = np.nan\n",
    "            else:\n",
    "                lai_cache[file2_path] = np.nan\n",
    "                lai2 = np.nan\n",
    "        else:\n",
    "            lai2 = np.nan\n",
    "            \n",
    "        # 线性插值计算最终LAI值\n",
    "        if not np.isnan(lai1) and not np.isnan(lai2):\n",
    "            # 使用权重进行线性插值\n",
    "            lai_final = (1 - weight) * lai1 + weight * lai2\n",
    "        elif not np.isnan(lai1):\n",
    "            lai_final = lai1\n",
    "        elif not np.isnan(lai2):\n",
    "            lai_final = lai2\n",
    "        else:\n",
    "            lai_final = np.nan\n",
    "            \n",
    "        df.at[i, 'LAI_Satellite'] = lai_final\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 步骤4: 添加Hveg数据\n",
    "    # ===================================================================\n",
    "    print(\"添加Hveg数据...\")\n",
    "    df['Hveg_Satellite'] = np.nan\n",
    "    \n",
    "    hveg_file = \"E:\\\\data\\\\CanopyHeight\\\\CH.mat\"\n",
    "    if os.path.exists(hveg_file):\n",
    "        hveg_data = read_mat_file(hveg_file, ['Hveg'])\n",
    "        if hveg_data and 'Hveg' in hveg_data:\n",
    "            matrix = hveg_data['Hveg']\n",
    "            \n",
    "            # 填充数据\n",
    "            for i in df.index:\n",
    "                row_index = int(df.at[i, 'row'])\n",
    "                col_index = int(df.at[i, 'col'])\n",
    "                \n",
    "                try:\n",
    "                    df.at[i, 'Hveg_Satellite'] = matrix[row_index, col_index]\n",
    "                except (IndexError, ValueError):\n",
    "                    # 保留NaN值\n",
    "                    pass\n",
    "    \n",
    "    print(f\"处理完成, 最终数据行数: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# 主处理过程\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = r'E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16'\n",
    "    input_file = os.path.join(input_dir, 'InsituData_Pixel.xlsx')\n",
    "    output_file = os.path.join(input_dir, 'InsituData_Pixel_ML.xlsx')\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    \n",
    "    # 处理每个sheet\n",
    "    sheet_names = ['SMEX02', 'CLASIC07', 'SMEX08', 'SMAPVEX16']\n",
    "    output_dfs = {}\n",
    "    \n",
    "    # 读取输入Excel文件\n",
    "    for sheet in sheet_names:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"处理数据集: {sheet}\")\n",
    "        try:\n",
    "            df = pd.read_excel(input_file, sheet_name=sheet, engine='openpyxl')\n",
    "            \n",
    "            # 确保有足够的行\n",
    "            if len(df) == 0:\n",
    "                print(f\"警告: {sheet} 中没有数据\")\n",
    "                output_dfs[sheet] = pd.DataFrame()\n",
    "                continue\n",
    "            \n",
    "            processed_df = process_dataset(df, sheet)\n",
    "            output_dfs[sheet] = processed_df\n",
    "            \n",
    "            # 添加虚拟行避免保存错误\n",
    "            if processed_df.empty:\n",
    "                # 创建至少一行数据防止ExcelWriter错误\n",
    "                processed_df = pd.DataFrame(columns=df.columns)\n",
    "                processed_df.loc[0] = [None] * len(processed_df.columns)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理 {sheet} 时出错: {str(e)}\")\n",
    "            # 创建空DataFrame但有列名防止保存错误\n",
    "            try:\n",
    "                df = pd.read_excel(input_file, sheet_name=sheet, nrows=0, engine='openpyxl')\n",
    "                output_dfs[sheet] = df\n",
    "            except:\n",
    "                output_dfs[sheet] = pd.DataFrame(columns=['Date', 'row', 'col'])\n",
    "    \n",
    "    # 保存结果\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for sheet, df in output_dfs.items():\n",
    "            if not df.empty:\n",
    "                print(f\"保存 '{sheet}' 到Excel文件 ({len(df)} 行)\")\n",
    "                df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "            else:\n",
    "                # 创建空但有列名的sheet\n",
    "                print(f\"{sheet} 无有效数据，创建空工作表\")\n",
    "                empty_df = pd.DataFrame(columns=df.columns)\n",
    "                empty_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理完成! 结果已保存至: {output_file}\")\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"文件大小: {os.path.getsize(output_file)/1024/1024:.2f} MB\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088ff894-f878-4a2d-99b0-73b3e5fa7750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\n",
      "  - SMEX02: 16行\n",
      "    替换了 14 行SM_Satellite数据\n",
      "  - CLASIC07: 18行\n",
      "  - SMAPVEX08: 6行\n",
      "    替换了 6 行LAI_Satellite数据\n",
      "  - SMAPVEX16: 115行\n",
      "\n",
      "处理波段-极化组合: Ku-H\n",
      "加载模型: models/RFR_Ku_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.5369, 1.0814]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.2684, 0.5407]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 7 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.4142, 0.7737]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.2071, 0.3869]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.3438, 0.7910]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.1719, 0.3955]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.4034, 1.2499]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.2017, 0.6250]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.5369, 1.0814]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.4142, 0.7737]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.3438, 0.7910]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.4034, 1.2499]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 3.3250\n",
      "  CLASIC07 原始模型预测RMSE: 2.2086\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.6414\n",
      "  SMAPVEX16 原始模型预测RMSE: 4.4347\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 145个样本\n",
      "    微调模型: 新增50棵树，使用145个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 3.1392 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 2.1070 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.4440 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 4.1913 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: Ku-V\n",
      "加载模型: models/RFR_Ku_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.6286, 0.7654]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.3143, 0.3827]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.4049, 0.7325]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.2025, 0.3663]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.3626, 0.6484]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.1813, 0.3242]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.2219, 1.8054]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.1109, 0.9027]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.6286, 0.7654]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.4049, 0.7325]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.3626, 0.6484]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.2219, 1.8054]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 3.4279\n",
      "  CLASIC07 原始模型预测RMSE: 1.8486\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.4580\n",
      "  SMAPVEX16 原始模型预测RMSE: 4.2213\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 109个样本\n",
      "    微调模型: 新增50棵树，使用109个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.9947 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 1.6207 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.0283 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.7000 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: Ku-HV\n",
      "加载模型: models/RFR_Ku_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD-Hpol 原始范围: [0.5369, 1.0814]\n",
      "  SMEX02 VOD-Vpol 原始范围: [0.6286, 0.7654]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD-Hpol 归一化后范围: [0.2684, 0.5407]\n",
      "  SMEX02 VOD-Vpol 归一化后范围: [0.3143, 0.3827]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  CLASIC07 VOD-Hpol 原始范围: [0.4142, 0.7737]\n",
      "  CLASIC07 VOD-Vpol 原始范围: [0.4049, 0.7325]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD-Hpol 归一化后范围: [0.2071, 0.3869]\n",
      "  CLASIC07 VOD-Vpol 归一化后范围: [0.2025, 0.3663]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD-Hpol 原始范围: [0.3438, 0.7910]\n",
      "  SMAPVEX08 VOD-Vpol 原始范围: [0.3626, 0.6484]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD-Hpol 归一化后范围: [0.1719, 0.3955]\n",
      "  SMAPVEX08 VOD-Vpol 归一化后范围: [0.1813, 0.3242]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD-Hpol 原始范围: [0.4034, 1.2499]\n",
      "  SMAPVEX16 VOD-Vpol 原始范围: [0.2219, 1.8054]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD-Hpol 归一化后范围: [0.2017, 0.6250]\n",
      "  SMAPVEX16 VOD-Vpol 归一化后范围: [0.1109, 0.9027]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD-Hpol: [0.5369, 1.0814]\n",
      "  VOD-Vpol: [0.6286, 0.7654]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD-Hpol: [0.4142, 0.7737]\n",
      "  VOD-Vpol: [0.4049, 0.7325]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD-Hpol: [0.3438, 0.7910]\n",
      "  VOD-Vpol: [0.3626, 0.6484]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD-Hpol: [0.4034, 1.2499]\n",
      "  VOD-Vpol: [0.2219, 1.8054]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.1328\n",
      "  CLASIC07 原始模型预测RMSE: 1.8340\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.3077\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.5568\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 109个样本\n",
      "    微调模型: 新增50棵树，使用109个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 1.9709 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 1.6935 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.0547 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.2873 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: X-H\n",
      "加载模型: models/RFR_X_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.3947, 1.4596]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.1973, 0.7298]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 6 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.2871, 0.5711]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.1436, 0.2856]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.2713, 0.5627]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.1356, 0.2813]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.3595, 0.9604]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.1798, 0.4802]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.3947, 1.4596]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.2871, 0.5711]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.2713, 0.5627]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.3595, 0.9604]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.9876\n",
      "  CLASIC07 原始模型预测RMSE: 2.1776\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.7587\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.7522\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 146个样本\n",
      "    微调模型: 新增50棵树，使用146个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.7898 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 2.0647 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.5186 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.5066 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: X-V\n",
      "加载模型: models/RFR_X_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.4351, 1.0064]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.2176, 0.5032]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.0755, 0.7287]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.0378, 0.3643]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.2481, 0.4814]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.1241, 0.2407]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.2049, 1.7812]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.1025, 0.8906]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.4351, 1.0064]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.0755, 0.7287]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.2481, 0.4814]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.2049, 1.7812]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.5485\n",
      "  CLASIC07 原始模型预测RMSE: 1.7007\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.1030\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.9412\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 129个样本\n",
      "    微调模型: 新增50棵树，使用129个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.3786 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 1.5985 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 2.8988 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.6820 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: X-HV\n",
      "加载模型: models/RFR_X_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD-Hpol 原始范围: [0.3947, 1.4596]\n",
      "  SMEX02 VOD-Vpol 原始范围: [0.4351, 1.0064]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD-Hpol 归一化后范围: [0.1973, 0.7298]\n",
      "  SMEX02 VOD-Vpol 归一化后范围: [0.2176, 0.5032]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 VOD-Hpol 原始范围: [0.2871, 0.5711]\n",
      "  CLASIC07 VOD-Vpol 原始范围: [0.0755, 0.7287]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD-Hpol 归一化后范围: [0.1436, 0.2856]\n",
      "  CLASIC07 VOD-Vpol 归一化后范围: [0.0378, 0.3643]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD-Hpol 原始范围: [0.2713, 0.5627]\n",
      "  SMAPVEX08 VOD-Vpol 原始范围: [0.2481, 0.4814]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD-Hpol 归一化后范围: [0.1356, 0.2813]\n",
      "  SMAPVEX08 VOD-Vpol 归一化后范围: [0.1241, 0.2407]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD-Hpol 原始范围: [0.3595, 0.9604]\n",
      "  SMAPVEX16 VOD-Vpol 原始范围: [0.2049, 1.7812]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD-Hpol 归一化后范围: [0.1798, 0.4802]\n",
      "  SMAPVEX16 VOD-Vpol 归一化后范围: [0.1025, 0.8906]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD-Hpol: [0.3947, 1.4596]\n",
      "  VOD-Vpol: [0.4351, 1.0064]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD-Hpol: [0.2871, 0.5711]\n",
      "  VOD-Vpol: [0.0755, 0.7287]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD-Hpol: [0.2713, 0.5627]\n",
      "  VOD-Vpol: [0.2481, 0.4814]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD-Hpol: [0.3595, 0.9604]\n",
      "  VOD-Vpol: [0.2049, 1.7812]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.2249\n",
      "  CLASIC07 原始模型预测RMSE: 1.5384\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.1673\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.7754\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 129个样本\n",
      "    微调模型: 新增50棵树，使用129个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.0015 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 1.3966 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 2.8488 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.4021 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: C-H\n",
      "加载模型: models/RFR_C_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.4533, 0.7661]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.2267, 0.3831]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.2258, 0.4418]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.1129, 0.2209]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.2293, 0.4395]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.1147, 0.2198]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.3209, 0.8175]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.1605, 0.4088]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.4533, 0.7661]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.2258, 0.4418]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.2293, 0.4395]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.3209, 0.8175]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.9076\n",
      "  CLASIC07 原始模型预测RMSE: 2.2200\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.7747\n",
      "  SMAPVEX16 原始模型预测RMSE: 4.0150\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 141个样本\n",
      "    微调模型: 新增50棵树，使用141个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.6194 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 2.0444 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.4022 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.6196 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: C-V\n",
      "加载模型: models/RFR_C_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD 原始范围: [0.0181, 0.1349]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD 归一化后范围: [0.0091, 0.0675]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  CLASIC07 VOD 原始范围: [0.0156, 0.6011]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD 归一化后范围: [0.0078, 0.3006]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD 原始范围: [0.1985, 0.6102]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD 归一化后范围: [0.0993, 0.3051]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD 原始范围: [0.3027, 0.8748]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD 归一化后范围: [0.1513, 0.4374]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD: [0.0181, 0.1349]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD: [0.0156, 0.6011]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD: [0.1985, 0.6102]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD: [0.3027, 0.8748]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.8022\n",
      "  CLASIC07 原始模型预测RMSE: 2.3944\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.9095\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.9582\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 96个样本\n",
      "    微调模型: 新增50棵树，使用96个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 2.5585 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 2.2321 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.5886 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.6326 (改进: 0.0000)\n",
      "\n",
      "处理波段-极化组合: C-HV\n",
      "加载模型: models/RFR_C_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 VOD-Hpol 原始范围: [0.4533, 0.7661]\n",
      "  SMEX02 VOD-Vpol 原始范围: [0.0181, 0.1349]\n",
      "  SMEX02 LAI 原始范围: [2.7000, 3.4800]\n",
      "  SMEX02 SM 原始范围: [0.1133, 0.2167]\n",
      "  SMEX02 Grass_man 原始范围: [93.1111, 99.3827]\n",
      "  SMEX02 Grass_nat 原始范围: [0.6173, 4.8974]\n",
      "  SMEX02 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 原始范围: [0.0000, 0.9398]\n",
      "  SMEX02 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMEX02 VOD-Hpol 归一化后范围: [0.2267, 0.3831]\n",
      "  SMEX02 VOD-Vpol 归一化后范围: [0.0091, 0.0675]\n",
      "  SMEX02 LAI 归一化后范围: [0.4500, 0.5800]\n",
      "  SMEX02 Grass_man 归一化后范围: [0.9311, 0.9938]\n",
      "  SMEX02 Grass_nat 归一化后范围: [0.0062, 0.0490]\n",
      "  SMEX02 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_bd 归一化后范围: [0.0000, 0.0094]\n",
      "  SMEX02 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 Tree_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  CLASIC07 VOD-Hpol 原始范围: [0.2258, 0.4418]\n",
      "  CLASIC07 VOD-Vpol 原始范围: [0.0156, 0.6011]\n",
      "  CLASIC07 LAI 原始范围: [1.7200, 1.9161]\n",
      "  CLASIC07 SM 原始范围: [0.0024, 0.2490]\n",
      "  CLASIC07 Grass_man 原始范围: [6.1906, 84.6744]\n",
      "  CLASIC07 Grass_nat 原始范围: [14.6065, 90.2137]\n",
      "  CLASIC07 Shrub_bd 原始范围: [0.0000, 0.0123]\n",
      "  CLASIC07 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 原始范围: [0.2245, 1.8927]\n",
      "  CLASIC07 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 原始范围: [0.0000, 1.9398]\n",
      "  CLASIC07 VOD-Hpol 归一化后范围: [0.1129, 0.2209]\n",
      "  CLASIC07 VOD-Vpol 归一化后范围: [0.0078, 0.3006]\n",
      "  CLASIC07 LAI 归一化后范围: [0.2867, 0.3194]\n",
      "  CLASIC07 Grass_man 归一化后范围: [0.0619, 0.8467]\n",
      "  CLASIC07 Grass_nat 归一化后范围: [0.1461, 0.9021]\n",
      "  CLASIC07 Shrub_bd 归一化后范围: [0.0000, 0.0001]\n",
      "  CLASIC07 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_bd 归一化后范围: [0.0022, 0.0189]\n",
      "  CLASIC07 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  CLASIC07 Tree_ne 归一化后范围: [0.0000, 0.0194]\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  SMAPVEX08 VOD-Hpol 原始范围: [0.2293, 0.4395]\n",
      "  SMAPVEX08 VOD-Vpol 原始范围: [0.1985, 0.6102]\n",
      "  SMAPVEX08 LAI 原始范围: [0.6600, 3.3300]\n",
      "  SMAPVEX08 SM 原始范围: [0.2623, 0.3314]\n",
      "  SMAPVEX08 Grass_man 原始范围: [72.0355, 76.1651]\n",
      "  SMAPVEX08 Grass_nat 原始范围: [5.1489, 6.0085]\n",
      "  SMAPVEX08 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 原始范围: [18.2840, 21.5147]\n",
      "  SMAPVEX08 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 原始范围: [0.0000, 0.1080]\n",
      "  SMAPVEX08 Tree_ne 原始范围: [0.0000, 0.0710]\n",
      "  SMAPVEX08 VOD-Hpol 归一化后范围: [0.1147, 0.2198]\n",
      "  SMAPVEX08 VOD-Vpol 归一化后范围: [0.0993, 0.3051]\n",
      "  SMAPVEX08 LAI 归一化后范围: [0.1100, 0.5550]\n",
      "  SMAPVEX08 Grass_man 归一化后范围: [0.7204, 0.7617]\n",
      "  SMAPVEX08 Grass_nat 归一化后范围: [0.0515, 0.0601]\n",
      "  SMAPVEX08 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_bd 归一化后范围: [0.1828, 0.2151]\n",
      "  SMAPVEX08 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX08 Tree_nd 归一化后范围: [0.0000, 0.0011]\n",
      "  SMAPVEX08 Tree_ne 归一化后范围: [0.0000, 0.0007]\n",
      "  SMAPVEX16 VOD-Hpol 原始范围: [0.3209, 0.8175]\n",
      "  SMAPVEX16 VOD-Vpol 原始范围: [0.3027, 0.8748]\n",
      "  SMAPVEX16 LAI 原始范围: [2.3774, 4.0710]\n",
      "  SMAPVEX16 SM 原始范围: [0.0839, 0.3003]\n",
      "  SMAPVEX16 Grass_man 原始范围: [93.3210, 99.9884]\n",
      "  SMAPVEX16 Grass_nat 原始范围: [0.0000, 2.5278]\n",
      "  SMAPVEX16 Shrub_bd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 原始范围: [0.0116, 4.1512]\n",
      "  SMAPVEX16 Tree_be 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 原始范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 原始范围: [0.0000, 0.0363]\n",
      "  SMAPVEX16 VOD-Hpol 归一化后范围: [0.1605, 0.4088]\n",
      "  SMAPVEX16 VOD-Vpol 归一化后范围: [0.1513, 0.4374]\n",
      "  SMAPVEX16 LAI 归一化后范围: [0.3962, 0.6785]\n",
      "  SMAPVEX16 Grass_man 归一化后范围: [0.9332, 0.9999]\n",
      "  SMAPVEX16 Grass_nat 归一化后范围: [0.0000, 0.0253]\n",
      "  SMAPVEX16 Shrub_bd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Shrub_ne 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_bd 归一化后范围: [0.0001, 0.0415]\n",
      "  SMAPVEX16 Tree_be 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_nd 归一化后范围: [0.0000, 0.0000]\n",
      "  SMAPVEX16 Tree_ne 归一化后范围: [0.0000, 0.0004]\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "\n",
      "===== 输入特征范围摘要 =====\n",
      "\n",
      "数据集: SMEX02\n",
      "  VOD-Hpol: [0.4533, 0.7661]\n",
      "  VOD-Vpol: [0.0181, 0.1349]\n",
      "  LAI: [2.7000, 3.4800]\n",
      "  SM: [0.1133, 0.2167]\n",
      "  Grass_man: [93.1111, 99.3827]\n",
      "  Grass_nat: [0.6173, 4.8974]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0000, 0.9398]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0000]\n",
      "\n",
      "数据集: CLASIC07\n",
      "  VOD-Hpol: [0.2258, 0.4418]\n",
      "  VOD-Vpol: [0.0156, 0.6011]\n",
      "  LAI: [1.7200, 1.9161]\n",
      "  SM: [0.0024, 0.2490]\n",
      "  Grass_man: [6.1906, 84.6744]\n",
      "  Grass_nat: [14.6065, 90.2137]\n",
      "  Shrub_bd: [0.0000, 0.0123]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.2245, 1.8927]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 1.9398]\n",
      "\n",
      "数据集: SMAPVEX08\n",
      "  VOD-Hpol: [0.2293, 0.4395]\n",
      "  VOD-Vpol: [0.1985, 0.6102]\n",
      "  LAI: [0.6600, 3.3300]\n",
      "  SM: [0.2623, 0.3314]\n",
      "  Grass_man: [72.0355, 76.1651]\n",
      "  Grass_nat: [5.1489, 6.0085]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [18.2840, 21.5147]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.1080]\n",
      "  Tree_ne: [0.0000, 0.0710]\n",
      "\n",
      "数据集: SMAPVEX16\n",
      "  VOD-Hpol: [0.3209, 0.8175]\n",
      "  VOD-Vpol: [0.3027, 0.8748]\n",
      "  LAI: [2.3774, 4.0710]\n",
      "  SM: [0.0839, 0.3003]\n",
      "  Grass_man: [93.3210, 99.9884]\n",
      "  Grass_nat: [0.0000, 2.5278]\n",
      "  Shrub_bd: [0.0000, 0.0000]\n",
      "  Shrub_be: [0.0000, 0.0000]\n",
      "  Shrub_nd: [0.0000, 0.0000]\n",
      "  Shrub_ne: [0.0000, 0.0000]\n",
      "  Tree_bd: [0.0116, 4.1512]\n",
      "  Tree_be: [0.0000, 0.0000]\n",
      "  Tree_nd: [0.0000, 0.0000]\n",
      "  Tree_ne: [0.0000, 0.0363]\n",
      "===========================\n",
      "\n",
      "===== 使用原始模型预测 =====\n",
      "  SMEX02 原始模型预测RMSE: 2.0967\n",
      "  CLASIC07 原始模型预测RMSE: 2.2208\n",
      "  SMAPVEX08 原始模型预测RMSE: 3.9137\n",
      "  SMAPVEX16 原始模型预测RMSE: 3.9833\n",
      "\n",
      "===== 应用迁移学习 (微调) =====\n",
      "  合并数据量: 96个样本\n",
      "    微调模型: 新增50棵树，使用96个样本\n",
      "\n",
      "===== 使用微调模型预测 =====\n",
      "  SMEX02 微调模型预测RMSE: 1.9798 (改进: 0.0000)\n",
      "  CLASIC07 微调模型预测RMSE: 2.0972 (改进: 0.0000)\n",
      "  SMAPVEX08 微调模型预测RMSE: 3.6838 (改进: 0.0000)\n",
      "  SMAPVEX16 微调模型预测RMSE: 3.7512 (改进: 0.0000)\n",
      "创建散点图...\n",
      "散点图已保存至: figures/AllSMAPInsituData_VWC_Scatter_FT.png\n",
      "保存预测结果到: Ku_H (145行)\n",
      "保存预测结果到: Ku_V (109行)\n",
      "保存预测结果到: Ku_HV (109行)\n",
      "保存预测结果到: X_H (146行)\n",
      "保存预测结果到: X_V (129行)\n",
      "保存预测结果到: X_HV (129行)\n",
      "保存预测结果到: C_H (141行)\n",
      "保存预测结果到: C_V (96行)\n",
      "保存预测结果到: C_HV (96行)\n",
      "所有预测结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\details.xlsx\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "##  添加迁移学习提升精度\n",
    "# 散点图（4个数据画在一块，写出n，按照波段-极化组合绘制为3*3）\n",
    "# 点形状及颜色：\n",
    "# SMEX02：*；CLASIC07：^；SMEX08：+；SMAPVEX16：o\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "SHEET_NAMES = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "VWC_COLUMNS = {\n",
    "    'SMEX02': 'VWC-Field',\n",
    "    'CLASIC07': 'VWC (kg/m²)',\n",
    "    'SMAPVEX08': 'VWC',\n",
    "    'SMAPVEX16': 'PLANT_WATER_CONTENT_AREA'\n",
    "}\n",
    "\n",
    "# 标记和颜色设置\n",
    "MARKER_STYLES = {\n",
    "    'SMEX02': {'marker': 'x', 'color': '#F8766D'},\n",
    "    'CLASIC07': {'marker': '^', 'facecolor': 'none', 'edgecolor': '#00BFC4'},\n",
    "    'SMAPVEX08': {'marker': '+', 'color': '#C77CFF'},\n",
    "    'SMAPVEX16': {'marker': 'o', 'facecolor': 'none', 'edgecolor': '#7CAE00'}\n",
    "}\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    加载并预处理Excel文件中的所有sheet\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): Excel文件路径\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含预处理后数据的字典，键为sheet名称\n",
    "    \"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 替换SM_Satellite和LAI_Satellite（如果存在地面实测数据）\n",
    "            if 'SM' in df.columns:\n",
    "                mask = df['SM'].notna()\n",
    "                df.loc[mask, 'SM_Satellite'] = df.loc[mask, 'SM']\n",
    "                print(f\"    替换了 {mask.sum()} 行SM_Satellite数据\")\n",
    "            \n",
    "            if 'LAI' in df.columns:\n",
    "                mask = df['LAI'].notna()\n",
    "                df.loc[mask, 'LAI_Satellite'] = df.loc[mask, 'LAI']\n",
    "                print(f\"    替换了 {mask.sum()} 行LAI_Satellite数据\")\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_features_for_model(band, pol):\n",
    "    \"\"\"\n",
    "    根据波段和极化类型获取特征列表（使用模型训练时的名称）\n",
    "    \n",
    "    参数:\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    list: 特征列名列表\n",
    "    \"\"\"\n",
    "    # 使用模型训练时的特征名称\n",
    "    features = [\n",
    "        'LAI',  # 注意：训练时使用\"LAI\"而不是\"LAI_Satellite\"\n",
    "        'SM',   # 注意：训练时使用\"SM\"而不是\"SM_Satellite\"\n",
    "        'Grass_man', \n",
    "        'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    # 添加VOD特征 - 根据模型类型\n",
    "    if pol == 'H' or pol == 'V':\n",
    "        # 单极化模型使用\"VOD\"\n",
    "        features.append('VOD')\n",
    "    elif pol == 'HV':\n",
    "        # 双极化模型使用\"VOD-Hpol\"和\"VOD-Vpol\"\n",
    "        features.extend(['VOD-Hpol', 'VOD-Vpol'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "##  新增迁移学习相关参数\n",
    "FINE_TUNE_PARAMS = {\n",
    "    'n_estimators': 50,        # 微调时新增树的数量（保持原有树不变）\n",
    "    'max_depth': None,          # 新树的最大深度\n",
    "    'max_samples': 0.8,         # 每个新树的样本采样比例\n",
    "    'random_state': 42,         # 随机种子\n",
    "    'n_jobs': -1,               # 使用所有CPU核心\n",
    "}\n",
    "\n",
    "def load_model_with_finetuning(model_path):\n",
    "    \"\"\"\n",
    "    加载模型并为迁移学习做准备\n",
    "    返回值：原始模型、是否支持迁移学习的标志\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  模型文件不存在: {model_path}\")\n",
    "        return None, False\n",
    "        \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"  成功加载原始模型，支持迁移学习: {hasattr(model, 'fit')}\")\n",
    "        return model, hasattr(model, 'fit')  # 仅支持可训练的模型\n",
    "    except Exception as e:\n",
    "        print(f\"  加载模型失败: {str(e)}\")\n",
    "        return None, False\n",
    "\n",
    "def predict_vwc(data_dict, band, pol):\n",
    "    \"\"\"\n",
    "    使用指定模型预测VWC，包括特征归一化和迁移学习\n",
    "    \n",
    "    参数:\n",
    "    data_dict (dict): 包含所有sheet数据的字典\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含每个sheet预测结果的字典\n",
    "    \"\"\"\n",
    "    # 迁移学习配置\n",
    "    FINE_TUNE_PARAMS = {\n",
    "        'n_estimators': 50,        # 微调时新增树的数量\n",
    "        'max_depth': 8,            # 新树的最大深度\n",
    "        'max_samples': 0.8,        # 每个新树的样本采样比例\n",
    "        'random_state': 42,        # 随机种子\n",
    "        'n_jobs': -1,              # 使用所有CPU核心\n",
    "    }\n",
    "    \n",
    "    # 加载模型\n",
    "    model_path = f\"models/RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "    print(f\"加载模型: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  模型文件不存在: {model_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        # 打印模型训练时的特征名称\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            print(f\"  模型训练特征: {list(model.feature_names_in_)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  加载模型失败: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "    # 获取特征列表\n",
    "    features = get_features_for_model(band, pol)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    predictions = {}\n",
    "    # 存储所有数据集特征统计信息\n",
    "    feature_ranges = {}\n",
    "    \n",
    "    # 第一步：收集所有数据集的特征数据用于微调\n",
    "    finetune_data = {}\n",
    "    \n",
    "    for sheet, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "        # 创建特征映射\n",
    "        feature_mapping = {}\n",
    "        for feature in features:\n",
    "            if feature == 'VOD':\n",
    "                if pol == 'H':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_H'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_H'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_H'] = 'VOD'\n",
    "                elif pol == 'V':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_V'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_V'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_V'] = 'VOD'\n",
    "            elif feature == 'VOD-Hpol':\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_H'] = 'VOD-Hpol'\n",
    "            elif feature == 'VOD-Vpol':\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_V'] = 'VOD-Vpol'\n",
    "            else:\n",
    "                if feature == 'LAI':\n",
    "                    feature_mapping['LAI_Satellite'] = 'LAI'\n",
    "                elif feature == 'SM':\n",
    "                    feature_mapping['SM_Satellite'] = 'SM'\n",
    "                elif feature == 'Grass_man':\n",
    "                    feature_mapping['grassman'] = 'Grass_man'\n",
    "                elif feature == 'Grass_nat':\n",
    "                    feature_mapping['grassnat'] = 'Grass_nat'\n",
    "                elif feature == 'Shrub_bd':\n",
    "                    feature_mapping['shrubbd'] = 'Shrub_bd'\n",
    "                elif feature == 'Shrub_be':\n",
    "                    feature_mapping['shrubbe'] = 'Shrub_be'\n",
    "                elif feature == 'Shrub_nd':\n",
    "                    feature_mapping['shrubnd'] = 'Shrub_nd'\n",
    "                elif feature == 'Shrub_ne':\n",
    "                    feature_mapping['shrubne'] = 'Shrub_ne'\n",
    "                elif feature == 'Tree_bd':\n",
    "                    feature_mapping['treebd'] = 'Tree_bd'\n",
    "                elif feature == 'Tree_be':\n",
    "                    feature_mapping['treebe'] = 'Tree_be'\n",
    "                elif feature == 'Tree_nd':\n",
    "                    feature_mapping['treend'] = 'Tree_nd'\n",
    "                elif feature == 'Tree_ne':\n",
    "                    feature_mapping['treene'] = 'Tree_ne'\n",
    "        \n",
    "        # 检查是否包含所有必要特征\n",
    "        missing_features = []\n",
    "        for data_feature in feature_mapping.keys():\n",
    "            if data_feature not in df.columns:\n",
    "                missing_features.append(data_feature)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"  {sheet} 缺少特征: {', '.join(missing_features)}\")\n",
    "            continue\n",
    "        \n",
    "        # 准备数据（使用重命名的特征）\n",
    "        X = df[list(feature_mapping.keys())].copy()\n",
    "        X.columns = [feature_mapping[col] for col in X.columns]\n",
    "        \n",
    "        # 确保特征顺序与模型期望一致\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            X = X[list(model.feature_names_in_)]\n",
    "        \n",
    "        # 记录原始特征范围（归一化前）\n",
    "        if sheet not in feature_ranges:\n",
    "            feature_ranges[sheet] = {}\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if col not in feature_ranges[sheet]:\n",
    "                min_val = X[col].min()\n",
    "                max_val = X[col].max()\n",
    "                feature_ranges[sheet][col] = (min_val, max_val)\n",
    "                print(f\"  {sheet} {col} 原始范围: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "        \n",
    "        # 应用归一化处理\n",
    "        vod_features = ['VOD', 'VOD-Hpol', 'VOD-Vpol']\n",
    "        for vod_feature in vod_features:\n",
    "            if vod_feature in X.columns:\n",
    "                X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "                # 记录归一化后范围\n",
    "                min_val = X[vod_feature].min()\n",
    "                max_val = X[vod_feature].max()\n",
    "                print(f\"  {sheet} {vod_feature} 归一化后范围: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "        \n",
    "        if 'LAI' in X.columns:\n",
    "            X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "            min_val = X['LAI'].min()\n",
    "            max_val = X['LAI'].max()\n",
    "            print(f\"  {sheet} LAI 归一化后范围: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "        \n",
    "        pft_features = [\n",
    "            'Grass_man', 'Grass_nat',\n",
    "            'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "            'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "        ]\n",
    "        \n",
    "        for pft_feature in pft_features:\n",
    "            if pft_feature in X.columns:\n",
    "                X[pft_feature] = X[pft_feature] / 100.0\n",
    "                min_val = X[pft_feature].min()\n",
    "                max_val = X[pft_feature].max()\n",
    "                print(f\"  {sheet} {pft_feature} 归一化后范围: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "        \n",
    "        # 移除缺失值\n",
    "        initial_count = len(X)\n",
    "        X = X.dropna()\n",
    "        removed_count = initial_count - len(X)\n",
    "        if removed_count > 0:\n",
    "            print(f\"  {sheet} 移除了 {removed_count} 行包含缺失值的数据\")\n",
    "        \n",
    "        if X.empty:\n",
    "            print(f\"  {sheet} 无有效数据可用于预测\")\n",
    "            continue\n",
    "        \n",
    "        y = df.loc[X.index, VWC_COLUMNS[sheet]]\n",
    "        \n",
    "        # 存储用于迁移学习的完整数据集\n",
    "        finetune_data[sheet] = {\n",
    "            'X': X,\n",
    "            'y': y\n",
    "        }\n",
    "    \n",
    "    # 打印整体特征范围摘要\n",
    "    print(\"\\n===== 输入特征范围摘要 =====\")\n",
    "    for sheet, ranges in feature_ranges.items():\n",
    "        print(f\"\\n数据集: {sheet}\")\n",
    "        for feature, (min_val, max_val) in ranges.items():\n",
    "            print(f\"  {feature}: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "    print(\"===========================\\n\")\n",
    "    \n",
    "    # 第二步：使用原始模型进行预测\n",
    "    print(\"===== 使用原始模型预测 =====\")\n",
    "    for sheet, data in finetune_data.items():\n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "        \n",
    "        y_pred = model.predict(X)\n",
    "        predictions[sheet] = {\n",
    "            'actual': y,\n",
    "            'predicted': y_pred,\n",
    "            'finetuned': False,  # 标记为原始模型预测\n",
    "            'source': sheet,\n",
    "            'row': data['X'].index,\n",
    "            'lat': df.loc[X.index, 'Latitude'] if 'Latitude' in df.columns else None,\n",
    "            'lon': df.loc[X.index, 'Longitude'] if 'Longitude' in df.columns else None,\n",
    "            'date': df.loc[X.index, 'Date'] if 'Date' in df.columns else None\n",
    "        }\n",
    "        \n",
    "        rmse = calculate_rmse(y, y_pred)\n",
    "        print(f\"  {sheet} 原始模型预测RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # 第三步：应用迁移学习（微调）\n",
    "    def finetune_model(original_model, X_finetune, y_finetune):\n",
    "        \"\"\"在目标数据集上微调模型\"\"\"\n",
    "        from copy import deepcopy\n",
    "        \n",
    "        # 创建新模型继承原模型参数\n",
    "        new_model = deepcopy(original_model)\n",
    "        \n",
    "        # 获取原始模型的bootstrap设置\n",
    "        bootstrap_setting = original_model.get_params().get('bootstrap', True)\n",
    "        \n",
    "        # 确保参数兼容性\n",
    "        max_samples_setting = FINE_TUNE_PARAMS['max_samples'] if bootstrap_setting else None\n",
    "        \n",
    "        # 修改参数进行增量训练\n",
    "        new_model.set_params(\n",
    "            warm_start=True,\n",
    "            n_estimators=original_model.n_estimators + FINE_TUNE_PARAMS['n_estimators'],\n",
    "            max_depth=FINE_TUNE_PARAMS['max_depth'],\n",
    "            bootstrap=bootstrap_setting,  # 保持原始设置\n",
    "            max_samples=max_samples_setting,  # 只在启用bootstrap时设置\n",
    "            random_state=FINE_TUNE_PARAMS['random_state'],\n",
    "            n_jobs=FINE_TUNE_PARAMS['n_jobs']\n",
    "        )\n",
    "        \n",
    "        print(f\"    微调模型: 新增{FINE_TUNE_PARAMS['n_estimators']}棵树，使用{len(X_finetune)}个样本\")\n",
    "        new_model.fit(X_finetune, y_finetune)\n",
    "        \n",
    "        return new_model\n",
    "    \n",
    "    # 检查是否有足够的数据进行微调\n",
    "    finetune_samples = sum(len(data['X']) for data in finetune_data.values())\n",
    "    \n",
    "    if finetune_samples >= 20:  # 至少有20个样本才进行微调\n",
    "        print(\"\\n===== 应用迁移学习 (微调) =====\")\n",
    "        print(f\"  合并数据量: {finetune_samples}个样本\")\n",
    "        \n",
    "        # 合并所有数据集进行微调\n",
    "        X_finetune = pd.concat([data['X'] for data in finetune_data.values()])\n",
    "        y_finetune = pd.concat([data['y'] for data in finetune_data.values()])\n",
    "        \n",
    "        # 微调模型\n",
    "        finetuned_model = finetune_model(model, X_finetune, y_finetune)\n",
    "        \n",
    "        # 第四步：使用微调后的模型进行预测\n",
    "        print(\"\\n===== 使用微调模型预测 =====\")\n",
    "        for sheet, data in finetune_data.items():\n",
    "            X = data['X']\n",
    "            y = data['y']\n",
    "            \n",
    "            y_pred_finetuned = finetuned_model.predict(X)\n",
    "            \n",
    "            # 更新预测结果\n",
    "            predictions[sheet] = {\n",
    "                'actual': y,\n",
    "                'predicted': y_pred_finetuned,\n",
    "                'finetuned': True,  # 标记为微调模型预测\n",
    "                'source': sheet,\n",
    "                'row': data['X'].index,\n",
    "                'lat': df.loc[X.index, 'Latitude'] if 'Latitude' in df.columns else None,\n",
    "                'lon': df.loc[X.index, 'Longitude'] if 'Longitude' in df.columns else None,\n",
    "                'date': df.loc[X.index, 'Date'] if 'Date' in df.columns else None\n",
    "            }\n",
    "            \n",
    "            rmse = calculate_rmse(y, y_pred_finetuned)\n",
    "            rmse_diff = calculate_rmse(y, predictions[sheet].get('predicted_original', y_pred_finetuned)) - rmse\n",
    "            print(f\"  {sheet} 微调模型预测RMSE: {rmse:.4f} (改进: {rmse_diff:.4f})\")\n",
    "    else:\n",
    "        print(f\"  样本不足({finetune_samples}<20)，跳过迁移学习\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def create_scatter_plots(all_predictions):\n",
    "    \"\"\"\n",
    "    创建3x3散点子图，只显示微调模型结果\n",
    "    \"\"\"\n",
    "    print(\"创建散点图...\")\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('VWC预测结果（迁移学习模型）', fontsize=24, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            \n",
    "            # 获取当前组合的预测结果\n",
    "            predictions = all_predictions.get((band, pol), {})\n",
    "            \n",
    "            # 收集所有数据点\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            \n",
    "            # 绘制每个sheet的数据点（只显示微调模型结果）\n",
    "            for sheet in SHEET_NAMES:\n",
    "                if sheet in predictions and predictions[sheet]['finetuned']:\n",
    "                    data = predictions[sheet]\n",
    "                    actual = data['actual']\n",
    "                    predicted = data['predicted']\n",
    "                    \n",
    "                    # 添加到总集合\n",
    "                    all_actual.extend(actual)\n",
    "                    all_predicted.extend(predicted)\n",
    "                    \n",
    "                    # 获取该数据集的标记样式\n",
    "                    style = MARKER_STYLES[sheet]\n",
    "                    \n",
    "                    # 创建统一的标记参数\n",
    "                    scatter_params = {\n",
    "                        'marker': style['marker'],\n",
    "                        's': 60,  # 点大小\n",
    "                        'alpha': 0.8,\n",
    "                    }\n",
    "                    \n",
    "                    # 为特殊数据集设置空心点\n",
    "                    if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "                        scatter_params.update({\n",
    "                            'facecolor': 'none',\n",
    "                            'edgecolor': style.get('edgecolor', 'black')\n",
    "                        })\n",
    "                    else:\n",
    "                        scatter_params['color'] = style.get('color', 'black')\n",
    "                    \n",
    "                    # 绘制点\n",
    "                    ax.scatter(actual, predicted, **scatter_params)\n",
    "            \n",
    "            # 如果没有数据，跳过\n",
    "            if not all_actual:\n",
    "                ax.text(0.5, 0.5, '无数据', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=16)\n",
    "                ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse = calculate_rmse(np.array(all_actual), np.array(all_predicted))\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            max_val = max(max(all_actual), max(all_predicted)) * 1.05\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7)\n",
    "            \n",
    "            # 设置坐标轴范围\n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if i == 2:  # 最后一行\n",
    "                ax.set_xlabel('实测VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            if j == 0:  # 第一列\n",
    "                ax.set_ylabel('预测VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 添加标题和RMSE\n",
    "            ax.set_title(f\"{band}-{pol}波段\", fontsize=16, fontweight='bold')\n",
    "            ax.text(0.05, 0.95, f\"RMSE: {rmse:.3f} kg/m²\", \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=16,\n",
    "                    fontweight='bold',\n",
    "                    verticalalignment='top')\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 添加图例（只显示数据集）\n",
    "    handles = []\n",
    "    labels = []\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        style = MARKER_STYLES[sheet]\n",
    "        if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w',\n",
    "                                     markerfacecolor='none',\n",
    "                                     markeredgecolor=style.get('edgecolor', 'black'),\n",
    "                                     markersize=10,\n",
    "                                     markeredgewidth=1.0))\n",
    "        else:\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w', \n",
    "                                     markerfacecolor=style.get('color', 'black'),\n",
    "                                     markersize=10))\n",
    "        labels.append(sheet)\n",
    "    \n",
    "    fig.legend(handles, labels, \n",
    "               loc='lower center', \n",
    "               ncol=len(SHEET_NAMES), \n",
    "               fontsize=12,\n",
    "               frameon=True,\n",
    "               fancybox=True,\n",
    "               shadow=True,\n",
    "               bbox_to_anchor=(0.5, 0.02))\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    # 保存图像\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = \"figures/AllSMAPInsituData_VWC_Scatter_FT.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def calculate_rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    计算RMSE\n",
    "    \n",
    "    参数:\n",
    "    actual (array-like): 实际值\n",
    "    predicted (array-like): 预测值\n",
    "    \n",
    "    返回:\n",
    "    float: RMSE值\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "\n",
    "def save_prediction_details(all_predictions):\n",
    "    \"\"\"\n",
    "    将预测结果保存到Excel文件中\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_file = output_dir / \"details.xlsx\"\n",
    "    \n",
    "    # 创建Excel写入器\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # 遍历所有波段和极化组合\n",
    "        for (band, pol), predictions in all_predictions.items():\n",
    "            if not predictions:\n",
    "                continue\n",
    "                \n",
    "            # 创建当前组合的数据框\n",
    "            all_data = []\n",
    "            \n",
    "            # 收集所有sheet的数据\n",
    "            for sheet, data in predictions.items():\n",
    "                # 创建当前sheet的数据框\n",
    "                sheet_df = pd.DataFrame({\n",
    "                    'Date': data['date'],\n",
    "                    # 'Row': data['row'],\n",
    "                    # 'Col': data['col'],\n",
    "                    'Latitude': data['lat'],\n",
    "                    'Longitude': data['lon'],\n",
    "                    'Actual_VWC': data['actual'],\n",
    "                    'Predicted_VWC': data['predicted'],\n",
    "                    'Source': data['source']\n",
    "                })\n",
    "                \n",
    "                # 添加波段和极化信息\n",
    "                sheet_df['Band'] = band\n",
    "                sheet_df['Polarization'] = pol\n",
    "                \n",
    "                all_data.append(sheet_df)\n",
    "            \n",
    "            # 合并所有数据\n",
    "            if all_data:\n",
    "                combined_df = pd.concat(all_data, ignore_index=True)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                sheet_name = f\"{band}_{pol}\"\n",
    "                combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                print(f\"保存预测结果到: {sheet_name} ({len(combined_df)}行)\")\n",
    "    \n",
    "    print(f\"所有预测结果已保存至: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\"\n",
    "    \n",
    "    # 加载并预处理数据\n",
    "    data_dict = load_and_preprocess_data(input_file)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            print(f\"\\n处理波段-极化组合: {band}-{pol}\")\n",
    "            predictions = predict_vwc(data_dict, band, pol)\n",
    "            all_predictions[(band, pol)] = predictions\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots(all_predictions)\n",
    "    \n",
    "    # 保存预测结果到Excel\n",
    "    save_prediction_details(all_predictions)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3588ed84-de99-4756-80a5-9b17029dcfdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\n",
      "  - SMEX02: 16 rows\n",
      "    Replaced 14 rows of SM_Satellite data\n",
      "  - CLASIC07: 18 rows\n",
      "  - SMAPVEX08: 6 rows\n",
      "    Replaced 6 rows of LAI_Satellite data\n",
      "  - SMAPVEX16: 115 rows\n",
      "\n",
      "Plotting feature distributions...\n",
      "Feature distributions plot saved to: figures\\Dataset_Feature_Distributions.png\n",
      "\n",
      "Plotting feature statistics...\n",
      "Feature statistics plot saved to: figures\\Dataset_Feature_Statistics.png\n",
      "\n",
      "Plotting feature correlations...\n",
      "Feature correlations plot saved to: figures\\Dataset_Feature_Correlations.png\n",
      "\n",
      "分析完成!\n"
     ]
    }
   ],
   "source": [
    "# 绘制上述4个数据集所填充自变量的情况\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 设置全局样式\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "SHEET_NAMES = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "VWC_COLUMNS = {\n",
    "    'SMEX02': 'VWC-Field',\n",
    "    'CLASIC07': 'VWC (kg/m²)',\n",
    "    'SMAPVEX08': 'VWC',\n",
    "    'SMAPVEX16': 'PLANT_WATER_CONTENT_AREA'\n",
    "}\n",
    "\n",
    "# 颜色设置\n",
    "DATASET_COLORS = {\n",
    "    'SMEX02': '#F8766D',\n",
    "    'CLASIC07': '#00BFC4',\n",
    "    'SMAPVEX08': '#C77CFF',\n",
    "    'SMAPVEX16': '#7CAE00'\n",
    "}\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess all sheets in Excel file\n",
    "    \"\"\"\n",
    "    print(f\"Loading file: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)} rows\")\n",
    "            \n",
    "            # Replace SM_Satellite and LAI_Satellite if ground measurements exist\n",
    "            if 'SM' in df.columns:\n",
    "                mask = df['SM'].notna()\n",
    "                df.loc[mask, 'SM_Satellite'] = df.loc[mask, 'SM']\n",
    "                print(f\"    Replaced {mask.sum()} rows of SM_Satellite data\")\n",
    "            \n",
    "            if 'LAI' in df.columns:\n",
    "                mask = df['LAI'].notna()\n",
    "                df.loc[mask, 'LAI_Satellite'] = df.loc[mask, 'LAI']\n",
    "                print(f\"    Replaced {mask.sum()} rows of LAI_Satellite data\")\n",
    "            \n",
    "            # Merge PFT variables\n",
    "            grass_cols = [col for col in df.columns if 'grass' in col.lower()]\n",
    "            shrub_cols = [col for col in df.columns if 'shrub' in col.lower()]\n",
    "            tree_cols = [col for col in df.columns if 'tree' in col.lower()]\n",
    "            \n",
    "            if grass_cols:\n",
    "                df['grass'] = df[grass_cols].sum(axis=1)\n",
    "            if shrub_cols:\n",
    "                df['shrub'] = df[shrub_cols].sum(axis=1)\n",
    "            if tree_cols:\n",
    "                df['tree'] = df[tree_cols].sum(axis=1)\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {sheet}: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def plot_feature_distributions(data_dict):\n",
    "    \"\"\"\n",
    "    Plot distributions of features across datasets\n",
    "    \"\"\"\n",
    "    print(\"\\nPlotting feature distributions...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Key features list - using merged PFT variables\n",
    "    key_features = [\n",
    "        'LAI_Satellite', \n",
    "        'SM_Satellite',\n",
    "        'grass',       # Merged grass fraction\n",
    "        'shrub',       # Merged shrub fraction\n",
    "        'tree',        # Merged tree fraction\n",
    "        'ku_vod_H',    # Ku-band H-pol VOD\n",
    "        'x_vod_H',     # X-band H-pol VOD\n",
    "        'c_vod_H',     # C-band H-pol VOD\n",
    "        'VWC_Measured' # Measured VWC\n",
    "    ]\n",
    "    \n",
    "    # Create figure - 3x3 grid\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Create subplot for each feature\n",
    "    for i, feature in enumerate(key_features):\n",
    "        if i >= len(axes):  # Prevent index out of range\n",
    "            break\n",
    "            \n",
    "        ax = axes[i]\n",
    "        all_data = []\n",
    "        \n",
    "        # Collect data from all datasets\n",
    "        for sheet in SHEET_NAMES:\n",
    "            if sheet in data_dict:\n",
    "                df = data_dict[sheet]\n",
    "                \n",
    "                # Special handling for measured VWC\n",
    "                if feature == 'VWC_Measured':\n",
    "                    vwc_col = VWC_COLUMNS.get(sheet)\n",
    "                    if vwc_col and vwc_col in df.columns:\n",
    "                        values = df[vwc_col].dropna()\n",
    "                        if not values.empty:\n",
    "                            temp_df = pd.DataFrame({\n",
    "                                'Value': values,\n",
    "                                'Dataset': sheet\n",
    "                            })\n",
    "                            all_data.append(temp_df)\n",
    "                else:\n",
    "                    if feature in df.columns:\n",
    "                        values = df[feature].dropna()\n",
    "                        if not values.empty:\n",
    "                            temp_df = pd.DataFrame({\n",
    "                                'Value': values,\n",
    "                                'Dataset': sheet\n",
    "                            })\n",
    "                            all_data.append(temp_df)\n",
    "        \n",
    "        if not all_data:\n",
    "            ax.text(0.5, 0.5, 'No data', \n",
    "                    horizontalalignment='center', \n",
    "                    verticalalignment='center', \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=12)\n",
    "            ax.set_title(feature, fontsize=14)\n",
    "            continue\n",
    "        \n",
    "        # Combine all data\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Plot violin plot\n",
    "        sns.violinplot(\n",
    "            x='Dataset', \n",
    "            y='Value', \n",
    "            data=combined_df,\n",
    "            ax=ax,\n",
    "            palette=DATASET_COLORS,\n",
    "            inner=\"quartile\",  # Show quartiles\n",
    "            cut=0  # Limit to data range\n",
    "        )\n",
    "        \n",
    "        # Add data points\n",
    "        sns.stripplot(\n",
    "            x='Dataset', \n",
    "            y='Value', \n",
    "            data=combined_df,\n",
    "            ax=ax,\n",
    "            color='black',\n",
    "            alpha=0.3,\n",
    "            jitter=True\n",
    "        )\n",
    "        \n",
    "        # Set titles and labels\n",
    "        if feature == 'VWC_Measured':\n",
    "            ax.set_title('Measured VWC', fontsize=14, fontweight='bold')\n",
    "            ax.set_ylabel('VWC (kg/m²)')\n",
    "        else:\n",
    "            ax.set_title(feature, fontsize=14, fontweight='bold')\n",
    "            ax.set_ylabel('Value')\n",
    "        \n",
    "        ax.set_xlabel('Dataset')\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # Hide last empty subplot (9th)\n",
    "    if len(key_features) < len(axes):\n",
    "        axes[len(key_features)].axis('off')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add main title\n",
    "    fig.suptitle('Feature Distributions Across Datasets', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = output_dir / \"Dataset_Feature_Distributions.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Feature distributions plot saved to: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_statistics(data_dict):\n",
    "    \"\"\"\n",
    "    Plot feature statistics comparison\n",
    "    \"\"\"\n",
    "    print(\"\\nPlotting feature statistics...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Key features list - using merged PFT variables\n",
    "    key_features = [\n",
    "        'LAI_Satellite', \n",
    "        'SM_Satellite',\n",
    "        'grass',       # Merged grass fraction\n",
    "        'shrub',       # Merged shrub fraction\n",
    "        'tree',        # Merged tree fraction\n",
    "        'ku_vod_H',    # Ku-band H-pol VOD\n",
    "        'x_vod_H',     # X-band H-pol VOD\n",
    "        'c_vod_H'      # C-band H-pol VOD\n",
    "    ]\n",
    "    \n",
    "    # Collect statistics\n",
    "    stats_data = []\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        if sheet in data_dict:\n",
    "            df = data_dict[sheet]\n",
    "            for feature in key_features:\n",
    "                if feature in df.columns:\n",
    "                    values = df[feature].dropna()\n",
    "                    if not values.empty:\n",
    "                        stats_data.append({\n",
    "                            'Dataset': sheet,\n",
    "                            'Feature': feature,\n",
    "                            'Mean': values.mean(),\n",
    "                            'Median': values.median(),\n",
    "                            'StdDev': values.std(),\n",
    "                            'Min': values.min(),\n",
    "                            'Max': values.max()\n",
    "                        })\n",
    "    \n",
    "    if not stats_data:\n",
    "        print(\"No valid statistics data\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # 1. Mean comparison\n",
    "    ax = axes[0]\n",
    "    sns.barplot(\n",
    "        x='Feature', \n",
    "        y='Mean', \n",
    "        hue='Dataset', \n",
    "        data=stats_df, \n",
    "        ax=ax,\n",
    "        palette=DATASET_COLORS\n",
    "    )\n",
    "    ax.set_title('Feature Mean Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Mean Value')\n",
    "    ax.legend(title='Dataset')\n",
    "    \n",
    "    # 2. Standard deviation comparison\n",
    "    ax = axes[1]\n",
    "    sns.barplot(\n",
    "        x='Feature', \n",
    "        y='StdDev', \n",
    "        hue='Dataset', \n",
    "        data=stats_df, \n",
    "        ax=ax,\n",
    "        palette=DATASET_COLORS\n",
    "    )\n",
    "    ax.set_title('Feature Standard Deviation Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Standard Deviation')\n",
    "    ax.legend(title='Dataset')\n",
    "    \n",
    "    # 3. Range comparison (Max - Min)\n",
    "    stats_df['Range'] = stats_df['Max'] - stats_df['Min']\n",
    "    ax = axes[2]\n",
    "    sns.barplot(\n",
    "        x='Feature', \n",
    "        y='Range', \n",
    "        hue='Dataset', \n",
    "        data=stats_df, \n",
    "        ax=ax,\n",
    "        palette=DATASET_COLORS\n",
    "    )\n",
    "    ax.set_title('Feature Range Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Range (Max - Min)')\n",
    "    ax.legend(title='Dataset')\n",
    "    \n",
    "    # 4. Median comparison\n",
    "    ax = axes[3]\n",
    "    sns.barplot(\n",
    "        x='Feature', \n",
    "        y='Median', \n",
    "        hue='Dataset', \n",
    "        data=stats_df, \n",
    "        ax=ax,\n",
    "        palette=DATASET_COLORS\n",
    "    )\n",
    "    ax.set_title('Feature Median Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Median Value')\n",
    "    ax.legend(title='Dataset')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add main title\n",
    "    fig.suptitle('Feature Statistics Comparison Across Datasets', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = output_dir / \"Dataset_Feature_Statistics.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Feature statistics plot saved to: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_correlations(data_dict):\n",
    "    \"\"\"\n",
    "    Plot feature correlation heatmaps\n",
    "    \"\"\"\n",
    "    print(\"\\nPlotting feature correlations...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Key features list - using merged PFT variables\n",
    "    key_features = [\n",
    "        'LAI_Satellite', \n",
    "        'SM_Satellite',\n",
    "        'grass',       # Merged grass fraction\n",
    "        'shrub',       # Merged shrub fraction\n",
    "        'tree',        # Merged tree fraction\n",
    "        'ku_vod_H',    # Ku-band H-pol VOD\n",
    "        'x_vod_H',     # X-band H-pol VOD\n",
    "        'c_vod_H'      # C-band H-pol VOD\n",
    "    ]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, sheet in enumerate(SHEET_NAMES):\n",
    "        if i >= len(axes):  # Prevent index out of range\n",
    "            break\n",
    "            \n",
    "        if sheet in data_dict:\n",
    "            df = data_dict[sheet]\n",
    "            \n",
    "            # Select features\n",
    "            features = [f for f in key_features if f in df.columns]\n",
    "            \n",
    "            if len(features) < 2:  # Need at least 2 features for correlation\n",
    "                ax = axes[i]\n",
    "                ax.text(0.5, 0.5, 'Insufficient features', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=12)\n",
    "                ax.set_title(sheet, fontsize=14)\n",
    "                continue\n",
    "            \n",
    "            # Calculate correlation matrix\n",
    "            corr = df[features].corr()\n",
    "            \n",
    "            # Plot heatmap\n",
    "            ax = axes[i]\n",
    "            sns.heatmap(\n",
    "                corr, \n",
    "                annot=True, \n",
    "                fmt=\".2f\", \n",
    "                cmap=\"coolwarm\", \n",
    "                vmin=-1, \n",
    "                vmax=1, \n",
    "                ax=ax,\n",
    "                cbar_kws={\"shrink\": 0.7}\n",
    "            )\n",
    "            ax.set_title(f'{sheet} - Feature Correlations', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add main title\n",
    "    fig.suptitle('Feature Correlations Across Datasets', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = output_dir / \"Dataset_Feature_Correlations.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Feature correlations plot saved to: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\"\n",
    "    \n",
    "    # 加载并预处理数据\n",
    "    data_dict = load_and_preprocess_data(input_file)\n",
    "    \n",
    "    # 绘制自变量分布图\n",
    "    plot_feature_distributions(data_dict)\n",
    "    \n",
    "    # 绘制特征统计量对比图\n",
    "    plot_feature_statistics(data_dict)\n",
    "    \n",
    "    # 绘制特征相关性热图\n",
    "    plot_feature_correlations(data_dict)\n",
    "    \n",
    "    print(\"\\n分析完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1bafc-d6a9-4d13-a186-5eeef569e389",
   "metadata": {},
   "source": [
    "# .VWC-Sites（多频多角度数据）----2017\\2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d2167b-7885-4e1d-a60d-bd0943075619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将处理以下工作表: CornVegMeasured, CornVegFitting, OatVegMeasured, OatVegFitting\n",
      "处理 2017: CornVegMeasured\n",
      "警告: CornVegMeasured 中删除了 5 行包含空值的行\n",
      "处理 2017: CornVegFitting\n",
      "处理 2017: OatVegMeasured\n",
      "处理 2017: OatVegFitting\n",
      "2017年数据处理完成，保存至: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\n",
      "将处理以下工作表: GrassVWC\n",
      "处理 2018: GrassVWC\n",
      "2018年数据处理完成，保存至: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 多频多角度数据填充\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import openpyxl\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def latlon_to_rowcol(lat, lon):\n",
    "    \"\"\"将经纬度转换为0.1°栅格的行列号\"\"\"\n",
    "    row = int((89.95 - lat) / 0.1)\n",
    "    col = int((lon + 179.95) / 0.1)\n",
    "    return row, col\n",
    "\n",
    "def get_nearest_lai_files(date):\n",
    "    \"\"\"获取指定日期前后两个月的LAI文件路径（精确到每月15日）\"\"\"\n",
    "    # 获取当前日期所在月份的前一个月15日\n",
    "    prev_month_15 = (date.replace(day=1) - timedelta(days=1)).replace(day=15)\n",
    "    \n",
    "    # 获取当前日期所在月份的下一个月15日\n",
    "    next_month_15 = (date.replace(day=28) + timedelta(days=4)).replace(day=15)\n",
    "    \n",
    "    # 构建文件路径\n",
    "    prev_file = Path(f\"E:/data/GLASS LAI/mat/0.1Deg/Dataset/{prev_month_15.strftime('%Y-%m')}-01.tif.mat\")\n",
    "    next_file = Path(f\"E:/data/GLASS LAI/mat/0.1Deg/Dataset/{next_month_15.strftime('%Y-%m')}-01.tif.mat\")\n",
    "    \n",
    "    return prev_file, next_file, prev_month_15, next_month_15\n",
    "\n",
    "def read_mat_v73(file_path, variable_names):\n",
    "    \"\"\"\n",
    "    读取 v7.3 格式的 .mat 文件\n",
    "    返回字典：{变量名: 矩阵数据}\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            for var in variable_names:\n",
    "                if var in f:\n",
    "                    dataset = f[var]\n",
    "                    # 读取数据（不自动转置）\n",
    "                    matrix = dataset[()]\n",
    "                    \n",
    "                    # 确保数据是二维数组\n",
    "                    if len(matrix.shape) == 2:\n",
    "                        # 检查形状是否匹配全局常量（1800×3600）\n",
    "                        if matrix.shape == (1800, 3600):\n",
    "                            data[var] = matrix\n",
    "                        elif matrix.shape == (3600, 1800):\n",
    "                            # 如果是转置的形状，则手动转置\n",
    "                            data[var] = matrix.T\n",
    "                        else:\n",
    "                            # 尝试重塑为正确形状\n",
    "                            try:\n",
    "                                data[var] = matrix.reshape(1800, 3600)\n",
    "                            except:\n",
    "                                data[var] = np.full((1800, 3600), np.nan)\n",
    "                    else:\n",
    "                        data[var] = np.full((1800, 3600), np.nan)\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 读取文件 {file_path} 时出错: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_sheet(df, sheet_name, lat, lon, year):\n",
    "    \"\"\"处理单个sheet的数据\"\"\"\n",
    "    # 计算固定位置的栅格行列号\n",
    "    row, col = latlon_to_rowcol(lat, lon)\n",
    "    \n",
    "    # 添加位置信息\n",
    "    df['Latitude'] = lat\n",
    "    df['Longitude'] = lon\n",
    "    df['row'] = row\n",
    "    df['col'] = col\n",
    "    \n",
    "    # 创建日期列 - 使用英文列名\n",
    "    # 检查并删除有空值的行\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=['Year', 'Month', 'Day'])\n",
    "    removed_count = initial_count - len(df)\n",
    "    if removed_count > 0:\n",
    "        print(f\"警告: {sheet_name} 中删除了 {removed_count} 行包含空值的行\")\n",
    "    \n",
    "    # 转换为整数\n",
    "    df[['Year', 'Month', 'Day']] = df[['Year', 'Month', 'Day']].astype(int)\n",
    "    \n",
    "    # 创建日期列\n",
    "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "    \n",
    "    # 准备新列\n",
    "    vod_columns = ['SM', 'ku_vod_H', 'ku_vod_V', 'x_vod_H', 'x_vod_V', 'c_vod_H', 'c_vod_V']\n",
    "    pft_columns = ['water', 'bare', 'snowice', 'built', 'grassnat', 'grassman', \n",
    "                   'shrubbd', 'shrubbe', 'shrubnd', 'shrubne', 'treebd', 'treebe', 'treend', 'treene']\n",
    "    lai_column = 'lai'  # LAI变量名\n",
    "    \n",
    "    for col_name in vod_columns + pft_columns + ['LAI_Satellite', 'Hveg_Satellite']:\n",
    "        df[col_name] = np.nan\n",
    "    \n",
    "    # 加载PFT数据 (一次性加载全年的)\n",
    "    pft_file = Path(f\"E:/data/ESACCI PFT/Resample/Data/{year}.mat\")\n",
    "    if pft_file.exists():\n",
    "        pft_data = read_mat_v73(pft_file, pft_columns)\n",
    "        if pft_data:\n",
    "            for pft_col in pft_columns:\n",
    "                if pft_col in pft_data:\n",
    "                    try:\n",
    "                        # 直接使用行列索引（不再使用位置索引）\n",
    "                        df[pft_col] = pft_data[pft_col][row, col]\n",
    "                    except Exception as e:\n",
    "                        print(f\"处理PFT数据时出错: {str(e)}\")\n",
    "    \n",
    "    # 加载Hveg数据 (不随时间变化)\n",
    "    hveg_file = Path(\"E:/data/CanopyHeight/CH.mat\")\n",
    "    if hveg_file.exists():\n",
    "        ch_data = read_mat_v73(hveg_file, ['Hveg'])\n",
    "        if ch_data and 'Hveg' in ch_data:\n",
    "            try:\n",
    "                # 直接使用行列索引\n",
    "                df['Hveg_Satellite'] = ch_data['Hveg'][row, col]\n",
    "            except Exception as e:\n",
    "                print(f\"处理Hveg数据时出错: {str(e)}\")\n",
    "    \n",
    "    # 逐行处理VOD和LAI数据\n",
    "    for idx, row_data in df.iterrows():\n",
    "        date_str = row_data['Date'].strftime('%Y%m%d')\n",
    "        year_int = row_data['Date'].year\n",
    "        \n",
    "        # 确定VOD文件路径\n",
    "        if year_int <= 2012:\n",
    "            vod_file = Path(f\"E:/data/VOD/mat/kuxcVOD/ASC/MCCA_AMSRE_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "        else:\n",
    "            vod_file = Path(f\"E:/data/VOD/mat/kuxcVOD/ASC/MCCA_AMSR2_010D_CCXH_VSM_VOD_Asc_{date_str}_V0.nc4.mat\")\n",
    "        \n",
    "        # 加载VOD数据\n",
    "        if vod_file.exists():\n",
    "            try:\n",
    "                vod_data = read_mat_v73(vod_file, vod_columns)\n",
    "                if vod_data:\n",
    "                    for var in vod_columns:\n",
    "                        if var in vod_data:\n",
    "                            try:\n",
    "                                # 获取特定位置的数值\n",
    "                                value = vod_data[var][row, col]\n",
    "                                if not np.isnan(value):\n",
    "                                    if var == 'SM':\n",
    "                                        df.at[idx, 'SM_Satellite'] = value\n",
    "                                    else:\n",
    "                                        df.at[idx, var] = value\n",
    "                            except:\n",
    "                                print(f\"提取VOD数据时出错 (文件: {vod_file}, 变量: {var})\")\n",
    "            except Exception as e:\n",
    "                print(f\"加载VOD文件 {vod_file} 时出错: {str(e)}\")\n",
    "        \n",
    "        # 处理LAI数据（插值）\n",
    "        prev_file, next_file, prev_date, next_date = get_nearest_lai_files(row_data['Date'])\n",
    "        if prev_file.exists() and next_file.exists():\n",
    "            try:\n",
    "                # 读取前一个月数据\n",
    "                prev_data = read_mat_v73(prev_file, [lai_column])\n",
    "                prev_lai = prev_data[lai_column][row, col] if prev_data and lai_column in prev_data else np.nan\n",
    "                \n",
    "                # 读取后一个月数据\n",
    "                next_data = read_mat_v73(next_file, [lai_column])\n",
    "                next_lai = next_data[lai_column][row, col] if next_data and lai_column in next_data else np.nan\n",
    "                \n",
    "                # 计算日期差（精确到天）\n",
    "                total_days = (next_date - prev_date).days\n",
    "                current_days = (row_data['Date'] - prev_date).days\n",
    "                \n",
    "                # 线性插值\n",
    "                if total_days > 0 and 0 <= current_days <= total_days:\n",
    "                    weight = current_days / total_days\n",
    "                    df.at[idx, 'LAI_Satellite'] = (1 - weight) * prev_lai + weight * next_lai\n",
    "                else:\n",
    "                    # 如果日期超出范围，使用最近的一个值\n",
    "                    if current_days < 0:\n",
    "                        df.at[idx, 'LAI_Satellite'] = prev_lai\n",
    "                    else:\n",
    "                        df.at[idx, 'LAI_Satellite'] = next_lai\n",
    "            except Exception as e:\n",
    "                print(f\"处理LAI插值失败，日期 {date_str}: {str(e)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_2017_data():\n",
    "    \"\"\"处理2017年的数据\"\"\"\n",
    "    file_path = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg.xlsx\"\n",
    "    save_path = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\"\n",
    "    \n",
    "    # 创建保存目录\n",
    "    save_dir = Path(save_path).parent\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 多伦位置 - 东经116.47，北纬42.18\n",
    "    lat = 42.18\n",
    "    lon = 116.47\n",
    "    \n",
    "    # 获取所有sheet名称\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    all_sheets = xl.sheet_names\n",
    "    \n",
    "    # 排除BuckwheatMeasured\n",
    "    sheets_to_process = [sheet for sheet in all_sheets if \"BuckwheatMeasured\" not in sheet]\n",
    "    \n",
    "    print(f\"将处理以下工作表: {', '.join(sheets_to_process)}\")\n",
    "    \n",
    "    # 创建一个新的Excel文件\n",
    "    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:\n",
    "        # 添加一个空的工作表作为占位符（避免\"没有可见工作表\"错误）\n",
    "        pd.DataFrame().to_excel(writer, sheet_name='Placeholder', index=False)\n",
    "        \n",
    "        for sheet_name in sheets_to_process:\n",
    "            try:\n",
    "                # 跳过首行标题（中文列名）\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1)\n",
    "                \n",
    "                # 处理数据\n",
    "                print(f\"处理 2017: {sheet_name}\")\n",
    "                df_processed = process_sheet(df, sheet_name, lat, lon, year=2017)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                df_processed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"处理工作表 {sheet_name} 时出错: {str(e)}\")\n",
    "    \n",
    "    # 删除占位符工作表\n",
    "    wb = openpyxl.load_workbook(save_path)\n",
    "    if 'Placeholder' in wb.sheetnames:\n",
    "        del wb['Placeholder']\n",
    "    wb.save(save_path)\n",
    "    \n",
    "    print(f\"2017年数据处理完成，保存至: {save_path}\")\n",
    "\n",
    "def process_2018_data():\n",
    "    \"\"\"处理2018年的数据\"\"\"\n",
    "    file_path = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC.xlsx\"\n",
    "    save_path = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\"\n",
    "    \n",
    "    # 正蓝旗位置 - 东经115.93，北纬42.04\n",
    "    lat = 42.04\n",
    "    lon = 115.93\n",
    "    \n",
    "    # 获取所有sheet名称\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    all_sheets = xl.sheet_names\n",
    "    \n",
    "    # 2018年只有一个名为GrassVWC的工作表\n",
    "    sheets_to_process = [sheet for sheet in all_sheets if \"GrassVWC\" in sheet]\n",
    "    \n",
    "    if not sheets_to_process:\n",
    "        print(f\"警告: 在 {file_path} 中未找到名为 'GrassVWC' 的工作表\")\n",
    "        sheets_to_process = all_sheets  # 尝试处理所有工作表\n",
    "    \n",
    "    print(f\"将处理以下工作表: {', '.join(sheets_to_process)}\")\n",
    "    \n",
    "    # 创建一个新的Excel文件\n",
    "    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:\n",
    "        # 添加一个空的工作表作为占位符（避免\"没有可见工作表\"错误）\n",
    "        pd.DataFrame().to_excel(writer, sheet_name='Placeholder', index=False)\n",
    "        \n",
    "        for sheet_name in sheets_to_process:\n",
    "            try:\n",
    "                # 跳过首行标题（中文列名）\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1)\n",
    "                \n",
    "                # 处理数据\n",
    "                print(f\"处理 2018: {sheet_name}\")\n",
    "                df_processed = process_sheet(df, sheet_name, lat, lon, year=2018)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                df_processed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"处理工作表 {sheet_name} 时出错: {str(e)}\")\n",
    "    \n",
    "    # 删除占位符工作表\n",
    "    wb = openpyxl.load_workbook(save_path)\n",
    "    if 'Placeholder' in wb.sheetnames:\n",
    "        del wb['Placeholder']\n",
    "    wb.save(save_path)\n",
    "    \n",
    "    print(f\"2018年数据处理完成，保存至: {save_path}\")\n",
    "\n",
    "def main():\n",
    "    # 处理2017年数据\n",
    "    process_2017_data()\n",
    "    \n",
    "    # 处理2018年数据\n",
    "    process_2018_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2243da27-9911-4919-a111-8dc460d7ff36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\n",
      "  - CornVegMeasured: 8行\n",
      "  - CornVegFitting: 64行\n",
      "  - OatVegMeasured: 7行\n",
      "  - OatVegFitting: 64行\n",
      "加载文件: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\n",
      "  - GrassVWC: 13行\n",
      "创建组合时间序列图...\n",
      "为 CornVegFitting 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Type1.pkl\n",
      "  模型期望特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "组合时间序列图已保存至: figures\\Combined_VWC_Time_Series.png\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_HV_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_H_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_V_predictions.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_HV_predictions.csv\n",
      "保存模型评估指标至: prediction_results\\model_metrics.csv\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.interpolate import make_interp_spline  # 导入样条插值函数\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "BAND_COLORS = {\n",
    "    'Ku': '#1f77b4',  # 蓝色\n",
    "    'X': '#ff7f0e',   # 橙色\n",
    "    'C': '#2ca02c'    # 绿色\n",
    "}\n",
    "POLS = ['H', 'V', 'HV']\n",
    "POL_LINESTYLES = {\n",
    "    'H': '-',     # 实线\n",
    "    'V': '--',    # 虚线\n",
    "    'HV': ':'     # 点线\n",
    "}\n",
    "POL_MARKERS = {\n",
    "    'H': '+',  # 加号\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 's'  # 正方形\n",
    "}\n",
    "POL_LABELS = {\n",
    "    'H': 'H-Pol',\n",
    "    'V': 'V-Pol',\n",
    "    'HV': 'H&V-Pol'  # 修改这里\n",
    "}\n",
    "\n",
    "# 植被类型映射\n",
    "VEGETATION_TYPES = {\n",
    "    'CornVegMeasured': 'Corn (2017)',\n",
    "    'OatVegMeasured': 'Oat (2017)',\n",
    "    'GrassVWC': 'Grass (2018)'\n",
    "}\n",
    "\n",
    "# 实测与拟合数据映射\n",
    "FITTING_MAPPING = {\n",
    "    'CornVegMeasured': 'CornVegFitting',\n",
    "    'OatVegMeasured': 'OatVegFitting',\n",
    "    'GrassVWC': 'GrassVWC'  # 2018年没有拟合数据\n",
    "}\n",
    "\n",
    "# 实测VWC列名映射\n",
    "ACTUAL_COL_MAPPING = {\n",
    "    'CornVegMeasured': 'total_VWC(kg/m2)',\n",
    "    'OatVegMeasured': 'total_VWC(kg/m2)',\n",
    "    'GrassVWC': 'vegetation water content(kg/m2)'\n",
    "}\n",
    "\n",
    "# 实测数据样式\n",
    "ACTUAL_STYLE = {\n",
    "    'color': 'black',\n",
    "    'marker': 'o',\n",
    "    'markersize': 8,\n",
    "    'markerfacecolor': 'none',\n",
    "    'markeredgewidth': 1.5,\n",
    "    'label': 'Measured'\n",
    "}\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"加载Excel文件中的所有工作表\"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    # 获取所有工作表名称\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    sheet_names = xl.sheet_names\n",
    "    \n",
    "    for sheet in sheet_names:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 确保日期是datetime类型\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def predict_vwc_for_sheet(df, band, pol):\n",
    "    \"\"\"\n",
    "    使用机器学习模型预测VWC，确保特征名称匹配\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model_path = f\"models/RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"警告: 模型文件不存在: {model_path}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"加载模型: {model_path}\")\n",
    "        \n",
    "        # 获取模型期望的特征名称\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            expected_features = list(model.feature_names_in_)\n",
    "            print(f\"  模型期望特征: {expected_features}\")\n",
    "        else:\n",
    "            print(\"  警告: 模型没有feature_names_in_属性\")\n",
    "            expected_features = []\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型失败: {str(e)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 1. 优先使用地面实测数据替换卫星数据\n",
    "    if 'SM' in df.columns:\n",
    "        sm_mask = df['SM'].notna() & (df['SM'] > 0)\n",
    "        if sm_mask.any():\n",
    "            df.loc[sm_mask, 'SM_Satellite'] = df.loc[sm_mask, 'SM']\n",
    "            print(f\"  使用实测SM替换了 {sm_mask.sum()} 行数据\")\n",
    "    \n",
    "    if 'LAI' in df.columns:\n",
    "        lai_mask = df['LAI'].notna() & (df['LAI'] > 0)\n",
    "        if lai_mask.any():\n",
    "            df.loc[lai_mask, 'LAI_Satellite'] = df.loc[lai_mask, 'LAI']\n",
    "            print(f\"  使用实测LAI替换了 {lai_mask.sum()} 行数据\")\n",
    "    \n",
    "    # 2. 根据波段和极化组合确定特征映射\n",
    "    feature_mapping = {}\n",
    "    \n",
    "    # Ku波段\n",
    "    if band == 'Ku':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_H': 'VOD-Hpol',\n",
    "                'ku_vod_V': 'VOD-Vpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # X波段\n",
    "    elif band == 'X':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'x_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'x_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'x_vod_H': 'VOD-Hpol',\n",
    "                'x_vod_V': 'VOD-Vpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # C波段\n",
    "    elif band == 'C':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'c_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'c_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'c_vod_H': 'VOD-Hpol',\n",
    "                'c_vod_V': 'VOD-Vpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # 时间序列插值\n",
    "    if 'Date' in df.columns and not df.empty:\n",
    "        # 确保按日期排序\n",
    "        df = df.sort_values('Date')\n",
    "        \n",
    "        # 确定需要插值的特征列\n",
    "        interpolate_cols = list(feature_mapping.keys())\n",
    "        valid_cols = [col for col in interpolate_cols if col in df.columns]\n",
    "        \n",
    "        # 设置时间索引\n",
    "        date_index = pd.DatetimeIndex(df['Date'])\n",
    "        df_temp = df.set_index('Date')\n",
    "        \n",
    "        # 生成完整的时间序列范围\n",
    "        full_range = pd.date_range(start=date_index.min(), end=date_index.max(), freq='D')\n",
    "        df_full = df_temp.reindex(full_range)\n",
    "        \n",
    "        # 对特征列进行线性插值\n",
    "        for col in valid_cols:\n",
    "            df_full[col] = df_full[col].interpolate(method='time', limit_direction='both')\n",
    "            print(f\"  已完成{col}的时间序列插值\")\n",
    "        \n",
    "        # 重置索引\n",
    "        df = df_full.reset_index().rename(columns={'index': 'Date'})\n",
    "    else:\n",
    "        print(\"  无日期列或数据为空，跳过插值\")\n",
    "    \n",
    "    # 3. 检查是否所有映射后的特征都存在\n",
    "    missing_features = []\n",
    "    for data_col in feature_mapping.keys():\n",
    "        if data_col not in df.columns:\n",
    "            missing_features.append(data_col)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"  缺少特征: {', '.join(missing_features)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 4. 准备特征数据\n",
    "    X = pd.DataFrame()\n",
    "    for data_col, model_feature in feature_mapping.items():\n",
    "        X[model_feature] = df[data_col]\n",
    "    \n",
    "    # 5. 应用特征归一化\n",
    "    # VOD特征归一化（除以2）\n",
    "    vod_features = ['VOD', 'VOD-Hpol', 'VOD-Vpol']\n",
    "    for vod_feature in vod_features:\n",
    "        if vod_feature in X.columns:\n",
    "            X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "    \n",
    "    # LAI特征归一化（除以6）\n",
    "    if 'LAI' in X.columns:\n",
    "        X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "    \n",
    "    # PFT特征归一化（除以100）\n",
    "    pft_features = [\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    for pft_feature in pft_features:\n",
    "        if pft_feature in X.columns:\n",
    "            X[pft_feature] = X[pft_feature] / 100.0\n",
    "    \n",
    "    # 6. 移除缺失值\n",
    "    initial_count = len(X)\n",
    "    X = X.dropna()\n",
    "    removed_count = initial_count - len(X)\n",
    "    if removed_count > 0:\n",
    "        print(f\"  移除了 {removed_count} 行包含缺失值的数据\")\n",
    "    \n",
    "    if X.empty:\n",
    "        print(\"  无有效数据可用于预测\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 7. 确保特征顺序与模型期望一致\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        X = X[expected_features]\n",
    "    \n",
    "    # 8. 预测VWC\n",
    "    try:\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        # 创建完整长度的预测序列\n",
    "        full_pred = pd.Series(np.nan, index=df.index)\n",
    "        full_pred.loc[X.index] = y_pred\n",
    "        \n",
    "        return full_pred\n",
    "    except Exception as e:\n",
    "        print(f\"  预测失败: {str(e)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "\n",
    "def create_combined_plots(data_dict_2017, data_dict_2018):\n",
    "    \"\"\"创建组合时间序列图并保存预测结果\"\"\"\n",
    "    print(\"创建组合时间序列图...\")\n",
    "    \n",
    "    # 创建输出目录\n",
    "    output_dir = Path(\"prediction_results\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 创建图形 - 增加底部空间用于多行图例\n",
    "    fig = plt.figure(figsize=(15, 18))\n",
    "    gs = gridspec.GridSpec(4, 1, figure=fig, height_ratios=[1, 1, 1, 0.4], hspace=0.3)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('Vegetation Water Content Time Series', fontsize=20, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 植被类型列表\n",
    "    vegetation_types = [\n",
    "        ('CornVegMeasured', data_dict_2017),  # 玉米\n",
    "        ('OatVegMeasured', data_dict_2017),   # 燕麦\n",
    "        ('GrassVWC', data_dict_2018)           # 草\n",
    "    ]\n",
    "    \n",
    "    # 实测VWC列名映射\n",
    "    ACTUAL_COL_MAPPING = {\n",
    "        'CornVegMeasured': 'total_VWC(kg/m2)',\n",
    "        'OatVegMeasured': 'total_VWC(kg/m2)',\n",
    "        'GrassVWC': 'vegetation water content(kg/m2)'\n",
    "    }\n",
    "    \n",
    "    # 存储所有评估指标\n",
    "    all_metrics = {}\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 根据图片定义极化标记样式\n",
    "    POL_MARKERS = {\n",
    "        'H': '+',   # 加号\n",
    "        'V': '^',   # 三角形\n",
    "        'HV': 's'   # 正方形\n",
    "    }\n",
    "    \n",
    "    # 波段颜色\n",
    "    BAND_COLORS = {\n",
    "        'Ku': 'blue',\n",
    "        'X': 'green',\n",
    "        'C': 'red'\n",
    "    }\n",
    "    \n",
    "    # 极化线型\n",
    "    POL_LINESTYLES = {\n",
    "        'H': '-',\n",
    "        'V': '--',\n",
    "        'HV': '-.'\n",
    "    }\n",
    "    \n",
    "    # 极化名称映射 - 修改1：使用新的标题格式\n",
    "    POL_NAMES = {\n",
    "        'H': 'H-Pol',\n",
    "        'V': 'V-Pol',\n",
    "        'HV': 'H&V-Pol'\n",
    "    }\n",
    "    \n",
    "    # 波段名称映射 - 修改2：使用新的标题格式\n",
    "    BAND_NAMES = {\n",
    "        'Ku': 'Ku-Band',\n",
    "        'X': 'X-Band',\n",
    "        'C': 'C-Band'\n",
    "    }\n",
    "    \n",
    "    # 植被类型显示名称\n",
    "    VEGETATION_TYPES = {\n",
    "        'CornVegMeasured': 'Corn',\n",
    "        'OatVegMeasured': 'Oat',\n",
    "        'GrassVWC': 'Grass'\n",
    "    }\n",
    "    \n",
    "    # 遍历所有植被类型\n",
    "    for idx, (veg_type, data_dict) in enumerate(vegetation_types):\n",
    "        ax = fig.add_subplot(gs[idx])\n",
    "        \n",
    "        # 获取当前植被类型的实测列名\n",
    "        actual_col = ACTUAL_COL_MAPPING[veg_type]\n",
    "        \n",
    "        # 初始化Y轴范围\n",
    "        y_min = float('inf')\n",
    "        y_max = float('-inf')\n",
    "        \n",
    "        # 获取实测数据\n",
    "        if veg_type in data_dict:\n",
    "            df_measured = data_dict[veg_type].copy()\n",
    "            \n",
    "            # 确保日期列存在\n",
    "            if 'Date' not in df_measured.columns:\n",
    "                print(f\"警告: {veg_type} 中没有 'Date' 列\")\n",
    "                continue\n",
    "            \n",
    "            # 按日期排序\n",
    "            df_measured = df_measured.sort_values('Date')\n",
    "            \n",
    "            # 更新Y轴范围（实测值）\n",
    "            if actual_col in df_measured.columns:\n",
    "                measured_values = df_measured[actual_col].dropna()\n",
    "                if not measured_values.empty:\n",
    "                    y_min = min(y_min, measured_values.min())\n",
    "                    y_max = max(y_max, measured_values.max())\n",
    "            \n",
    "            # 获取拟合数据用于预测\n",
    "            fitting_sheet = FITTING_MAPPING.get(veg_type, veg_type)\n",
    "            if fitting_sheet in data_dict:\n",
    "                df_fitting = data_dict[fitting_sheet].copy()\n",
    "                \n",
    "                # 确保日期列存在\n",
    "                if 'Date' not in df_fitting.columns:\n",
    "                    print(f\"警告: {fitting_sheet} 中没有 'Date' 列\")\n",
    "                    continue\n",
    "                \n",
    "                # 按日期排序\n",
    "                df_fitting = df_fitting.sort_values('Date')\n",
    "            else:\n",
    "                # 2018年没有单独的拟合数据\n",
    "                df_fitting = df_measured.copy()\n",
    "            \n",
    "            # 存储评估指标\n",
    "            metrics = []\n",
    "            \n",
    "            # 为每个波段和极化组合预测VWC\n",
    "            for band in BAND_COLORS.keys():\n",
    "                for pol in POL_LINESTYLES.keys():\n",
    "                    # 生成列名\n",
    "                    col_name = f\"Predicted_VWC_{band}_{pol}\"\n",
    "                    \n",
    "                    # 如果列不存在，使用模型预测\n",
    "                    if col_name not in df_fitting.columns:\n",
    "                        print(f\"为 {fitting_sheet} 预测 {band}-{pol} VWC...\")\n",
    "                        df_fitting[col_name] = predict_vwc_for_sheet(df_fitting, band, pol)\n",
    "                    \n",
    "                    # 只在有有效预测值的点进行绘制和评估\n",
    "                    if col_name in df_fitting.columns:\n",
    "                        # 更新Y轴范围（预测值）\n",
    "                        pred_values = df_fitting[col_name].dropna()\n",
    "                        if not pred_values.empty:\n",
    "                            y_min = min(y_min, pred_values.min())\n",
    "                            y_max = max(y_max, pred_values.max())\n",
    "                        \n",
    "                        # 获取有效预测数据点\n",
    "                        valid_mask = df_fitting[col_name].notna()\n",
    "                        valid_dates = df_fitting['Date'][valid_mask]\n",
    "                        valid_values = df_fitting[col_name][valid_mask]\n",
    "                        \n",
    "                        # 如果数据点足够多，使用样条插值生成平滑曲线\n",
    "                        if len(valid_dates) > 3:\n",
    "                            try:\n",
    "                                # 将日期转换为数值（从最小日期开始的天数）\n",
    "                                date_numeric = (valid_dates - valid_dates.min()).dt.days\n",
    "                                \n",
    "                                # 创建样条插值对象\n",
    "                                spline = make_interp_spline(date_numeric, valid_values, k=3)\n",
    "                                \n",
    "                                # 生成更密集的时间点\n",
    "                                dense_dates = np.linspace(date_numeric.min(), date_numeric.max(), 300)\n",
    "                                dense_values = spline(dense_dates)\n",
    "                                \n",
    "                                # 将数值日期转换回实际日期\n",
    "                                dense_dates = valid_dates.min() + pd.to_timedelta(dense_dates, unit='D')\n",
    "                                \n",
    "                                # 绘制平滑曲线\n",
    "                                ax.plot(dense_dates, dense_values,\n",
    "                                        color=BAND_COLORS[band],\n",
    "                                        linestyle=POL_LINESTYLES[pol],\n",
    "                                        linewidth=1.5)\n",
    "                            except Exception as e:\n",
    "                                print(f\"样条插值失败: {str(e)}\")\n",
    "                                # 如果插值失败，使用原始数据点绘制折线\n",
    "                                ax.plot(valid_dates, valid_values,\n",
    "                                        color=BAND_COLORS[band],\n",
    "                                        linestyle=POL_LINESTYLES[pol],\n",
    "                                        linewidth=1.5)\n",
    "                        else:\n",
    "                            # 数据点太少，直接绘制折线\n",
    "                            ax.plot(valid_dates, valid_values,\n",
    "                                    color=BAND_COLORS[band],\n",
    "                                    linestyle=POL_LINESTYLES[pol],\n",
    "                                    linewidth=1.5)\n",
    "                        \n",
    "                        # 找出同时有实测值和预测值的点\n",
    "                        common_data = pd.merge(\n",
    "                            df_measured[['Date', actual_col]], \n",
    "                            df_fitting[['Date', col_name]], \n",
    "                            on='Date', \n",
    "                            how='inner'\n",
    "                        ).dropna(subset=[actual_col, col_name])\n",
    "                        \n",
    "                        if not common_data.empty:\n",
    "                            # 更新Y轴范围（共同数据）\n",
    "                            common_min = min(common_data[actual_col].min(), common_data[col_name].min())\n",
    "                            common_max = max(common_data[actual_col].max(), common_data[col_name].max())\n",
    "                            y_min = min(y_min, common_min)\n",
    "                            y_max = max(y_max, common_max)\n",
    "                            \n",
    "                            # 在实测日期位置绘制实测值点（空心圆）\n",
    "                            ax.plot(common_data['Date'], common_data[actual_col],\n",
    "                                    linestyle='',  # 无线条\n",
    "                                    color='black',\n",
    "                                    marker='o',\n",
    "                                    markersize=8,\n",
    "                                    markerfacecolor='none',  # 透明填充（空心）\n",
    "                                    markeredgewidth=1.5)\n",
    "                            \n",
    "                            # 在实测日期位置绘制预测点（空心标记）\n",
    "                            ax.plot(common_data['Date'], common_data[col_name],\n",
    "                                    linestyle='',  # 无线条\n",
    "                                    color=BAND_COLORS[band],\n",
    "                                    marker=POL_MARKERS[pol],\n",
    "                                    markersize=10,\n",
    "                                    markerfacecolor='none',  # 透明填充（空心）\n",
    "                                    markeredgewidth=1.5)\n",
    "                            \n",
    "                            # 计算评估指标\n",
    "                            rmse = np.sqrt(mean_squared_error(common_data[actual_col], common_data[col_name]))\n",
    "                            r2 = r2_score(common_data[actual_col], common_data[col_name])\n",
    "                            \n",
    "                            # 添加到指标列表\n",
    "                            metrics.append({\n",
    "                                'band': band,\n",
    "                                'pol': pol,\n",
    "                                'rmse': rmse,\n",
    "                                'r2': r2\n",
    "                            })\n",
    "                            \n",
    "                            # 保存预测结果\n",
    "                            model_key = f\"{veg_type}_{band}_{pol}\"\n",
    "                            all_predictions[model_key] = {\n",
    "                                'dates': common_data['Date'].tolist(),\n",
    "                                'measured': common_data[actual_col].tolist(),\n",
    "                                'predicted': common_data[col_name].tolist(),\n",
    "                                'rmse': rmse,\n",
    "                                'r2': r2\n",
    "                            }\n",
    "            \n",
    "            # 设置子图标题 - 修改3：使用新的标题格式\n",
    "            ax.set_title(VEGETATION_TYPES.get(veg_type, veg_type), \n",
    "                         fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if idx == 2:  # 最后一行\n",
    "                ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('VWC (kg/m²)', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # 设置X轴格式\n",
    "            ax.xaxis.set_major_locator(mdates.DayLocator(interval=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # 动态设置Y轴范围\n",
    "            if y_min != float('inf') and y_max != float('-inf'):\n",
    "                # 添加10%的边距\n",
    "                y_range = y_max - y_min\n",
    "                padding = y_range * 0.1\n",
    "                \n",
    "                # 确保最小值不小于0\n",
    "                y_min = max(0, y_min - padding)\n",
    "                y_max = y_max + padding\n",
    "                \n",
    "                ax.set_ylim(y_min, y_max)\n",
    "            else:\n",
    "                # 默认范围\n",
    "                ax.set_ylim(0, 10)\n",
    "            \n",
    "            # 存储指标\n",
    "            all_metrics[veg_type] = metrics\n",
    "    \n",
    "    # ==================================\n",
    "    # 创建图例（精确匹配要求）\n",
    "    # ==================================\n",
    "    \n",
    "    # 创建图例区域的轴\n",
    "    ax_legend = fig.add_subplot(gs[3])\n",
    "    ax_legend.axis('off')  # 隐藏坐标轴\n",
    "    \n",
    "    # 定义图例行内容（标题+项目） - 修改4：使用新的标题格式\n",
    "    legend_rows = [\n",
    "        # 第一行：Ku波段\n",
    "        [f\"{BAND_NAMES['Ku']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "        \n",
    "        # 第二行：X波段\n",
    "        [f\"{BAND_NAMES['X']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "        \n",
    "        # 第三行：C波段\n",
    "        [f\"{BAND_NAMES['C']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "\n",
    "        # 第四行：实测点\n",
    "        [f\"Insitu VWC\"]\n",
    "    ]\n",
    "    \n",
    "    # 创建代理艺术家\n",
    "    proxies = {}\n",
    "    \n",
    "    # Insitu VWC代理（空心圆）\n",
    "    proxies['insitu'] = plt.Line2D([], [], \n",
    "                     linestyle='', \n",
    "                     marker='o',\n",
    "                     markersize=10,\n",
    "                     markerfacecolor='none',\n",
    "                     markeredgecolor='black',\n",
    "                     markeredgewidth=1.5,\n",
    "                     label='Insitu VWC')\n",
    "    \n",
    "    # 波段-极化组合代理 - 修改5：使用新的标题格式\n",
    "    for band in ['Ku', 'X', 'C']:\n",
    "        color = BAND_COLORS[band]\n",
    "        for pol in ['H', 'V', 'HV']:\n",
    "            proxies[f\"{band}-{pol}\"] = plt.Line2D([], [],\n",
    "                color=color,\n",
    "                linestyle=POL_LINESTYLES[pol],\n",
    "                linewidth=2,\n",
    "                marker=POL_MARKERS[pol],\n",
    "                markersize=10,\n",
    "                markerfacecolor='none',\n",
    "                markeredgecolor=color,\n",
    "                markeredgewidth=1.5,\n",
    "                label=f\"{BAND_NAMES[band]},{POL_NAMES[pol]}\")\n",
    "    \n",
    "    # 为每行创建图例\n",
    "    y_positions = [0.85, 0.60, 0.35, 0.10]  # 三行垂直位置\n",
    "    \n",
    "    for row_idx, row_items in enumerate(legend_rows):\n",
    "        handles = []\n",
    "        labels = []\n",
    "        \n",
    "        for item in row_items:\n",
    "            # 处理Insitu项\n",
    "            if item == \"Insitu VWC\":\n",
    "                handles.append(proxies['insitu'])\n",
    "                labels.append(item)\n",
    "            # 处理波段-极化项\n",
    "            else:\n",
    "                # 解析新的标签格式\n",
    "                band_part, pol_part = item.split(',')\n",
    "                band = band_part.split('-')[0]  # 提取波段名称\n",
    "                \n",
    "                handles.append(proxies[f\"{band}-{pol}\"])\n",
    "                labels.append(item)  # 使用完整的标签文本\n",
    "        \n",
    "        # 计算当前行文本宽度（均匀分布）\n",
    "        n_items = len(handles)\n",
    "        x_positions = np.linspace(0.05, 0.95, n_items)\n",
    "        \n",
    "        # 绘制当前行的图例项\n",
    "        for i, (handle, label) in enumerate(zip(handles, labels)):\n",
    "            ax_legend.plot([], [])  # 空白绘图以创建图例项\n",
    "            \n",
    "            # 创建图例句柄\n",
    "            leg = ax_legend.legend([handle], [label], \n",
    "                                  loc='lower center',\n",
    "                                  bbox_to_anchor=(x_positions[i], y_positions[row_idx]),\n",
    "                                  frameon=False,\n",
    "                                  handlelength=2,\n",
    "                                  fontsize=10,\n",
    "                                  handletextpad=0.8)\n",
    "            \n",
    "            # 添加到轴（否则会被覆盖）\n",
    "            ax_legend.add_artist(leg)\n",
    "    \n",
    "    # 在子图中显示评估指标\n",
    "    for idx, (veg_type, metrics) in enumerate(all_metrics.items()):\n",
    "        if idx < 3:  # 确保索引有效（排除图例轴）\n",
    "            ax = fig.axes[idx]\n",
    "            \n",
    "            # 创建指标文本\n",
    "            if metrics:\n",
    "                # 使用多列格式显示所有指标\n",
    "                metric_text = \"Evaluation Metrics:\\n\"\n",
    "                \n",
    "                # 按波段分组指标\n",
    "                band_metrics = {}\n",
    "                for metric in metrics:\n",
    "                    band = metric['band']\n",
    "                    if band not in band_metrics:\n",
    "                        band_metrics[band] = []\n",
    "                    band_metrics[band].append(metric)\n",
    "                \n",
    "                # 为每个波段创建一行文本\n",
    "                for band in ['Ku', 'X', 'C']:\n",
    "                    if band in band_metrics:\n",
    "                        band_text = f\"{BAND_NAMES[band]}: \"\n",
    "                        pol_texts = []\n",
    "                        for metric in band_metrics[band]:\n",
    "                            pol_texts.append(f\"{POL_NAMES[metric['pol']]}(RMSE={metric['rmse']:.3f})\")\n",
    "                        band_text += \", \".join(pol_texts)\n",
    "                        metric_text += band_text + \"\\n\"\n",
    "                \n",
    "                # 添加文本框\n",
    "                ax.text(0.02, 0.95, metric_text, \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=9,\n",
    "                        verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    \n",
    "    # 保存图像\n",
    "    figures_dir = Path(\"figures\")\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = figures_dir / \"Combined_VWC_Time_Series.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"组合时间序列图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存所有预测结果到CSV文件\n",
    "    for model_key, data in all_predictions.items():\n",
    "        veg_type, band, pol = model_key.split('_')\n",
    "        df = pd.DataFrame({\n",
    "            'Date': data['dates'],\n",
    "            'Measured': data['measured'],\n",
    "            'Predicted': data['predicted']\n",
    "        })\n",
    "        csv_path = output_dir / f\"{veg_type}_{band}_{pol}_predictions.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"保存预测结果至: {csv_path}\")\n",
    "    \n",
    "    # 保存评估指标\n",
    "    metrics_path = output_dir / \"model_metrics.csv\"\n",
    "    metrics_data = []\n",
    "    for veg_type, metrics in all_metrics.items():\n",
    "        for metric in metrics:\n",
    "            metrics_data.append({\n",
    "                'Vegetation': veg_type,\n",
    "                'Band': metric['band'],\n",
    "                'Polarization': metric['pol'],\n",
    "                'RMSE': metric['rmse'],\n",
    "                'R2': metric['r2']\n",
    "            })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"保存模型评估指标至: {metrics_path}\")\n",
    "\n",
    "def main():\n",
    "    # 2017年数据文件\n",
    "    file_2017 = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\"\n",
    "    data_2017 = load_data(file_2017)\n",
    "    \n",
    "    # 2018年数据文件\n",
    "    file_2018 = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\"\n",
    "    data_2018 = load_data(file_2018)\n",
    "    \n",
    "    # 创建组合时间序列图\n",
    "    create_combined_plots(data_2017, data_2018)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfa7f15-2891-4042-9cd2-c2ede2408e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载预测结果: prediction_results\n",
      "处理模型: Ku_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: Ku_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: Ku_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "散点图已保存至: figures\\Scatter_Predictions_From_Saved_Data.png\n",
      "\n",
      "模型评估指标:\n",
      "Ku_H:\n",
      "  Corn RMSE = 0.4584\n",
      "  Oat RMSE = 0.2044\n",
      "  Grass RMSE = 0.3865\n",
      "  Total RMSE = 0.3739\n",
      "Ku_V:\n",
      "  Corn RMSE = 0.3945\n",
      "  Oat RMSE = 0.2822\n",
      "  Grass RMSE = 0.4523\n",
      "  Total RMSE = 0.3992\n",
      "Ku_HV:\n",
      "  Corn RMSE = 0.6910\n",
      "  Oat RMSE = 0.3684\n",
      "  Grass RMSE = 0.5800\n",
      "  Total RMSE = 0.5715\n",
      "X_H:\n",
      "  Corn RMSE = 0.6264\n",
      "  Oat RMSE = 0.2532\n",
      "  Grass RMSE = 0.4367\n",
      "  Total RMSE = 0.4655\n",
      "X_V:\n",
      "  Corn RMSE = 0.4515\n",
      "  Oat RMSE = 0.2022\n",
      "  Grass RMSE = 0.5206\n",
      "  Total RMSE = 0.4408\n",
      "X_HV:\n",
      "  Corn RMSE = 0.4707\n",
      "  Oat RMSE = 0.2664\n",
      "  Grass RMSE = 0.5018\n",
      "  Total RMSE = 0.4449\n",
      "C_H:\n",
      "  Corn RMSE = 0.3580\n",
      "  Oat RMSE = 0.1685\n",
      "  Grass RMSE = 0.4001\n",
      "  Total RMSE = 0.3436\n",
      "C_V:\n",
      "  Corn RMSE = 0.6191\n",
      "  Oat RMSE = 0.3555\n",
      "  Grass RMSE = 0.4970\n",
      "  Total RMSE = 0.5058\n",
      "C_HV:\n",
      "  Corn RMSE = 0.3692\n",
      "  Oat RMSE = 0.1610\n",
      "  Grass RMSE = 0.4572\n",
      "  Total RMSE = 0.3774\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 3*3 散点图结果\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "BAND_COLORS = {\n",
    "    'Ku': '#1f77b4',  # 蓝色\n",
    "    'X': '#ff7f0e',   # 橙色\n",
    "    'C': '#2ca02c'    # 绿色\n",
    "}\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 植被类型标记样式 - 玉米标记改为空心方形（'s'）\n",
    "VEG_MARKERS = {\n",
    "    'CornVegMeasured': {'marker': 's', 'size': 80, 'label': 'Corn (2017)'},  # 改为方形\n",
    "    'OatVegMeasured': {'marker': '^', 'size': 80, 'label': 'Oat (2017)'},\n",
    "    'GrassVWC': {'marker': 'o', 'size': 80, 'label': 'Grass (2018)'}\n",
    "}\n",
    "\n",
    "def load_prediction_data(prediction_dir):\n",
    "    \"\"\"从CSV文件加载预测结果\"\"\"\n",
    "    print(f\"加载预测结果: {prediction_dir}\")\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有CSV文件\n",
    "    for csv_file in prediction_dir.glob(\"*_predictions.csv\"):\n",
    "        # 解析文件名获取模型信息\n",
    "        filename = csv_file.stem\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 4:  # 格式: {植被类型}_{波段}_{极化}_predictions\n",
    "            veg_type = parts[0]\n",
    "            band = parts[1]\n",
    "            pol = parts[2]\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            \n",
    "            # 加载数据\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # 确保日期是datetime类型\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # 存储数据\n",
    "            if model_key not in all_predictions:\n",
    "                all_predictions[model_key] = {}\n",
    "            \n",
    "            all_predictions[model_key][veg_type] = df\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "def get_model_title(band, pol):\n",
    "    \"\"\"根据波段和极化返回自定义标题\"\"\"\n",
    "    band_names = {\n",
    "        'Ku': 'Ku-Band',\n",
    "        'X': 'X-Band',\n",
    "        'C': 'C-Band'\n",
    "    }\n",
    "    pol_names = {\n",
    "        'H': 'H-Pol',\n",
    "        'V': 'V-Pol',\n",
    "        'HV': 'H&V-Pol'  # 修改这里\n",
    "    }\n",
    "    return f\"{band_names.get(band, band)},{pol_names.get(pol, pol)}\"\n",
    "\n",
    "def create_scatter_plots_from_predictions(prediction_dir):\n",
    "    \"\"\"从预测结果文件创建9个模型的真值与预测值散点图（3x3网格）\"\"\"\n",
    "    # 加载预测结果\n",
    "    all_predictions = load_prediction_data(prediction_dir)\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"警告: 没有找到预测结果文件\")\n",
    "        return\n",
    "    \n",
    "    # 创建3x3网格图\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.suptitle('', fontsize=20, y=0.95)\n",
    "    gs = gridspec.GridSpec(3, 3, wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    # 收集所有散点的最小和最大值（用于统一坐标轴）\n",
    "    all_actual_min, all_actual_max = np.inf, -np.inf\n",
    "    all_pred_min, all_pred_max = np.inf, -np.inf\n",
    "    \n",
    "    # 收集所有评估指标\n",
    "    all_metrics = {}\n",
    "\n",
    "    # 处理每个模型（波段和极化组合）\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            print(f\"处理模型: {model_key}\")\n",
    "            \n",
    "            # 检查该模型是否有预测数据\n",
    "            if model_key not in all_predictions:\n",
    "                print(f\"警告: {model_key} 模型没有预测数据\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 收集该模型的所有植被类型的数据\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            all_veg_types = []\n",
    "            \n",
    "            # 存储各植被类型的数据点\n",
    "            veg_data = {\n",
    "                'CornVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'OatVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'GrassVWC': {'actual': [], 'predicted': []}\n",
    "            }\n",
    "            \n",
    "            # 处理玉米数据\n",
    "            veg_type = 'CornVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 玉米数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理燕麦数据\n",
    "            veg_type = 'OatVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 燕麦数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理草数据\n",
    "            veg_type = 'GrassVWC'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 草数据点: {len(df)}\")\n",
    "            \n",
    "            # 如果没有数据点，跳过\n",
    "            if len(all_actual) == 0:\n",
    "                print(f\"警告: {model_key} 模型没有有效数据点\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 转换为numpy数组\n",
    "            all_actual = np.array(all_actual)\n",
    "            all_predicted = np.array(all_predicted)\n",
    "            \n",
    "            # 更新全局最小/最大值\n",
    "            all_actual_min = min(all_actual_min, np.min(all_actual))\n",
    "            all_actual_max = max(all_actual_max, np.max(all_actual))\n",
    "            all_pred_min = min(all_pred_min, np.min(all_predicted))\n",
    "            all_pred_max = max(all_pred_max, np.max(all_predicted))\n",
    "            \n",
    "            # 计算各植被类型的RMSE\n",
    "            rmse_corn = None\n",
    "            rmse_oat = None\n",
    "            rmse_grass = None\n",
    "            \n",
    "            if veg_data['CornVegMeasured']['actual']:\n",
    "                actual_corn = np.array(veg_data['CornVegMeasured']['actual'])\n",
    "                predicted_corn = np.array(veg_data['CornVegMeasured']['predicted'])\n",
    "                rmse_corn = np.sqrt(mean_squared_error(actual_corn, predicted_corn))\n",
    "            \n",
    "            if veg_data['OatVegMeasured']['actual']:\n",
    "                actual_oat = np.array(veg_data['OatVegMeasured']['actual'])\n",
    "                predicted_oat = np.array(veg_data['OatVegMeasured']['predicted'])\n",
    "                rmse_oat = np.sqrt(mean_squared_error(actual_oat, predicted_oat))\n",
    "            \n",
    "            if veg_data['GrassVWC']['actual']:\n",
    "                actual_grass = np.array(veg_data['GrassVWC']['actual'])\n",
    "                predicted_grass = np.array(veg_data['GrassVWC']['predicted'])\n",
    "                rmse_grass = np.sqrt(mean_squared_error(actual_grass, predicted_grass))\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse_total = np.sqrt(mean_squared_error(all_actual, all_predicted))\n",
    "            \n",
    "            # 存储评估指标\n",
    "            all_metrics[model_key] = {\n",
    "                'RMSE_Corn': rmse_corn,\n",
    "                'RMSE_Oat': rmse_oat,\n",
    "                'RMSE_Grass': rmse_grass,\n",
    "                'RMSE_Total': rmse_total\n",
    "            }\n",
    "            \n",
    "            # 绘制散点图 - 按植被类型区分标记\n",
    "            # 先绘制草和燕麦，最后绘制玉米（确保玉米在最上层）\n",
    "            for veg_type in ['GrassVWC', 'OatVegMeasured', 'CornVegMeasured']:\n",
    "                if veg_data[veg_type]['actual']:\n",
    "                    actual_values = np.array(veg_data[veg_type]['actual'])\n",
    "                    predicted_values = np.array(veg_data[veg_type]['predicted'])\n",
    "                    \n",
    "                    marker_style = VEG_MARKERS[veg_type]\n",
    "                    \n",
    "                    # 为玉米标记使用更大的尺寸和线宽\n",
    "                    if veg_type == 'CornVegMeasured':\n",
    "                        size = 100  # 增加大小\n",
    "                        edgewidth = 1.5  # 更粗的线宽\n",
    "                        alpha = 0.9  # 更高的不透明度\n",
    "                    else:\n",
    "                        size = marker_style['size']\n",
    "                        edgewidth = 1.0\n",
    "                        alpha = 0.8\n",
    "                    \n",
    "                    # 所有标记使用相同的波段颜色\n",
    "                    ax.scatter(actual_values, predicted_values, \n",
    "                              marker=marker_style['marker'], \n",
    "                              s=size,\n",
    "                              alpha=alpha,  # 调整透明度\n",
    "                              facecolor='none', \n",
    "                              edgecolor=BAND_COLORS[band],  # 使用波段颜色\n",
    "                              linewidths=edgewidth,\n",
    "                              label=marker_style['label'])\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            ax.plot([0, 4], [0, 4], 'k--', linewidth=1, label='1:1 Line')\n",
    "            \n",
    "            # 设置标题和坐标轴标签\n",
    "            ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "            if j == 0:  # 第一列添加y轴标签\n",
    "                ax.set_ylabel('RF VWC (kg/m²)', fontsize=12)\n",
    "            if i == 2:  # 最后一行添加x轴标签\n",
    "                ax.set_xlabel('In Situ VWC (kg/m²)', fontsize=12)\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # 显示评估指标\n",
    "            metric_text = \"\"\n",
    "            if rmse_corn is not None:\n",
    "                metric_text += f\"Corn RMSE = {rmse_corn:.3f}\\n\"\n",
    "            if rmse_oat is not None:\n",
    "                metric_text += f\"Oat RMSE = {rmse_oat:.3f}\\n\"\n",
    "            if rmse_grass is not None:\n",
    "                metric_text += f\"Grass RMSE = {rmse_grass:.3f}\\n\"\n",
    "            metric_text += f\"Total RMSE = {rmse_total:.3f}\"\n",
    "            \n",
    "            ax.text(0.05, 0.95, metric_text, transform=ax.transAxes, \n",
    "                   fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 设置所有子图的坐标轴范围一致\n",
    "    max_val = 4\n",
    "    min_val = 0\n",
    "    for ax in fig.get_axes():\n",
    "        ax.set_xlim(min_val, max_val)\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "    \n",
    "    # 添加图例\n",
    "    # 创建代理艺术家用于图例\n",
    "    handles = []\n",
    "    labels = []\n",
    "    \n",
    "    # 添加植被类型标记\n",
    "    for veg_type, style in VEG_MARKERS.items():\n",
    "        # 为玉米标记使用特殊大小\n",
    "        if veg_type == 'CornVegMeasured':\n",
    "            markersize = 10  # 图例中保持相同大小\n",
    "        else:\n",
    "            markersize = 8\n",
    "            \n",
    "        handles.append(\n",
    "            plt.Line2D([], [], marker=style['marker'], linestyle='None', \n",
    "                       markersize=markersize, alpha=0.7, markerfacecolor='none', \n",
    "                       markeredgecolor='gray', label=style['label'])\n",
    "        )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    handles.append(\n",
    "        plt.Line2D([], [], color='k', linestyle='--', linewidth=1, label='1:1 Line')\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.95])  # 调整底部空间\n",
    " \n",
    "    # 添加图例到整个图形\n",
    "    fig.legend(handles=handles, loc='lower center', \n",
    "               bbox_to_anchor=(0.5, 0.05), ncol=4, fontsize=10, \n",
    "               title=\"\")\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = output_dir / \"Scatter_Predictions_From_Saved_Data.png\"\n",
    "    plt.savefig(fig_path, dpi=1000, bbox_inches='tight', pad_inches=0.1)\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印所有模型的评估指标\n",
    "    print(\"\\n模型评估指标:\")\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        if metrics['RMSE_Corn'] is not None:\n",
    "            print(f\"  Corn RMSE = {metrics['RMSE_Corn']:.4f}\")\n",
    "        if metrics['RMSE_Oat'] is not None:\n",
    "            print(f\"  Oat RMSE = {metrics['RMSE_Oat']:.4f}\")\n",
    "        if metrics['RMSE_Grass'] is not None:\n",
    "            print(f\"  Grass RMSE = {metrics['RMSE_Grass']:.4f}\")\n",
    "        print(f\"  Total RMSE = {metrics['RMSE_Total']:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # 设置预测结果目录\n",
    "    prediction_dir = Path(\"prediction_results\")\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots_from_predictions(prediction_dir)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa1ee17-8e53-458a-875c-d4d0fef64680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载预测结果: prediction_results\n",
      "处理模型: Ku_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: Ku_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "散点图已保存至: figures\\Scatter_Predictions_HV_Only.png\n",
      "\n",
      "模型评估指标:\n",
      "Ku_H:\n",
      "  Corn RMSE = 0.4584\n",
      "  Oat RMSE = 0.2044\n",
      "  Grass RMSE = 0.3865\n",
      "  Total RMSE = 0.3739\n",
      "X_H:\n",
      "  Corn RMSE = 0.6264\n",
      "  Oat RMSE = 0.2532\n",
      "  Grass RMSE = 0.4367\n",
      "  Total RMSE = 0.4655\n",
      "C_H:\n",
      "  Corn RMSE = 0.3580\n",
      "  Oat RMSE = 0.1685\n",
      "  Grass RMSE = 0.4001\n",
      "  Total RMSE = 0.3436\n",
      "Ku_V:\n",
      "  Corn RMSE = 0.3945\n",
      "  Oat RMSE = 0.2822\n",
      "  Grass RMSE = 0.4523\n",
      "  Total RMSE = 0.3992\n",
      "X_V:\n",
      "  Corn RMSE = 0.4515\n",
      "  Oat RMSE = 0.2022\n",
      "  Grass RMSE = 0.5206\n",
      "  Total RMSE = 0.4408\n",
      "C_V:\n",
      "  Corn RMSE = 0.6191\n",
      "  Oat RMSE = 0.3555\n",
      "  Grass RMSE = 0.4970\n",
      "  Total RMSE = 0.5058\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 3*2 散点图结果\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# 常量定义 - 修改1：只包含H和V极化\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V']  # 只包含H和V极化，排除HV\n",
    "\n",
    "BAND_COLORS = {\n",
    "    'Ku': '#1f77b4',  # 蓝色\n",
    "    'X': '#ff7f0e',   # 橙色\n",
    "    'C': '#2ca02c'    # 绿色\n",
    "}\n",
    "\n",
    "# 植被类型标记样式 - 玉米标记改为空心方形（'s'）\n",
    "VEG_MARKERS = {\n",
    "    'CornVegMeasured': {'marker': 's', 'size': 80, 'label': 'Corn (2017)'},  # 改为方形\n",
    "    'OatVegMeasured': {'marker': '^', 'size': 80, 'label': 'Oat (2017)'},\n",
    "    'GrassVWC': {'marker': 'o', 'size': 80, 'label': 'Grass (2018)'}\n",
    "}\n",
    "\n",
    "def load_prediction_data(prediction_dir):\n",
    "    \"\"\"从CSV文件加载预测结果\"\"\"\n",
    "    print(f\"加载预测结果: {prediction_dir}\")\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有CSV文件\n",
    "    for csv_file in prediction_dir.glob(\"*_predictions.csv\"):\n",
    "        # 解析文件名获取模型信息\n",
    "        filename = csv_file.stem\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 4:  # 格式: {植被类型}_{波段}_{极化}_predictions\n",
    "            veg_type = parts[0]\n",
    "            band = parts[1]\n",
    "            pol = parts[2]\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            \n",
    "            # 加载数据\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # 确保日期是datetime类型\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # 存储数据\n",
    "            if model_key not in all_predictions:\n",
    "                all_predictions[model_key] = {}\n",
    "            \n",
    "            all_predictions[model_key][veg_type] = df\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "def get_model_title(band, pol):\n",
    "    \"\"\"根据波段和极化返回自定义标题\"\"\"\n",
    "    band_names = {\n",
    "        'Ku': 'Ku-Band',\n",
    "        'X': 'X-Band',\n",
    "        'C': 'C-Band'\n",
    "    }\n",
    "    pol_names = {\n",
    "        'H': 'H-Pol',\n",
    "        'V': 'V-Pol'\n",
    "    }\n",
    "    return f\"{band_names.get(band, band)},{pol_names.get(pol, pol)}\"\n",
    "\n",
    "def create_scatter_plots_from_predictions(prediction_dir):\n",
    "    \"\"\"从预测结果文件创建6个模型的真值与预测值散点图（2x3网格）\"\"\"\n",
    "    # 加载预测结果\n",
    "    all_predictions = load_prediction_data(prediction_dir)\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"警告: 没有找到预测结果文件\")\n",
    "        return\n",
    "    \n",
    "    # 修改2：创建2x3网格图\n",
    "    fig = plt.figure(figsize=(15, 10))  # 调整高度以适应2行\n",
    "    fig.suptitle('', fontsize=20, y=0.95)\n",
    "    gs = gridspec.GridSpec(2, 3, wspace=0.25, hspace=0.3)  # 调整间距\n",
    "    \n",
    "    # 收集所有散点的最小和最大值（用于统一坐标轴）\n",
    "    all_actual_min, all_actual_max = np.inf, -np.inf\n",
    "    all_pred_min, all_pred_max = np.inf, -np.inf\n",
    "    \n",
    "    # 收集所有评估指标\n",
    "    all_metrics = {}\n",
    "\n",
    "    # 修改3：调整循环顺序 - 外层为极化，内层为波段\n",
    "    for i, pol in enumerate(POLS):  # 行索引 - 极化方式\n",
    "        for j, band in enumerate(BANDS):  # 列索引 - 波段\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            print(f\"处理模型: {model_key}\")\n",
    "            \n",
    "            # 检查该模型是否有预测数据\n",
    "            if model_key not in all_predictions:\n",
    "                print(f\"警告: {model_key} 模型没有预测数据\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 收集该模型的所有植被类型的数据\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            all_veg_types = []\n",
    "            \n",
    "            # 存储各植被类型的数据点\n",
    "            veg_data = {\n",
    "                'CornVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'OatVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'GrassVWC': {'actual': [], 'predicted': []}\n",
    "            }\n",
    "            \n",
    "            # 处理玉米数据\n",
    "            veg_type = 'CornVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 玉米数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理燕麦数据\n",
    "            veg_type = 'OatVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 燕麦数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理草数据\n",
    "            veg_type = 'GrassVWC'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 草数据点: {len(df)}\")\n",
    "            \n",
    "            # 如果没有数据点，跳过\n",
    "            if len(all_actual) == 0:\n",
    "                print(f\"警告: {model_key} 模型没有有效数据点\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 转换为numpy数组\n",
    "            all_actual = np.array(all_actual)\n",
    "            all_predicted = np.array(all_predicted)\n",
    "            \n",
    "            # 更新全局最小/最大值\n",
    "            all_actual_min = min(all_actual_min, np.min(all_actual))\n",
    "            all_actual_max = max(all_actual_max, np.max(all_actual))\n",
    "            all_pred_min = min(all_pred_min, np.min(all_predicted))\n",
    "            all_pred_max = max(all_pred_max, np.max(all_predicted))\n",
    "            \n",
    "            # 计算各植被类型的RMSE\n",
    "            rmse_corn = None\n",
    "            rmse_oat = None\n",
    "            rmse_grass = None\n",
    "            \n",
    "            if veg_data['CornVegMeasured']['actual']:\n",
    "                actual_corn = np.array(veg_data['CornVegMeasured']['actual'])\n",
    "                predicted_corn = np.array(veg_data['CornVegMeasured']['predicted'])\n",
    "                rmse_corn = np.sqrt(mean_squared_error(actual_corn, predicted_corn))\n",
    "            \n",
    "            if veg_data['OatVegMeasured']['actual']:\n",
    "                actual_oat = np.array(veg_data['OatVegMeasured']['actual'])\n",
    "                predicted_oat = np.array(veg_data['OatVegMeasured']['predicted'])\n",
    "                rmse_oat = np.sqrt(mean_squared_error(actual_oat, predicted_oat))\n",
    "            \n",
    "            if veg_data['GrassVWC']['actual']:\n",
    "                actual_grass = np.array(veg_data['GrassVWC']['actual'])\n",
    "                predicted_grass = np.array(veg_data['GrassVWC']['predicted'])\n",
    "                rmse_grass = np.sqrt(mean_squared_error(actual_grass, predicted_grass))\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse_total = np.sqrt(mean_squared_error(all_actual, all_predicted))\n",
    "            \n",
    "            # 存储评估指标\n",
    "            all_metrics[model_key] = {\n",
    "                'RMSE_Corn': rmse_corn,\n",
    "                'RMSE_Oat': rmse_oat,\n",
    "                'RMSE_Grass': rmse_grass,\n",
    "                'RMSE_Total': rmse_total\n",
    "            }\n",
    "            \n",
    "            # 绘制散点图 - 按植被类型区分标记\n",
    "            # 先绘制草和燕麦，最后绘制玉米（确保玉米在最上层）\n",
    "            for veg_type in ['GrassVWC', 'OatVegMeasured', 'CornVegMeasured']:\n",
    "                if veg_data[veg_type]['actual']:\n",
    "                    actual_values = np.array(veg_data[veg_type]['actual'])\n",
    "                    predicted_values = np.array(veg_data[veg_type]['predicted'])\n",
    "                    \n",
    "                    marker_style = VEG_MARKERS[veg_type]\n",
    "                    \n",
    "                    # 为玉米标记使用更大的尺寸和线宽\n",
    "                    if veg_type == 'CornVegMeasured':\n",
    "                        size = 100  # 增加大小\n",
    "                        edgewidth = 1.5  # 更粗的线宽\n",
    "                        alpha = 0.9  # 更高的不透明度\n",
    "                    else:\n",
    "                        size = marker_style['size']\n",
    "                        edgewidth = 1.0\n",
    "                        alpha = 0.8\n",
    "                    \n",
    "                    # 所有标记使用相同的波段颜色\n",
    "                    ax.scatter(actual_values, predicted_values, \n",
    "                              marker=marker_style['marker'], \n",
    "                              s=size,\n",
    "                              alpha=alpha,  # 调整透明度\n",
    "                              facecolor='none', \n",
    "                              edgecolor=BAND_COLORS[band],  # 使用波段颜色\n",
    "                              linewidths=edgewidth,\n",
    "                              label=marker_style['label'])\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            ax.plot([0, 4], [0, 4], 'k--', linewidth=1, label='1:1 Line')\n",
    "            \n",
    "            # 修改4：调整坐标轴标签位置\n",
    "            ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "            if j == 0:  # 第一列添加y轴标签\n",
    "                ax.set_ylabel('RF VWC (kg/m²)', fontsize=12)\n",
    "            if i == 1:  # 第二行（V极化行）添加x轴标签\n",
    "                ax.set_xlabel('In Situ VWC (kg/m²)', fontsize=12)\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # 显示评估指标\n",
    "            metric_text = \"\"\n",
    "            if rmse_corn is not None:\n",
    "                metric_text += f\"Corn RMSE = {rmse_corn:.3f}\\n\"\n",
    "            if rmse_oat is not None:\n",
    "                metric_text += f\"Oat RMSE = {rmse_oat:.3f}\\n\"\n",
    "            if rmse_grass is not None:\n",
    "                metric_text += f\"Grass RMSE = {rmse_grass:.3f}\\n\"\n",
    "            metric_text += f\"Total RMSE = {rmse_total:.3f}\"\n",
    "            \n",
    "            ax.text(0.05, 0.95, metric_text, transform=ax.transAxes, \n",
    "                   fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 设置所有子图的坐标轴范围一致\n",
    "    max_val = 4\n",
    "    min_val = 0\n",
    "    for ax in fig.get_axes():\n",
    "        ax.set_xlim(min_val, max_val)\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "    \n",
    "    # 添加图例\n",
    "    # 创建代理艺术家用于图例\n",
    "    handles = []\n",
    "    labels = []\n",
    "    \n",
    "    # 添加植被类型标记\n",
    "    for veg_type, style in VEG_MARKERS.items():\n",
    "        # 为玉米标记使用特殊大小\n",
    "        if veg_type == 'CornVegMeasured':\n",
    "            markersize = 10  # 图例中保持相同大小\n",
    "        else:\n",
    "            markersize = 8\n",
    "            \n",
    "        handles.append(\n",
    "            plt.Line2D([], [], marker=style['marker'], linestyle='None', \n",
    "                       markersize=markersize, alpha=0.7, markerfacecolor='none', \n",
    "                       markeredgecolor='gray', label=style['label'])\n",
    "        )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    handles.append(\n",
    "        plt.Line2D([], [], color='k', linestyle='--', linewidth=1, label='1:1 Line')\n",
    "    )\n",
    "    \n",
    "    # 修改5：优化布局调整\n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.95])  # 调整底部空间\n",
    " \n",
    "    # 修改6：重新定位图例位置（提高位置）\n",
    "    fig.legend(handles=handles, loc='lower center', \n",
    "               bbox_to_anchor=(0.5, 0.01), ncol=4, fontsize=16, \n",
    "               title=\"\")\n",
    "    \n",
    "    # 修改7：更改输出文件名以反映新布局\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = output_dir / \"Scatter_Predictions_HV_Only.png\"\n",
    "    \n",
    "    # 修改8：提高输出质量\n",
    "    plt.savefig(fig_path, dpi=600, bbox_inches='tight', pad_inches=0.05)\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印所有模型的评估指标\n",
    "    print(\"\\n模型评估指标:\")\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        if metrics['RMSE_Corn'] is not None:\n",
    "            print(f\"  Corn RMSE = {metrics['RMSE_Corn']:.4f}\")\n",
    "        if metrics['RMSE_Oat'] is not None:\n",
    "            print(f\"  Oat RMSE = {metrics['RMSE_Oat']:.4f}\")\n",
    "        if metrics['RMSE_Grass'] is not None:\n",
    "            print(f\"  Grass RMSE = {metrics['RMSE_Grass']:.4f}\")\n",
    "        print(f\"  Total RMSE = {metrics['RMSE_Total']:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # 设置预测结果目录\n",
    "    prediction_dir = Path(\"prediction_results\")\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots_from_predictions(prediction_dir)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbfad0-7ac5-4f06-8a80-afb71698faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用加权的代码，设置weight为1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8420c-a3e6-4ee5-bfcf-d0d2c815122d",
   "metadata": {},
   "source": [
    "# SMEX02+CLASIC07+SMAPVEX08+SMAPVEX16——对每一部分重新处理，如果有说明采样植被类型，则按照植被类型计算像元VWC加权平均；如果没有，则①去除并处理为像元后计算权重；②直接处理站点数据，自定义PFT的值\n",
    "\n",
    "（SMEX08更名为SMAPVEX08）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1ddde-3662-4662-b28f-1fdd1e2fcb9c",
   "metadata": {},
   "source": [
    "## 1.处理为站点区域的验证，未标记类型的数据不采纳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2933e10b-98d2-4848-b8e8-dcd6313fe213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 SMEX02 数据集...\n",
      "  文件路径: E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\n",
      "  设置 8 行为 PFT_grassnat=1\n",
      "  设置 96 行为 PFT_grassman=1\n",
      "  成功保存 104 行数据\n",
      "处理 CLASIC07 数据集...\n",
      "  文件路径: E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
      "  设置所有行 PFT_grassman=1\n",
      "  成功保存 22 行数据\n",
      "处理 SMAPVEX08 数据集...\n",
      "  文件路径: E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\n",
      "  设置所有行 PFT_grassman=1\n",
      "  成功保存 10 行数据\n",
      "处理 SMAPVEX16 数据集...\n",
      "  文件路径: E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\n",
      "  设置所有行 PFT_grassman=1\n",
      "  成功保存 1400 行数据\n",
      "\n",
      "处理完成! 结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Point_ML.xlsx\n"
     ]
    }
   ],
   "source": [
    "# SMEX02：无植被类型信息，唯一标注的就是Class，10为Grassland-Grassnat；12为Cropland-Grassman；E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx\n",
    "# CLASIC07：Crop列：Corn, Cotton,Cut WW: Harvested Winter Wheat, Pasture, WW:Winter Wheat；E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx\n",
    "# SMAPVEX08：Crop列：SB: Soybean、Corn；E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx\n",
    "# SMAPVEX16：CROP列：Alfalfa、Black Bean、Canola、Corn；Oat、Soybean、Wheat（没有所谓的树木类型，全是农作物）；E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv\n",
    "\n",
    "# 直接读取各部分数据，进行填充，不进行日内均值，保存原先的经纬度——直接合并各ML后缀数据为E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Point_ML.xlsx，根据采样植被修改PFT的值\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 定义PFT列名\n",
    "PFT_COLUMNS = [\n",
    "    'PFT_water', 'PFT_bare', 'PFT_snowice', 'PFT_built', \n",
    "    'PFT_grassnat', 'PFT_grassman', \n",
    "    'PFT_shrubbd', 'PFT_shrubbe', 'PFT_shrubnd', 'PFT_shrubne',\n",
    "    'PFT_treebd', 'PFT_treebe', 'PFT_treend', 'PFT_treene'\n",
    "]\n",
    "\n",
    "# 定义文件路径\n",
    "input_files = {\n",
    "    'SMEX02': r'E:\\data\\VWC\\test-VWC\\NSIDC_0666\\SMEX02\\processed_SMEX02V_ML.xlsx',\n",
    "    'CLASIC07': r'E:\\data\\VWC\\test-VWC\\Insitu CLASIC07\\CL07V_SUM_VEG_CLASIC_ML.xlsx',\n",
    "    'SMAPVEX08': r'E:\\data\\VWC\\test-VWC\\Insitu SMEX08\\processed_SV08V_ML.xlsx',\n",
    "    'SMAPVEX16': r'E:\\data\\VWC\\test-VWC\\Insitu SMAPVEX16 Manitoba\\Processed_Results\\SV16M_V_CropBiomass_Vers4_with_coords_ML.csv'\n",
    "}\n",
    "\n",
    "# 输出文件路径\n",
    "output_dir = r'E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16'\n",
    "output_file = os.path.join(output_dir, 'InsituData_Point_ML.xlsx')\n",
    "\n",
    "# 确保输出目录存在\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 创建Excel写入器\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet_name, file_path in input_files.items():\n",
    "        print(f\"处理 {sheet_name} 数据集...\")\n",
    "        print(f\"  文件路径: {file_path}\")\n",
    "        \n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"  警告: 文件不存在，跳过\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # 根据文件扩展名读取数据\n",
    "            suffix = Path(file_path).suffix.lower()\n",
    "            if suffix == '.xlsx':\n",
    "                df = pd.read_excel(file_path)\n",
    "            elif suffix == '.csv':\n",
    "                df = pd.read_csv(file_path)\n",
    "            else:\n",
    "                print(f\"  警告: 不支持的文件格式 {suffix}，跳过\")\n",
    "                continue\n",
    "                \n",
    "            # 添加PFT列（如果不存在）\n",
    "            for col in PFT_COLUMNS:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = 0.0\n",
    "                    \n",
    "            # 根据数据集类型设置PFT值\n",
    "            if sheet_name == 'SMEX02':\n",
    "                # SMEX02: 根据Class列设置PFT值\n",
    "                if 'Class' in df.columns:\n",
    "                    # 设置所有PFT列为0\n",
    "                    for col in PFT_COLUMNS:\n",
    "                        df[col] = 0.0\n",
    "                    \n",
    "                    # 设置grassnat\n",
    "                    grassnat_mask = df['Class'] == 10\n",
    "                    df.loc[grassnat_mask, 'PFT_grassnat'] = 1.0\n",
    "                    print(f\"  设置 {grassnat_mask.sum()} 行为 PFT_grassnat=1\")\n",
    "                    \n",
    "                    # 设置grassman\n",
    "                    grassman_mask = df['Class'] == 12\n",
    "                    df.loc[grassman_mask, 'PFT_grassman'] = 1.0\n",
    "                    print(f\"  设置 {grassman_mask.sum()} 行为 PFT_grassman=1\")\n",
    "                else:\n",
    "                    print(\"  警告: SMEX02数据集中缺少'Class'列，无法设置PFT\")\n",
    "            else:\n",
    "                # 其他数据集: 设置PFT_grassman=1，其他=0\n",
    "                for col in PFT_COLUMNS:\n",
    "                    df[col] = 0.0\n",
    "                df['PFT_grassman'] = 1.0\n",
    "                print(f\"  设置所有行 PFT_grassman=1\")\n",
    "                \n",
    "            # 保存到Excel\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            print(f\"  成功保存 {len(df)} 行数据\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  处理 {sheet_name} 时出错: {str(e)}\")\n",
    "            # 创建空工作表\n",
    "            pd.DataFrame().to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            print(f\"  创建空工作表\")\n",
    "\n",
    "print(f\"\\n处理完成! 结果已保存至: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8332f5c2-dc31-46cd-a0c3-bad254aade46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Point_ML.xlsx\n",
      "  - SMEX02: 104行\n",
      "    替换了 42 行SM_Satellite数据\n",
      "  - CLASIC07: 22行\n",
      "    替换了 17 行SM_Satellite数据\n",
      "  - SMAPVEX08: 10行\n",
      "    替换了 10 行SM_Satellite数据\n",
      "    替换了 10 行LAI_Satellite数据\n",
      "  - SMAPVEX16: 1400行\n",
      "    替换了 1375 行SM_Satellite数据\n",
      "\n",
      "处理波段-极化组合: Ku-H\n",
      "加载模型: models/RFR_Ku_H-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 83 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 21 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 5 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 17 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 25 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1375 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-V\n",
      "加载模型: models/RFR_Ku_V-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 89 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 15 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 15 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 7 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 320 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1080 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-HV\n",
      "加载模型: models/RFR_Ku_HV-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 89 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 15 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 15 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 7 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 320 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1080 个样本\n",
      "\n",
      "处理波段-极化组合: X-H\n",
      "加载模型: models/RFR_X_H-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 80 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 24 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 5 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 17 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 25 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1375 个样本\n",
      "\n",
      "处理波段-极化组合: X-V\n",
      "加载模型: models/RFR_X_V-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 86 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 18 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 11 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 11 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 88 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1312 个样本\n",
      "\n",
      "处理波段-极化组合: X-HV\n",
      "加载模型: models/RFR_X_HV-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 86 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 18 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 11 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 11 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 88 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1312 个样本\n",
      "\n",
      "处理波段-极化组合: C-H\n",
      "加载模型: models/RFR_C_H-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 89 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 15 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 5 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 17 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 25 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 1375 个样本\n",
      "\n",
      "处理波段-极化组合: C-V\n",
      "加载模型: models/RFR_C_V-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 98 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 6 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 5 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 17 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 545 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 855 个样本\n",
      "\n",
      "处理波段-极化组合: C-HV\n",
      "加载模型: models/RFR_C_HV-pol_Weighted_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMEX02 移除了 98 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 6 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  CLASIC07 移除了 5 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 17 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX08 预测完成: 10 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    跳过PFT特征归一化（已归一化）\n",
      "  SMAPVEX16 移除了 545 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 855 个样本\n",
      "创建散点图...\n",
      "散点图已保存至: figures/AllSMAPInsituData_PointVWC_Scatter.png\n",
      "保存预测结果到: Ku_H (1423行)\n",
      "保存预测结果到: Ku_V (1112行)\n",
      "保存预测结果到: Ku_HV (1112行)\n",
      "保存预测结果到: X_H (1426行)\n",
      "保存预测结果到: X_V (1351行)\n",
      "保存预测结果到: X_HV (1351行)\n",
      "保存预测结果到: C_H (1417行)\n",
      "保存预测结果到: C_V (888行)\n",
      "保存预测结果到: C_HV (888行)\n",
      "所有预测结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\details_Point.xlsx\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 散点图（4个数据画在一块，写出n，按照波段-极化组合绘制为3 * 3）\n",
    "# 点形状及颜色：\n",
    "# SMEX02：*；CLASIC07：^；SMAPVEX08：+；SMAPVEX16：o\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "SHEET_NAMES = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "VWC_COLUMNS = {\n",
    "    'SMEX02': 'VWC-Field',\n",
    "    'CLASIC07': 'VWC (kg/m²)',\n",
    "    'SMAPVEX08': 'VWC',\n",
    "    'SMAPVEX16': 'PLANT_WATER_CONTENT_AREA'\n",
    "}\n",
    "\n",
    "# 标记和颜色设置\n",
    "MARKER_STYLES = {\n",
    "    'SMEX02': {'marker': '*', 'color': '#F8766D'},\n",
    "    'CLASIC07': {'marker': '^', 'facecolor': 'none', 'edgecolor': '#00BFC4'},\n",
    "    'SMAPVEX08': {'marker': '+', 'color': '#C77CFF'},\n",
    "    'SMAPVEX16': {'marker': 'o', 'facecolor': 'none', 'edgecolor': '#7CAE00'}\n",
    "}\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    加载并预处理Excel文件中的所有sheet\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): Excel文件路径\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含预处理后数据的字典，键为sheet名称\n",
    "    \"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 替换SM_Satellite和LAI_Satellite（如果存在地面实测数据）\n",
    "            if 'SM' in df.columns:\n",
    "                mask = df['SM'].notna()\n",
    "                df.loc[mask, 'SM_Satellite'] = df.loc[mask, 'SM']\n",
    "                print(f\"    替换了 {mask.sum()} 行SM_Satellite数据\")\n",
    "            \n",
    "            if 'LAI' in df.columns:\n",
    "                mask = df['LAI'].notna()\n",
    "                df.loc[mask, 'LAI_Satellite'] = df.loc[mask, 'LAI']\n",
    "                print(f\"    替换了 {mask.sum()} 行LAI_Satellite数据\")\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_features_for_model(band, pol):\n",
    "    \"\"\"\n",
    "    根据波段和极化类型获取特征列表（使用模型训练时的名称）\n",
    "    \n",
    "    参数:\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    list: 特征列名列表\n",
    "    \"\"\"\n",
    "    # 使用模型训练时的特征名称\n",
    "    features = [\n",
    "        'LAI',  # 注意：训练时使用\"LAI\"而不是\"LAI_Satellite\"\n",
    "        'SM',   # 注意：训练时使用\"SM\"而不是\"SM_Satellite\"\n",
    "        'Grass_man', \n",
    "        'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    # 添加VOD特征 - 根据模型类型\n",
    "    if pol == 'H' or pol == 'V':\n",
    "        # 单极化模型使用\"VOD\"\n",
    "        features.append('VOD')\n",
    "    elif pol == 'HV':\n",
    "        # 双极化模型使用\"VOD-Hpol\"和\"VOD-Vpol\"\n",
    "        features.extend(['VOD-Hpol', 'VOD-Vpol'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predict_vwc(data_dict, band, pol):\n",
    "    \"\"\"\n",
    "    使用指定模型预测VWC，包括特征归一化\n",
    "    \n",
    "    参数:\n",
    "    data_dict (dict): 包含所有sheet数据的字典\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含每个sheet预测结果的字典\n",
    "    \"\"\"\n",
    "    # 加载模型 - 使用新模型命名规则\n",
    "    model_path = f\"models/RFR_{band}_{pol}-pol_Weighted_Type1.pkl\"\n",
    "    print(f\"加载模型: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  模型文件不存在: {model_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        # 打印模型训练时的特征名称（如果可用）\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            print(f\"  模型训练特征: {list(model.feature_names_in_)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  加载模型失败: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "    # 获取特征列表\n",
    "    features = get_features_for_model(band, pol)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    predictions = {}\n",
    "    \n",
    "    for sheet, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # 创建特征映射（将数据列名映射到模型期望的特征名）\n",
    "        feature_mapping = {}\n",
    "        for feature in features:\n",
    "            # 特殊处理VOD特征\n",
    "            if feature == 'VOD':\n",
    "                # 单极化模型\n",
    "                if pol == 'H':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_H'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_H'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_H'] = 'VOD'\n",
    "                elif pol == 'V':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_V'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_V'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_V'] = 'VOD'\n",
    "            elif feature == 'VOD-Hpol':\n",
    "                # 双极化模型中的H极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_H'] = 'VOD-Hpol'\n",
    "            elif feature == 'VOD-Vpol':\n",
    "                # 双极化模型中的V极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_V'] = 'VOD-Vpol'\n",
    "            else:\n",
    "                # 其他特征映射 - 使用实际数据中的列名\n",
    "                if feature == 'LAI':\n",
    "                    feature_mapping['LAI_Satellite'] = 'LAI'\n",
    "                elif feature == 'SM':\n",
    "                    feature_mapping['SM_Satellite'] = 'SM'\n",
    "                elif feature == 'Grass_man':\n",
    "                    feature_mapping['PFT_grassman'] = 'Grass_man'\n",
    "                elif feature == 'Grass_nat':\n",
    "                    feature_mapping['PFT_grassnat'] = 'Grass_nat'\n",
    "                elif feature == 'Shrub_bd':\n",
    "                    feature_mapping['PFT_shrubbd'] = 'Shrub_bd'\n",
    "                elif feature == 'Shrub_be':\n",
    "                    feature_mapping['PFT_shrubbe'] = 'Shrub_be'\n",
    "                elif feature == 'Shrub_nd':\n",
    "                    feature_mapping['PFT_shrubnd'] = 'Shrub_nd'\n",
    "                elif feature == 'Shrub_ne':\n",
    "                    feature_mapping['PFT_shrubne'] = 'Shrub_ne'\n",
    "                elif feature == 'Tree_bd':\n",
    "                    feature_mapping['PFT_treebd'] = 'Tree_bd'\n",
    "                elif feature == 'Tree_be':\n",
    "                    feature_mapping['PFT_treebe'] = 'Tree_be'\n",
    "                elif feature == 'Tree_nd':\n",
    "                    feature_mapping['PFT_treend'] = 'Tree_nd'\n",
    "                elif feature == 'Tree_ne':\n",
    "                    feature_mapping['PFT_treene'] = 'Tree_ne'\n",
    "        \n",
    "        # 检查是否包含所有必要特征\n",
    "        missing_features = []\n",
    "        for data_feature in feature_mapping.keys():\n",
    "            if data_feature not in df.columns:\n",
    "                missing_features.append(data_feature)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"  {sheet} 缺少特征: {', '.join(missing_features)}\")\n",
    "            continue\n",
    "        \n",
    "        # 准备数据（使用重命名的特征）\n",
    "        X = df[list(feature_mapping.keys())].copy()\n",
    "        X.columns = [feature_mapping[col] for col in X.columns]\n",
    "        \n",
    "        # 确保特征顺序与模型期望一致\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            X = X[list(model.feature_names_in_)]\n",
    "        \n",
    "        # ========== 添加归一化处理 ==========\n",
    "        print(f\"  {sheet} 应用归一化处理...\")\n",
    "        \n",
    "        # 1. VOD特征归一化（除以2）\n",
    "        vod_features = ['VOD', 'VOD-Hpol', 'VOD-Vpol']\n",
    "        for vod_feature in vod_features:\n",
    "            if vod_feature in X.columns:\n",
    "                X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "                print(f\"    归一化 {vod_feature}: 除以2\")\n",
    "        \n",
    "        # 2. LAI特征归一化（除以6）\n",
    "        if 'LAI' in X.columns:\n",
    "            X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "            print(f\"    归一化 LAI: 除以6\")\n",
    "        \n",
    "        # 3. PFT特征归一化 - 跳过，因为已经归一化\n",
    "        # 根据要求，PFT特征不需要再次归一化\n",
    "        print(f\"    跳过PFT特征归一化（已归一化）\")\n",
    "        # =================================\n",
    "        \n",
    "        # 移除缺失值\n",
    "        initial_count = len(X)\n",
    "        X = X.dropna()\n",
    "        removed_count = initial_count - len(X)\n",
    "        if removed_count > 0:\n",
    "            print(f\"  {sheet} 移除了 {removed_count} 行包含缺失值的数据\")\n",
    "        \n",
    "        if X.empty:\n",
    "            print(f\"  {sheet} 无有效数据可用于预测\")\n",
    "            continue\n",
    "        \n",
    "        # 预测VWC\n",
    "        y_pred = model.predict(X)\n",
    "        predictions[sheet] = {\n",
    "            'actual': df.loc[X.index, VWC_COLUMNS[sheet]],\n",
    "            'predicted': y_pred,\n",
    "            'source': sheet,\n",
    "            'lat': df.loc[X.index, 'Latitude'],\n",
    "            'lon': df.loc[X.index, 'Longitude'],\n",
    "            'date': df.loc[X.index, 'Date']\n",
    "        }\n",
    "        print(f\"  {sheet} 预测完成: {len(y_pred)} 个样本\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def calculate_rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    计算RMSE\n",
    "    \n",
    "    参数:\n",
    "    actual (array-like): 实际值\n",
    "    predicted (array-like): 预测值\n",
    "    \n",
    "    返回:\n",
    "    float: RMSE值\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "\n",
    "def create_scatter_plots(all_predictions):\n",
    "    \"\"\"\n",
    "    创建3x3散点子图\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    print(\"创建散点图...\")\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('', fontsize=24, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            \n",
    "            # 获取当前组合的预测结果\n",
    "            predictions = all_predictions.get((band, pol), {})\n",
    "            \n",
    "            # 收集所有数据点\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            \n",
    "            # 绘制每个sheet的数据点\n",
    "            for sheet in SHEET_NAMES:\n",
    "                if sheet in predictions:\n",
    "                    actual = predictions[sheet]['actual']\n",
    "                    predicted = predictions[sheet]['predicted']\n",
    "                    \n",
    "                    # 添加到总集合\n",
    "                    all_actual.extend(actual)\n",
    "                    all_predicted.extend(predicted)\n",
    "                    \n",
    "                    # 绘制当前sheet的点\n",
    "                    if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "                        # 对CLASIC07、SMAPVEX16特殊处理：空心\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=MARKER_STYLES[sheet]['marker'],\n",
    "                            facecolor=MARKER_STYLES[sheet]['facecolor'],  # 内部无填充\n",
    "                            edgecolor=MARKER_STYLES[sheet]['edgecolor'],  # 使用边缘颜色\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            linewidths=1.0,  # 确保边框可见\n",
    "                            label=sheet\n",
    "                        )\n",
    "                    else:\n",
    "                        # 其他数据集保持原样\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=MARKER_STYLES[sheet]['marker'],\n",
    "                            color=MARKER_STYLES[sheet].get('color', MARKER_STYLES[sheet].get('edgecolor', None)),\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            label=sheet\n",
    "                        )\n",
    "            \n",
    "            # 如果没有数据，跳过\n",
    "            if not all_actual:\n",
    "                ax.text(0.5, 0.5, '无数据', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=16)\n",
    "                ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse = calculate_rmse(np.array(all_actual), np.array(all_predicted))\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            max_val = max(max(all_actual), max(all_predicted)) * 1.05\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7)\n",
    "            \n",
    "            # 设置坐标轴范围\n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if i == 2:  # 最后一行\n",
    "                ax.set_xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            if j == 0:  # 第一列\n",
    "                ax.set_ylabel('Predicted VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 添加标题和RMSE\n",
    "            ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "            ax.text(0.05, 0.95, f\"RMSE: {rmse:.3f} kg/m²\", \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=16,\n",
    "                    fontweight='bold',\n",
    "                    verticalalignment='top')\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 添加图例\n",
    "    handles, labels = [], []\n",
    "    for sheet in SHEET_NAMES:\n",
    "        style = MARKER_STYLES[sheet]\n",
    "        \n",
    "        if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "            # 为CLASIC07、SMAPVEX16创建空心图例\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w',\n",
    "                                     markerfacecolor=style['facecolor'],  # 内部白色\n",
    "                                     markeredgecolor=style['edgecolor'],  # 边缘颜色\n",
    "                                     markersize=10,\n",
    "                                     markeredgewidth=1.0))  # 边框宽度\n",
    "        else:\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w', \n",
    "                                     markerfacecolor=style.get('color', style.get('edgecolor')),\n",
    "                                     markeredgecolor=style.get('color', style.get('edgecolor')), \n",
    "                                     markersize=10))\n",
    "        labels.append(sheet)\n",
    "    \n",
    "    fig.legend(handles, labels, \n",
    "               loc='lower center', \n",
    "               ncol=4, \n",
    "               fontsize=12,\n",
    "               frameon=True,\n",
    "               fancybox=True,\n",
    "               shadow=True,\n",
    "               bbox_to_anchor=(0.5, 0.02))\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    # 保存图像 - 使用新路径\n",
    "    fig_path = \"figures/AllSMAPInsituData_PointVWC_Scatter.png\"\n",
    "    os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def save_prediction_details(all_predictions):\n",
    "    \"\"\"\n",
    "    将预测结果保存到Excel文件中\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_file = output_dir / \"details_Point.xlsx\"  # 修改输出文件名\n",
    "    \n",
    "    # 创建Excel写入器\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # 遍历所有波段和极化组合\n",
    "        for (band, pol), predictions in all_predictions.items():\n",
    "            if not predictions:\n",
    "                continue\n",
    "                \n",
    "            # 创建当前组合的数据框\n",
    "            all_data = []\n",
    "            \n",
    "            # 收集所有sheet的数据\n",
    "            for sheet, data in predictions.items():\n",
    "                # 创建当前sheet的数据框\n",
    "                sheet_df = pd.DataFrame({\n",
    "                    'Date': data['date'],\n",
    "                    'Latitude': data['lat'],\n",
    "                    'Longitude': data['lon'],\n",
    "                    'Actual_VWC': data['actual'],\n",
    "                    'Predicted_VWC': data['predicted'],\n",
    "                    'Source': data['source']\n",
    "                })\n",
    "                \n",
    "                # 添加波段和极化信息\n",
    "                sheet_df['Band'] = band\n",
    "                sheet_df['Polarization'] = pol\n",
    "                \n",
    "                all_data.append(sheet_df)\n",
    "            \n",
    "            # 合并所有数据\n",
    "            if all_data:\n",
    "                combined_df = pd.concat(all_data, ignore_index=True)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                sheet_name = f\"{band}_{pol}\"\n",
    "                combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                print(f\"保存预测结果到: {sheet_name} ({len(combined_df)}行)\")\n",
    "    \n",
    "    print(f\"所有预测结果已保存至: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # 输入文件路径 - 使用新路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Point_ML.xlsx\"\n",
    "    \n",
    "    # 加载并预处理数据\n",
    "    data_dict = load_and_preprocess_data(input_file)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            print(f\"\\n处理波段-极化组合: {band}-{pol}\")\n",
    "            predictions = predict_vwc(data_dict, band, pol)\n",
    "            all_predictions[(band, pol)] = predictions\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots(all_predictions)\n",
    "    \n",
    "    # 保存预测结果到Excel\n",
    "    save_prediction_details(all_predictions)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fd93f5-3526-484f-befb-0579f7dd65ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\n",
      "  - SMEX02: 16行\n",
      "    计算validCoverage权重\n",
      "    计算实际VWC: Actual_VWC = VWC-Field * validCoverage\n",
      "    替换了 14 行SM_Satellite数据\n",
      "  - CLASIC07: 18行\n",
      "    计算validCoverage权重\n",
      "    计算实际VWC: Actual_VWC = VWC (kg/m²) * validCoverage\n",
      "  - SMAPVEX08: 6行\n",
      "    计算validCoverage权重\n",
      "    计算实际VWC: Actual_VWC = VWC * validCoverage\n",
      "    替换了 6 行LAI_Satellite数据\n",
      "  - SMAPVEX16: 115行\n",
      "    计算validCoverage权重\n",
      "    计算实际VWC: Actual_VWC = PLANT_WATER_CONTENT_AREA * validCoverage\n",
      "\n",
      "处理波段-极化组合: Ku-H\n",
      "加载模型: models/RFR_Ku_H-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 7 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 9 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-V\n",
      "加载模型: models/RFR_Ku_V-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 6 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 92 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-HV\n",
      "加载模型: models/RFR_Ku_HV-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 6 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 92 个样本\n",
      "\n",
      "处理波段-极化组合: X-H\n",
      "加载模型: models/RFR_X_H-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 6 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 10 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: X-V\n",
      "加载模型: models/RFR_X_V-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 7 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 9 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 107 个样本\n",
      "\n",
      "处理波段-极化组合: X-HV\n",
      "加载模型: models/RFR_X_HV-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 7 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 9 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 107 个样本\n",
      "\n",
      "处理波段-极化组合: C-H\n",
      "加载模型: models/RFR_C_H-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: C-V\n",
      "加载模型: models/RFR_C_V-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 2 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 73 个样本\n",
      "\n",
      "处理波段-极化组合: C-HV\n",
      "加载模型: models/RFR_C_HV-pol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 2 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 73 个样本\n",
      "创建散点图...\n",
      "散点图已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\customizePFT_AllSMAPInsituData_VWC_Scatter.png\n",
      "保存预测结果到: Ku_H (145行)\n",
      "保存预测结果到: Ku_V (109行)\n",
      "保存预测结果到: Ku_HV (109行)\n",
      "保存预测结果到: X_H (146行)\n",
      "保存预测结果到: X_V (129行)\n",
      "保存预测结果到: X_HV (129行)\n",
      "保存预测结果到: C_H (141行)\n",
      "保存预测结果到: C_V (96行)\n",
      "保存预测结果到: C_HV (96行)\n",
      "所有预测结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\customizePFT_predictions_details.xlsx\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 2.仍然处理为像元区域验证,对比PFT，计算像元VWC，并且列出权重，即有效测量值占比，然后投入值预估\n",
    "# 因为数据都是农作物或草，没有灌木、树木，所以这里直接读取E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx的各个Sheet,将PFT_grassnat和PFT_grassman这两列相加获得新列validCoverage\n",
    "# 再将VWC修改，等于原先的VWC×validCoverage。使用新训练的模型进行预测\n",
    "# 绘制3*3的散点图\n",
    "# 不使用Weight\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "SHEET_NAMES = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "VWC_COLUMNS = {\n",
    "    'SMEX02': 'VWC-Field',\n",
    "    'CLASIC07': 'VWC (kg/m²)',\n",
    "    'SMAPVEX08': 'VWC',\n",
    "    'SMAPVEX16': 'PLANT_WATER_CONTENT_AREA'\n",
    "}\n",
    "\n",
    "# 标记和颜色设置\n",
    "MARKER_STYLES = {\n",
    "    'SMEX02': {'marker': 'x', 'color': '#F8766D'},\n",
    "    'CLASIC07': {'marker': '^', 'facecolor': 'none', 'edgecolor': '#00BFC4'},\n",
    "    'SMAPVEX08': {'marker': '+', 'color': '#C77CFF'},\n",
    "    'SMAPVEX16': {'marker': 'o', 'facecolor': 'none', 'edgecolor': '#7CAE00'}\n",
    "}\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    加载并预处理Excel文件中的所有sheet，计算validCoverage权重\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): Excel文件路径\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含预处理后数据的字典，键为sheet名称\n",
    "    \"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 计算validCoverage权重 (grassman + grassnat)/100\n",
    "            if 'grassman' in df.columns and 'grassnat' in df.columns:\n",
    "                df['validCoverage'] = (df['grassman'] + df['grassnat']) / 100.0\n",
    "                print(f\"    计算validCoverage权重\")\n",
    "            else:\n",
    "                print(f\"    警告: {sheet} 缺少grassman或grassnat列，无法计算validCoverage\")\n",
    "                df['validCoverage'] = 1.0  # 默认权重为1\n",
    "                \n",
    "            # 计算实际VWC = VWC值 * validCoverage\n",
    "            if VWC_COLUMNS[sheet] in df.columns:\n",
    "                df['Actual_VWC'] = df[VWC_COLUMNS[sheet]] * df['validCoverage']\n",
    "                print(f\"    计算实际VWC: Actual_VWC = {VWC_COLUMNS[sheet]} * validCoverage\")\n",
    "            else:\n",
    "                print(f\"    错误: {sheet} 缺少{VWC_COLUMNS[sheet]}列\")\n",
    "                df['Actual_VWC'] = 0.0\n",
    "                \n",
    "            # 替换SM_Satellite和LAI_Satellite（如果存在地面实测数据）\n",
    "            if 'SM' in df.columns:\n",
    "                mask = df['SM'].notna()\n",
    "                df.loc[mask, 'SM_Satellite'] = df.loc[mask, 'SM']\n",
    "                print(f\"    替换了 {mask.sum()} 行SM_Satellite数据\")\n",
    "            \n",
    "            if 'LAI' in df.columns:\n",
    "                mask = df['LAI'].notna()\n",
    "                df.loc[mask, 'LAI_Satellite'] = df.loc[mask, 'LAI']\n",
    "                print(f\"    替换了 {mask.sum()} 行LAI_Satellite数据\")\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_features_for_model(band, pol):\n",
    "    \"\"\"\n",
    "    根据波段和极化类型获取特征列表（使用模型训练时的名称）\n",
    "    \n",
    "    参数:\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    list: 特征列名列表\n",
    "    \"\"\"\n",
    "    # 使用模型训练时的特征名称\n",
    "    features = [\n",
    "        'LAI',  # 注意：训练时使用\"LAI\"而不是\"LAI_Satellite\"\n",
    "        'SM',   # 注意：训练时使用\"SM\"而不是\"SM_Satellite\"\n",
    "        'Grass_man', \n",
    "        'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    # 添加VOD特征 - 根据模型类型\n",
    "    if pol == 'H' or pol == 'V':\n",
    "        # 单极化模型使用\"VOD\"\n",
    "        features.append('VOD')\n",
    "    elif pol == 'HV':\n",
    "        # 双极化模型使用\"VOD-Hpol\"和\"VOD-Vpol\"\n",
    "        features.extend(['VOD-Hpol', 'VOD-Vpol'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predict_vwc(data_dict, band, pol):\n",
    "    \"\"\"\n",
    "    使用指定模型预测VWC，包括特征归一化和样本权重处理\n",
    "    \n",
    "    参数:\n",
    "    data_dict (dict): 包含所有sheet数据的字典\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含每个sheet预测结果的字典\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model_path = f\"models/RFR_{band}_{pol}-pol_Type1.pkl\"  # 不使用带权重的模型\n",
    "    print(f\"加载模型: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  模型文件不存在: {model_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        # 打印模型训练时的特征名称（如果可用）\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            print(f\"  模型训练特征: {list(model.feature_names_in_)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  加载模型失败: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "    # 获取特征列表\n",
    "    features = get_features_for_model(band, pol)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    predictions = {}\n",
    "    \n",
    "    for sheet, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # 创建特征映射（将数据列名映射到模型期望的特征名）\n",
    "        feature_mapping = {}\n",
    "        for feature in features:\n",
    "            # 特殊处理VOD特征\n",
    "            if feature == 'VOD':\n",
    "                # 单极化模型\n",
    "                if pol == 'H':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_H'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_H'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_H'] = 'VOD'\n",
    "                elif pol == 'V':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_V'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_V'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_V'] = 'VOD'\n",
    "            elif feature == 'VOD-Hpol':\n",
    "                # 双极化模型中的H极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_H'] = 'VOD-Hpol'\n",
    "            elif feature == 'VOD-Vpol':\n",
    "                # 双极化模型中的V极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_V'] = 'VOD-Vpol'\n",
    "            else:\n",
    "                # 其他特征映射\n",
    "                if feature == 'LAI':\n",
    "                    feature_mapping['LAI_Satellite'] = 'LAI'\n",
    "                elif feature == 'SM':\n",
    "                    feature_mapping['SM_Satellite'] = 'SM'\n",
    "                elif feature == 'Grass_man':\n",
    "                    feature_mapping['grassman'] = 'Grass_man'\n",
    "                elif feature == 'Grass_nat':\n",
    "                    feature_mapping['grassnat'] = 'Grass_nat'\n",
    "                elif feature == 'Shrub_bd':\n",
    "                    feature_mapping['shrubbd'] = 'Shrub_bd'\n",
    "                elif feature == 'Shrub_be':\n",
    "                    feature_mapping['shrubbe'] = 'Shrub_be'\n",
    "                elif feature == 'Shrub_nd':\n",
    "                    feature_mapping['shrubnd'] = 'Shrub_nd'\n",
    "                elif feature == 'Shrub_ne':\n",
    "                    feature_mapping['shrubne'] = 'Shrub_ne'\n",
    "                elif feature == 'Tree_bd':\n",
    "                    feature_mapping['treebd'] = 'Tree_bd'\n",
    "                elif feature == 'Tree_be':\n",
    "                    feature_mapping['treebe'] = 'Tree_be'\n",
    "                elif feature == 'Tree_nd':\n",
    "                    feature_mapping['treend'] = 'Tree_nd'\n",
    "                elif feature == 'Tree_ne':\n",
    "                    feature_mapping['treene'] = 'Tree_ne'\n",
    "        \n",
    "        # 检查是否包含所有必要特征\n",
    "        missing_features = []\n",
    "        for data_feature in feature_mapping.keys():\n",
    "            if data_feature not in df.columns:\n",
    "                missing_features.append(data_feature)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"  {sheet} 缺少特征: {', '.join(missing_features)}\")\n",
    "            continue\n",
    "        \n",
    "        # 准备数据（使用重命名的特征）\n",
    "        X = df[list(feature_mapping.keys())].copy()\n",
    "        X.columns = [feature_mapping[col] for col in X.columns]\n",
    "        \n",
    "        # 确保特征顺序与模型期望一致\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            X = X[list(model.feature_names_in_)]\n",
    "        \n",
    "        # ========== 添加归一化处理 ==========\n",
    "        print(f\"  {sheet} 应用归一化处理...\")\n",
    "        \n",
    "        # 1. VOD特征归一化（除以2）\n",
    "        vod_features = ['VOD', 'VOD-Hpol', 'VOD-Vpol']\n",
    "        for vod_feature in vod_features:\n",
    "            if vod_feature in X.columns:\n",
    "                X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "                print(f\"    归一化 {vod_feature}: 除以2\")\n",
    "        \n",
    "        # 2. LAI特征归一化（除以6）\n",
    "        if 'LAI' in X.columns:\n",
    "            X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "            print(f\"    归一化 LAI: 除以6\")\n",
    "        \n",
    "        # 3. PFT特征归一化（除以100）\n",
    "        pft_features = [\n",
    "            'Grass_man', 'Grass_nat',\n",
    "            'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "            'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "        ]\n",
    "        \n",
    "        for pft_feature in pft_features:\n",
    "            if pft_feature in X.columns:\n",
    "                X[pft_feature] = X[pft_feature] / 100.0\n",
    "                print(f\"    归一化 {pft_feature}: 除以100\")\n",
    "        # =================================\n",
    "        \n",
    "        # # 获取样本权重\n",
    "        # sample_weights = df.loc[X.index, 'validCoverage']\n",
    "        \n",
    "        # 移除缺失值\n",
    "        initial_count = len(X)\n",
    "        X = X.dropna()\n",
    "        # sample_weights = sample_weights.loc[X.index]  # 相应调整权重\n",
    "        removed_count = initial_count - len(X)\n",
    "        if removed_count > 0:\n",
    "            print(f\"  {sheet} 移除了 {removed_count} 行包含缺失值的数据\")\n",
    "        \n",
    "        if X.empty:\n",
    "            print(f\"  {sheet} 无有效数据可用于预测\")\n",
    "            continue\n",
    "        \n",
    "        # 预测VWC\n",
    "        y_pred = model.predict(X)\n",
    "        predictions[sheet] = {\n",
    "            'actual': df.loc[X.index, 'Actual_VWC'],  # 使用计算的实际VWC\n",
    "            'predicted': y_pred,\n",
    "            # 'weight': sample_weights.values,  # 保存权重\n",
    "            'source': sheet,\n",
    "            'row': df.loc[X.index, 'row'],\n",
    "            'col': df.loc[X.index, 'col'],\n",
    "            'lat': df.loc[X.index, 'Latitude'],\n",
    "            'lon': df.loc[X.index, 'Longitude'],\n",
    "            'date': df.loc[X.index, 'Date']\n",
    "        }\n",
    "        print(f\"  {sheet} 预测完成: {len(y_pred)} 个样本\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def calculate_rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    计算RMSE\n",
    "    \n",
    "    参数:\n",
    "    actual (array-like): 实际值\n",
    "    predicted (array-like): 预测值\n",
    "    \n",
    "    返回:\n",
    "    float: RMSE值\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "    \n",
    "def create_scatter_plots(all_predictions):\n",
    "    \"\"\"\n",
    "    创建3x3散点子图，使用权重调整点的大小\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    print(\"创建散点图...\")\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('', fontsize=24, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            \n",
    "            # 获取当前组合的预测结果\n",
    "            predictions = all_predictions.get((band, pol), {})\n",
    "            \n",
    "            # 收集所有数据点\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            \n",
    "            # 绘制每个sheet的数据点\n",
    "            for sheet in SHEET_NAMES:\n",
    "                if sheet in predictions:\n",
    "                    actual = predictions[sheet]['actual']\n",
    "                    predicted = predictions[sheet]['predicted']\n",
    "                    \n",
    "                    # 添加到总集合\n",
    "                    all_actual.extend(actual)\n",
    "                    all_predicted.extend(predicted)\n",
    "                    \n",
    "                    # 绘制当前sheet的点，使用权重调整点的大小\n",
    "                    style = MARKER_STYLES[sheet]\n",
    "                    \n",
    "                    # # 计算点的大小（权重 * 50 + 10，确保最小尺寸）\n",
    "                    # sizes = np.array(weights) * 50 + 10\n",
    "                    \n",
    "                    if 'facecolor' in style and 'edgecolor' in style:\n",
    "                        # 对需要空心处理的点\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=style['marker'],\n",
    "                            facecolor=style['facecolor'],\n",
    "                            edgecolor=style['edgecolor'],\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            linewidths=1.0,\n",
    "                            label=sheet\n",
    "                        )\n",
    "                    else:\n",
    "                        # 其他点\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=style['marker'],\n",
    "                            color=style['color'],\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            label=sheet\n",
    "                        )\n",
    "            \n",
    "            # 如果没有数据，跳过\n",
    "            if not all_actual:\n",
    "                ax.text(0.5, 0.5, 'No Data', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=16)\n",
    "                ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            # 计算RMSE\n",
    "            rmse = calculate_rmse(np.array(all_actual), np.array(all_predicted))\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            max_val = max(max(all_actual), max(all_predicted)) * 1.05\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7)\n",
    "            \n",
    "            # 设置坐标轴范围\n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if i == 2:  # 最后一行\n",
    "                ax.set_xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            if j == 0:  # 第一列\n",
    "                ax.set_ylabel('Predicted VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 添加标题和RMSE\n",
    "            ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "            ax.text(0.05, 0.95, f\"RMSE: {rmse:.3f} kg/m²\", \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=16,\n",
    "                    fontweight='bold',\n",
    "                    verticalalignment='top')\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 添加图例\n",
    "    handles, labels = [], []\n",
    "    for sheet in SHEET_NAMES:\n",
    "        style = MARKER_STYLES[sheet]\n",
    "        \n",
    "        if 'facecolor' in style and 'edgecolor' in style:\n",
    "            # 为空心点创建图例\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w',\n",
    "                                     markerfacecolor=style['facecolor'],  # 内部白色\n",
    "                                     markeredgecolor=style['edgecolor'],  # 边缘颜色\n",
    "                                     markersize=10,\n",
    "                                     markeredgewidth=1.0))  # 边框宽度\n",
    "        else:\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w', \n",
    "                                     markerfacecolor=style['color'],\n",
    "                                     markeredgecolor=style['color'], \n",
    "                                     markersize=10))\n",
    "        labels.append(sheet)\n",
    "    \n",
    "    fig.legend(handles, labels, \n",
    "               loc='lower center', \n",
    "               ncol=4, \n",
    "               fontsize=12,\n",
    "               frameon=True,\n",
    "               fancybox=True,\n",
    "               shadow=True,\n",
    "               bbox_to_anchor=(0.5, 0.02),\n",
    "               title=\"Dataset\")\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    # 保存图像\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = output_dir / \"customizePFT_AllSMAPInsituData_VWC_Scatter.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def save_prediction_details(all_predictions):\n",
    "    \"\"\"\n",
    "    将预测结果保存到Excel文件中，包含权重信息\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_file = output_dir / \"customizePFT_predictions_details.xlsx\"\n",
    "    \n",
    "    # 检查是否有数据可保存\n",
    "    has_data = False\n",
    "    for (band, pol), predictions in all_predictions.items():\n",
    "        if predictions and any(predictions.values()):\n",
    "            has_data = True\n",
    "            break\n",
    "    \n",
    "    if not has_data:\n",
    "        print(\"警告: 没有预测数据可保存\")\n",
    "        return\n",
    "    \n",
    "    # 创建Excel写入器\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # 遍历所有波段和极化组合\n",
    "        for (band, pol), predictions in all_predictions.items():\n",
    "            if not predictions or not any(predictions.values()):\n",
    "                print(f\"跳过空数据集: {band}-{pol}\")\n",
    "                continue\n",
    "                \n",
    "            # 创建当前组合的数据框\n",
    "            all_data = []\n",
    "            \n",
    "            # 收集所有sheet的数据\n",
    "            for sheet, data in predictions.items():\n",
    "                if not data or len(data.get('actual', [])) == 0:\n",
    "                    print(f\"  跳过空sheet: {sheet}\")\n",
    "                    continue\n",
    "                \n",
    "                # 创建当前sheet的数据框\n",
    "                sheet_df = pd.DataFrame({\n",
    "                    'Date': data['date'],\n",
    "                    'Row': data['row'],\n",
    "                    'Col': data['col'],\n",
    "                    'Latitude': data['lat'],\n",
    "                    'Longitude': data['lon'],\n",
    "                    'Actual_VWC': data['actual'],\n",
    "                    'Predicted_VWC': data['predicted'],\n",
    "                    # 'Weight': data['weight'],\n",
    "                    'Source': data['source']\n",
    "                })\n",
    "                \n",
    "                # 添加波段和极化信息\n",
    "                sheet_df['Band'] = band\n",
    "                sheet_df['Polarization'] = pol\n",
    "                \n",
    "                all_data.append(sheet_df)\n",
    "            \n",
    "            # 合并所有数据\n",
    "            if all_data:\n",
    "                combined_df = pd.concat(all_data, ignore_index=True)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                sheet_name = f\"{band}_{pol}\"\n",
    "                combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                print(f\"保存预测结果到: {sheet_name} ({len(combined_df)}行)\")\n",
    "    \n",
    "    print(f\"所有预测结果已保存至: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\"\n",
    "    \n",
    "    # 加载并预处理数据，计算validCoverage和实际VWC\n",
    "    data_dict = load_and_preprocess_data(input_file)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            print(f\"\\n处理波段-极化组合: {band}-{pol}\")\n",
    "            predictions = predict_vwc(data_dict, band, pol)\n",
    "            all_predictions[(band, pol)] = predictions\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots(all_predictions)\n",
    "    \n",
    "    # 保存预测结果到Excel\n",
    "    save_prediction_details(all_predictions)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b50fb-6672-447a-935c-33f2f17e990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3e4438-ae1b-4636-9eb7-260da35c2e56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 补充：训练数据的VOD-LFMC、VOD-AGB散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6eec1a-2592-4074-bd51-960ef4eec0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_Ku_H_Correlation.png\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_Ku_V_Correlation.png\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_X_H_Correlation.png\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_X_V_Correlation.png\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_C_H_Correlation.png\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_C_V_Correlation.png\n",
      "所有处理完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 文件路径\n",
    "file_path = r'E:\\Matlab\\EX2025\\AuxiliaryData\\VWC_ML_Data.xlsx'\n",
    "\n",
    "# 验证文件是否存在\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"文件未找到: {file_path}\")\n",
    "\n",
    "# 创建保存目录\n",
    "save_dir = r'E:\\文章\\HUITU\\Fig'\n",
    "os.makedirs(save_dir, exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# 获取所有sheet名称\n",
    "all_sheets = pd.ExcelFile(file_path).sheet_names\n",
    "\n",
    "# 正则表达式匹配目标sheet命名格式\n",
    "pattern = r'VOD_(Ku|X|C)_(H|V)pol_Asc_Cleaned_Type1'\n",
    "target_sheets = [s for s in all_sheets if re.match(pattern, s)]\n",
    "\n",
    "# 没有匹配sheet时的处理\n",
    "if not target_sheets:\n",
    "    raise ValueError(\"未找到符合命名规则的sheet\")\n",
    "\n",
    "# 波段和极化方式映射\n",
    "band_map = {\n",
    "    'Ku': 'Ku',\n",
    "    'X': 'X',\n",
    "    'C': 'C'\n",
    "}\n",
    "pol_map = {\n",
    "    'H': 'Horizontal',\n",
    "    'V': 'Vertical'\n",
    "}\n",
    "\n",
    "# 设置全局绘图风格\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 遍历所有匹配的sheet\n",
    "for sheet_name in target_sheets:\n",
    "    # 提取波段和极化方式\n",
    "    parts = sheet_name.split('_')\n",
    "    band = parts[1]  # Ku/X/C\n",
    "    pol = parts[2][0]  # H/V\n",
    "    \n",
    "    # 确定目标列名 (例如: VOD_Ku_Hpol_Asc)\n",
    "    target_col = f'VOD_{band}_{pol}pol_Asc'\n",
    "    \n",
    "    # 获取波段和极化的友好名称\n",
    "    band_name = band_map.get(band, band)\n",
    "    pol_name = pol_map.get(pol, pol)\n",
    "    \n",
    "    try:\n",
    "        # 读取sheet数据\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # 检查所需列是否存在\n",
    "        required_cols = [target_col, 'LFMC', 'AGB']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"Sheet '{sheet_name}'缺少列: {missing_cols}\")\n",
    "            continue\n",
    "            \n",
    "        # 创建带两个子图的图像\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle(f'{band_name}-Band, {pol_name} Polarization', \n",
    "                    fontsize=20, fontweight='bold', y=1.02)\n",
    "        \n",
    "        # ============= 左图: VOD vs LFMC =============\n",
    "        ax1 = axes[0]\n",
    "        x1 = df['LFMC'].values\n",
    "        y1 = df[target_col].values\n",
    "        \n",
    "        # 删除NaN值\n",
    "        valid_idx1 = ~np.isnan(x1) & ~np.isnan(y1)\n",
    "        x1_clean = x1[valid_idx1]\n",
    "        y1_clean = y1[valid_idx1]\n",
    "        \n",
    "        # 绘制散点图\n",
    "        sns.scatterplot(x=x1_clean, y=y1_clean, ax=ax1, alpha=0.7, edgecolor='w', s=60)\n",
    "        \n",
    "        if len(x1_clean) > 3:  # 确保有足够的数据点\n",
    "            # 按x值排序确保升序排列\n",
    "            sort_idx = np.argsort(x1_clean)\n",
    "            x1_sorted = x1_clean[sort_idx]\n",
    "            y1_sorted = y1_clean[sort_idx]\n",
    "            \n",
    "            # 使用UnivariateSpline替代smoothing_spline\n",
    "            # 它更灵活，不易出错\n",
    "            try:\n",
    "                spline1 = UnivariateSpline(x1_sorted, y1_sorted, s=len(x1_sorted)*3)\n",
    "                x1_smooth = np.linspace(min(x1_sorted), max(x1_sorted), 300)\n",
    "                y1_smooth = spline1(x1_smooth)\n",
    "                \n",
    "                # 计算R²\n",
    "                y1_pred = spline1(x1_sorted)\n",
    "                r2_1 = r2_score(y1_sorted, y1_pred)\n",
    "                \n",
    "                # 绘制拟合线\n",
    "                ax1.plot(x1_smooth, y1_smooth, 'r-', lw=3, alpha=0.8)\n",
    "                \n",
    "                # 添加R²值\n",
    "                ax1.text(0.05, 0.95, f'$R^2$ = {r2_1:.2f}', \n",
    "                         transform=ax1.transAxes, \n",
    "                         fontsize=14,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            except Exception as e:\n",
    "                print(f\"LFMC拟合失败: {str(e)}\")\n",
    "        \n",
    "        # 设置轴标签和网格\n",
    "        ax1.set_xlabel('LFMC (%)', fontsize=14)\n",
    "        ax1.set_ylabel('VOD', fontsize=14)\n",
    "        ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # ============= 右图: VOD vs AGB =============\n",
    "        ax2 = axes[1]\n",
    "        x2 = df['AGB'].values\n",
    "        y2 = df[target_col].values\n",
    "        \n",
    "        # 删除NaN值\n",
    "        valid_idx2 = ~np.isnan(x2) & ~np.isnan(y2)\n",
    "        x2_clean = x2[valid_idx2]\n",
    "        y2_clean = y2[valid_idx2]\n",
    "        \n",
    "        # 绘制散点图\n",
    "        sns.scatterplot(x=x2_clean, y=y2_clean, ax=ax2, alpha=0.7, edgecolor='w', s=60)\n",
    "        \n",
    "        if len(x2_clean) > 3:  # 确保有足够的数据点\n",
    "            # 按x值排序确保升序排列\n",
    "            sort_idx = np.argsort(x2_clean)\n",
    "            x2_sorted = x2_clean[sort_idx]\n",
    "            y2_sorted = y2_clean[sort_idx]\n",
    "            \n",
    "            try:\n",
    "                spline2 = UnivariateSpline(x2_sorted, y2_sorted, s=len(x2_sorted)*3)\n",
    "                x2_smooth = np.linspace(min(x2_sorted), max(x2_sorted), 300)\n",
    "                y2_smooth = spline2(x2_smooth)\n",
    "                \n",
    "                # 计算R²\n",
    "                y2_pred = spline2(x2_sorted)\n",
    "                r2_2 = r2_score(y2_sorted, y2_pred)\n",
    "                \n",
    "                # 绘制拟合线\n",
    "                ax2.plot(x2_smooth, y2_smooth, 'r-', lw=3, alpha=0.8)\n",
    "                \n",
    "                # 添加R²值\n",
    "                ax2.text(0.05, 0.95, f'$R^2$ = {r2_2:.2f}', \n",
    "                         transform=ax2.transAxes, \n",
    "                         fontsize=14,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            except Exception as e:\n",
    "                print(f\"AGB拟合失败: {str(e)}\")\n",
    "        \n",
    "        # 设置轴标签和网格\n",
    "        ax2.set_xlabel('AGB (Mg/ha)', fontsize=14)\n",
    "        ax2.set_ylabel('')  # 共用同一个y轴标签\n",
    "        ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # 自动调整布局\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像\n",
    "        save_path = os.path.join(save_dir, f'VOD_{band}_{pol}_Correlation.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # 关闭图形释放内存\n",
    "        print(f\"成功保存图像: {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理sheet '{sheet_name}'时出错: {str(e)}\")\n",
    "        plt.close()  # 确保出错时关闭图形\n",
    "\n",
    "print(\"所有处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba962df-ce74-4288-aa77-ea4403af4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试：单独分析LFMC和VOD，为什么相关性这么低，不利于后续的训练，尝试去除整体趋势异常值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8d5ef-93cd-4d6e-95df-c7e3c4ad883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除LFMC的异常值（3个标准差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66d8f70-fc1c-44cc-aaa1-9ad503927816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VOD_Ku_Hpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 113.42, 标准差: 36.62, 上限: 223.30\n",
      "处理前数据点: 26692\n",
      "发现异常值: 357个\n",
      "处理后有效点: 26335\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_Ku_H_Correlation_Cleaned.png\n",
      "[VOD_Ku_Vpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 114.64, 标准差: 36.95, 上限: 225.49\n",
      "处理前数据点: 18884\n",
      "发现异常值: 250个\n",
      "处理后有效点: 18634\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_Ku_V_Correlation_Cleaned.png\n",
      "[VOD_X_Hpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 113.58, 标准差: 36.65, 上限: 223.51\n",
      "处理前数据点: 27187\n",
      "发现异常值: 358个\n",
      "处理后有效点: 26829\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_X_H_Correlation_Cleaned.png\n",
      "[VOD_X_Vpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 113.83, 标准差: 36.58, 上限: 223.58\n",
      "处理前数据点: 23909\n",
      "发现异常值: 319个\n",
      "处理后有效点: 23590\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_X_V_Correlation_Cleaned.png\n",
      "[VOD_C_Hpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 113.55, 标准差: 36.64, 上限: 223.47\n",
      "处理前数据点: 27114\n",
      "发现异常值: 365个\n",
      "处理后有效点: 26749\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_C_H_Correlation_Cleaned.png\n",
      "[VOD_C_Vpol_Asc_Cleaned_Type1] LFMC处理 - 均值: 113.11, 标准差: 36.55, 上限: 222.76\n",
      "处理前数据点: 22223\n",
      "发现异常值: 302个\n",
      "处理后有效点: 21921\n",
      "成功保存图像: E:\\文章\\HUITU\\Fig\\VOD_C_V_Correlation_Cleaned.png\n",
      "所有处理完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 文件路径\n",
    "file_path = r'E:\\Matlab\\EX2025\\AuxiliaryData\\VWC_ML_Data.xlsx'\n",
    "\n",
    "# 验证文件是否存在\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"文件未找到: {file_path}\")\n",
    "\n",
    "# 创建保存目录\n",
    "save_dir = r'E:\\文章\\HUITU\\Fig'\n",
    "os.makedirs(save_dir, exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# 获取所有sheet名称\n",
    "all_sheets = pd.ExcelFile(file_path).sheet_names\n",
    "\n",
    "# 正则表达式匹配目标sheet命名格式\n",
    "pattern = r'VOD_(Ku|X|C)_(H|V)pol_Asc_Cleaned_Type1'\n",
    "target_sheets = [s for s in all_sheets if re.match(pattern, s)]\n",
    "\n",
    "# 没有匹配sheet时的处理\n",
    "if not target_sheets:\n",
    "    raise ValueError(\"未找到符合命名规则的sheet\")\n",
    "\n",
    "# 波段和极化方式映射\n",
    "band_map = {\n",
    "    'Ku': 'Ku',\n",
    "    'X': 'X',\n",
    "    'C': 'C'\n",
    "}\n",
    "pol_map = {\n",
    "    'H': 'Horizontal',\n",
    "    'V': 'Vertical'\n",
    "}\n",
    "\n",
    "# 设置全局绘图风格\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 遍历所有匹配的sheet\n",
    "for sheet_name in target_sheets:\n",
    "    # 提取波段和极化方式\n",
    "    parts = sheet_name.split('_')\n",
    "    band = parts[1]  # Ku/X/C\n",
    "    pol = parts[2][0]  # H/V\n",
    "    \n",
    "    # 确定目标列名 (例如: VOD_Ku_Hpol_Asc)\n",
    "    target_col = f'VOD_{band}_{pol}pol_Asc'\n",
    "    \n",
    "    # 获取波段和极化的友好名称\n",
    "    band_name = band_map.get(band, band)\n",
    "    pol_name = pol_map.get(pol, pol)\n",
    "    \n",
    "    try:\n",
    "        # 读取sheet数据\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # 检查所需列是否存在\n",
    "        required_cols = [target_col, 'LFMC', 'AGB']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"Sheet '{sheet_name}'缺少列: {missing_cols}\")\n",
    "            continue\n",
    "        \n",
    "        # ======== 新增：LFMC异常值处理 ========\n",
    "        if 'LFMC' in df.columns:\n",
    "            # 计算均值和标准差（忽略NaN）\n",
    "            lfmc_mean = df['LFMC'].mean()\n",
    "            lfmc_std = df['LFMC'].std()\n",
    "            \n",
    "            # 计算异常阈值（仅上限）\n",
    "            upper_limit = lfmc_mean + 3 * lfmc_std\n",
    "            \n",
    "            # 打印诊断信息\n",
    "            print(f\"[{sheet_name}] LFMC处理 - 均值: {lfmc_mean:.2f}, 标准差: {lfmc_std:.2f}, 上限: {upper_limit:.2f}\")\n",
    "            print(f\"处理前数据点: {len(df)}\")\n",
    "            \n",
    "            # 创建异常值掩码\n",
    "            is_outlier = df['LFMC'] > upper_limit\n",
    "            \n",
    "            # 打印异常值数量\n",
    "            print(f\"发现异常值: {is_outlier.sum()}个\")\n",
    "            \n",
    "            # 将异常值替换为NaN\n",
    "            df.loc[is_outlier, 'LFMC'] = np.nan\n",
    "            \n",
    "            print(f\"处理后有效点: {len(df) - is_outlier.sum()}\")\n",
    "        \n",
    "        # ======== 异常值处理结束 ========\n",
    "        \n",
    "        # 创建带两个子图的图像\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle(f'{band_name}-Band, {pol_name} Polarization', \n",
    "                    fontsize=20, fontweight='bold', y=1.02)\n",
    "        \n",
    "        # ============= 左图: VOD vs LFMC =============\n",
    "        ax1 = axes[0]\n",
    "        x1 = df['LFMC'].values\n",
    "        y1 = df[target_col].values\n",
    "        \n",
    "        # 删除NaN值\n",
    "        valid_idx1 = ~np.isnan(x1) & ~np.isnan(y1)\n",
    "        x1_clean = x1[valid_idx1]\n",
    "        y1_clean = y1[valid_idx1]\n",
    "        \n",
    "        # 绘制散点图\n",
    "        sns.scatterplot(x=x1_clean, y=y1_clean, ax=ax1, alpha=0.7, edgecolor='w', s=60)\n",
    "        \n",
    "        if len(x1_clean) > 3:  # 确保有足够的数据点\n",
    "            # 按x值排序确保升序排列\n",
    "            sort_idx = np.argsort(x1_clean)\n",
    "            x1_sorted = x1_clean[sort_idx]\n",
    "            y1_sorted = y1_clean[sort_idx]\n",
    "            \n",
    "            # 使用UnivariateSpline替代smoothing_spline\n",
    "            # 它更灵活，不易出错\n",
    "            try:\n",
    "                spline1 = UnivariateSpline(x1_sorted, y1_sorted, s=len(x1_sorted)*3)\n",
    "                x1_smooth = np.linspace(min(x1_sorted), max(x1_sorted), 300)\n",
    "                y1_smooth = spline1(x1_smooth)\n",
    "                \n",
    "                # 计算R²\n",
    "                y1_pred = spline1(x1_sorted)\n",
    "                r2_1 = r2_score(y1_sorted, y1_pred)\n",
    "                \n",
    "                # 绘制拟合线\n",
    "                ax1.plot(x1_smooth, y1_smooth, 'r-', lw=3, alpha=0.8)\n",
    "                \n",
    "                # 添加R²值\n",
    "                ax1.text(0.05, 0.95, f'$R^2$ = {r2_1:.2f}', \n",
    "                         transform=ax1.transAxes, \n",
    "                         fontsize=14,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            except Exception as e:\n",
    "                print(f\"LFMC拟合失败: {str(e)}\")\n",
    "        \n",
    "        # 设置轴标签和网格\n",
    "        ax1.set_xlabel('LFMC (%)', fontsize=14)\n",
    "        ax1.set_ylabel('VOD', fontsize=14)\n",
    "        ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # ============= 右图: VOD vs AGB =============\n",
    "        ax2 = axes[1]\n",
    "        x2 = df['AGB'].values\n",
    "        y2 = df[target_col].values\n",
    "        \n",
    "        # 删除NaN值\n",
    "        valid_idx2 = ~np.isnan(x2) & ~np.isnan(y2)\n",
    "        x2_clean = x2[valid_idx2]\n",
    "        y2_clean = y2[valid_idx2]\n",
    "        \n",
    "        # 绘制散点图\n",
    "        sns.scatterplot(x=x2_clean, y=y2_clean, ax=ax2, alpha=0.7, edgecolor='w', s=60)\n",
    "        \n",
    "        if len(x2_clean) > 3:  # 确保有足够的数据点\n",
    "            # 按x值排序确保升序排列\n",
    "            sort_idx = np.argsort(x2_clean)\n",
    "            x2_sorted = x2_clean[sort_idx]\n",
    "            y2_sorted = y2_clean[sort_idx]\n",
    "            \n",
    "            try:\n",
    "                spline2 = UnivariateSpline(x2_sorted, y2_sorted, s=len(x2_sorted)*3)\n",
    "                x2_smooth = np.linspace(min(x2_sorted), max(x2_sorted), 300)\n",
    "                y2_smooth = spline2(x2_smooth)\n",
    "                \n",
    "                # 计算R²\n",
    "                y2_pred = spline2(x2_sorted)\n",
    "                r2_2 = r2_score(y2_sorted, y2_pred)\n",
    "                \n",
    "                # 绘制拟合线\n",
    "                ax2.plot(x2_smooth, y2_smooth, 'r-', lw=3, alpha=0.8)\n",
    "                \n",
    "                # 添加R²值\n",
    "                ax2.text(0.05, 0.95, f'$R^2$ = {r2_2:.2f}', \n",
    "                         transform=ax2.transAxes, \n",
    "                         fontsize=14,\n",
    "                         verticalalignment='top',\n",
    "                         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            except Exception as e:\n",
    "                print(f\"AGB拟合失败: {str(e)}\")\n",
    "        \n",
    "        # 设置轴标签和网格\n",
    "        ax2.set_xlabel('AGB (Mg/ha)', fontsize=14)\n",
    "        ax2.set_ylabel('')  # 共用同一个y轴标签\n",
    "        ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # 自动调整布局\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像\n",
    "        save_path = os.path.join(save_dir, f'VOD_{band}_{pol}_Correlation_Cleaned.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # 关闭图形释放内存\n",
    "        print(f\"成功保存图像: {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理sheet '{sheet_name}'时出错: {str(e)}\")\n",
    "        plt.close()  # 确保出错时关闭图形\n",
    "\n",
    "print(\"所有处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4212a80-af99-49f7-b4ca-2102ec8c5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我感觉这个确实是做不到……"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d292927-b8e5-49f5-a6f0-8aae4b698365",
   "metadata": {},
   "source": [
    "# .使用高度清洗的模型进行估算(_purify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85bdfd-745d-4100-9596-9b7973cb69f5",
   "metadata": {},
   "source": [
    "2017-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b54c1a7-559d-4c07-891a-1e0896724813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\n",
      "  - CornVegMeasured: 8行\n",
      "  - CornVegFitting: 64行\n",
      "  - OatVegMeasured: 7行\n",
      "  - OatVegFitting: 64行\n",
      "加载文件: E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\n",
      "  - GrassVWC: 13行\n",
      "创建组合时间序列图...\n",
      "为 CornVegFitting 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 CornVegFitting 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 OatVegFitting 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  使用实测LAI替换了 63 行数据\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-H VWC...\n",
      "加载模型: models/RFR_Ku_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-V VWC...\n",
      "加载模型: models/RFR_Ku_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 Ku-HV VWC...\n",
      "加载模型: models/RFR_Ku_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成ku_vod_H的时间序列插值\n",
      "  已完成ku_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-H VWC...\n",
      "加载模型: models/RFR_X_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-V VWC...\n",
      "加载模型: models/RFR_X_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 X-HV VWC...\n",
      "加载模型: models/RFR_X_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成x_vod_H的时间序列插值\n",
      "  已完成x_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-H VWC...\n",
      "加载模型: models/RFR_C_Hpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-V VWC...\n",
      "加载模型: models/RFR_C_Vpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "为 GrassVWC 预测 C-HV VWC...\n",
      "加载模型: models/RFR_C_HVpol_Purify_Type1.pkl\n",
      "  模型期望特征: ['VODHpol', 'VODVpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  已完成c_vod_H的时间序列插值\n",
      "  已完成c_vod_V的时间序列插值\n",
      "  已完成LAI_Satellite的时间序列插值\n",
      "  已完成SM_Satellite的时间序列插值\n",
      "  已完成grassman的时间序列插值\n",
      "  已完成grassnat的时间序列插值\n",
      "  已完成shrubbd的时间序列插值\n",
      "  已完成shrubbe的时间序列插值\n",
      "  已完成shrubnd的时间序列插值\n",
      "  已完成shrubne的时间序列插值\n",
      "  已完成treebd的时间序列插值\n",
      "  已完成treebe的时间序列插值\n",
      "  已完成treend的时间序列插值\n",
      "  已完成treene的时间序列插值\n",
      "组合时间序列图已保存至: figures\\Combined_VWC_Time_Series_Purify.png\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_Ku_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_X_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\CornVegMeasured_C_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_Ku_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_X_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\OatVegMeasured_C_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_Ku_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_X_HV_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_H_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_V_predictions_Purify.csv\n",
      "保存预测结果至: prediction_results\\GrassVWC_C_HV_predictions_Purify.csv\n",
      "保存模型评估指标至: prediction_results\\model_metrics_Purify.csv\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.interpolate import make_interp_spline  # 导入样条插值函数\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "BAND_COLORS = {\n",
    "    'Ku': '#1f77b4',  # 蓝色\n",
    "    'X': '#ff7f0e',   # 橙色\n",
    "    'C': '#2ca02c'    # 绿色\n",
    "}\n",
    "POLS = ['H', 'V', 'HV']\n",
    "POL_LINESTYLES = {\n",
    "    'H': '-',     # 实线\n",
    "    'V': '--',    # 虚线\n",
    "    'HV': ':'     # 点线\n",
    "}\n",
    "POL_MARKERS = {\n",
    "    'H': '+',  # 加号\n",
    "    'V': '^',  # 三角形\n",
    "    'HV': 's'  # 正方形\n",
    "}\n",
    "POL_LABELS = {\n",
    "    'H': 'H-Pol',\n",
    "    'V': 'V-Pol',\n",
    "    'HV': 'H&V-Pol'  # 修改这里\n",
    "}\n",
    "\n",
    "# 植被类型映射\n",
    "VEGETATION_TYPES = {\n",
    "    'CornVegMeasured': 'Corn (2017)',\n",
    "    'OatVegMeasured': 'Oat (2017)',\n",
    "    'GrassVWC': 'Grass (2018)'\n",
    "}\n",
    "\n",
    "# 实测与拟合数据映射\n",
    "FITTING_MAPPING = {\n",
    "    'CornVegMeasured': 'CornVegFitting',\n",
    "    'OatVegMeasured': 'OatVegFitting',\n",
    "    'GrassVWC': 'GrassVWC'  # 2018年没有拟合数据\n",
    "}\n",
    "\n",
    "# 实测VWC列名映射\n",
    "ACTUAL_COL_MAPPING = {\n",
    "    'CornVegMeasured': 'total_VWC(kg/m2)',\n",
    "    'OatVegMeasured': 'total_VWC(kg/m2)',\n",
    "    'GrassVWC': 'vegetation water content(kg/m2)'\n",
    "}\n",
    "\n",
    "# 实测数据样式\n",
    "ACTUAL_STYLE = {\n",
    "    'color': 'black',\n",
    "    'marker': 'o',\n",
    "    'markersize': 8,\n",
    "    'markerfacecolor': 'none',\n",
    "    'markeredgewidth': 1.5,\n",
    "    'label': 'Measured'\n",
    "}\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"加载Excel文件中的所有工作表\"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    # 获取所有工作表名称\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    sheet_names = xl.sheet_names\n",
    "    \n",
    "    for sheet in sheet_names:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 确保日期是datetime类型\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def predict_vwc_for_sheet(df, band, pol):\n",
    "    \"\"\"\n",
    "    使用机器学习模型预测VWC，确保特征名称匹配\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model_path = f\"models/RFR_{band}_{pol}pol_Purify_Type1.pkl\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"警告: 模型文件不存在: {model_path}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"加载模型: {model_path}\")\n",
    "        \n",
    "        # 获取模型期望的特征名称\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            expected_features = list(model.feature_names_in_)\n",
    "            print(f\"  模型期望特征: {expected_features}\")\n",
    "        else:\n",
    "            print(\"  警告: 模型没有feature_names_in_属性\")\n",
    "            expected_features = []\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型失败: {str(e)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 1. 优先使用地面实测数据替换卫星数据\n",
    "    if 'SM' in df.columns:\n",
    "        sm_mask = df['SM'].notna() & (df['SM'] > 0)\n",
    "        if sm_mask.any():\n",
    "            df.loc[sm_mask, 'SM_Satellite'] = df.loc[sm_mask, 'SM']\n",
    "            print(f\"  使用实测SM替换了 {sm_mask.sum()} 行数据\")\n",
    "    \n",
    "    if 'LAI' in df.columns:\n",
    "        lai_mask = df['LAI'].notna() & (df['LAI'] > 0)\n",
    "        if lai_mask.any():\n",
    "            df.loc[lai_mask, 'LAI_Satellite'] = df.loc[lai_mask, 'LAI']\n",
    "            print(f\"  使用实测LAI替换了 {lai_mask.sum()} 行数据\")\n",
    "    \n",
    "    # 2. 根据波段和极化组合确定特征映射\n",
    "    feature_mapping = {}\n",
    "    \n",
    "    # Ku波段\n",
    "    if band == 'Ku':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'ku_vod_H': 'VODHpol',\n",
    "                'ku_vod_V': 'VODVpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # X波段\n",
    "    elif band == 'X':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'x_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'x_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'x_vod_H': 'VODHpol',\n",
    "                'x_vod_V': 'VODVpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # C波段\n",
    "    elif band == 'C':\n",
    "        if pol == 'H':\n",
    "            feature_mapping = {\n",
    "                'c_vod_H': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'V':\n",
    "            feature_mapping = {\n",
    "                'c_vod_V': 'VOD',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "        elif pol == 'HV':\n",
    "            feature_mapping = {\n",
    "                'c_vod_H': 'VODHpol',\n",
    "                'c_vod_V': 'VODVpol',\n",
    "                'LAI_Satellite': 'LAI',\n",
    "                'SM_Satellite': 'SM',\n",
    "                'grassman': 'Grass_man',\n",
    "                'grassnat': 'Grass_nat',\n",
    "                'shrubbd': 'Shrub_bd',\n",
    "                'shrubbe': 'Shrub_be',\n",
    "                'shrubnd': 'Shrub_nd',\n",
    "                'shrubne': 'Shrub_ne',\n",
    "                'treebd': 'Tree_bd',\n",
    "                'treebe': 'Tree_be',\n",
    "                'treend': 'Tree_nd',\n",
    "                'treene': 'Tree_ne'\n",
    "            }\n",
    "    \n",
    "    # 时间序列插值\n",
    "    if 'Date' in df.columns and not df.empty:\n",
    "        # 确保按日期排序\n",
    "        df = df.sort_values('Date')\n",
    "        \n",
    "        # 确定需要插值的特征列\n",
    "        interpolate_cols = list(feature_mapping.keys())\n",
    "        valid_cols = [col for col in interpolate_cols if col in df.columns]\n",
    "        \n",
    "        # 设置时间索引\n",
    "        date_index = pd.DatetimeIndex(df['Date'])\n",
    "        df_temp = df.set_index('Date')\n",
    "        \n",
    "        # 生成完整的时间序列范围\n",
    "        full_range = pd.date_range(start=date_index.min(), end=date_index.max(), freq='D')\n",
    "        df_full = df_temp.reindex(full_range)\n",
    "        \n",
    "        # 对特征列进行线性插值\n",
    "        for col in valid_cols:\n",
    "            df_full[col] = df_full[col].interpolate(method='time', limit_direction='both')\n",
    "            print(f\"  已完成{col}的时间序列插值\")\n",
    "        \n",
    "        # 重置索引\n",
    "        df = df_full.reset_index().rename(columns={'index': 'Date'})\n",
    "    else:\n",
    "        print(\"  无日期列或数据为空，跳过插值\")\n",
    "    \n",
    "    # 3. 检查是否所有映射后的特征都存在\n",
    "    missing_features = []\n",
    "    for data_col in feature_mapping.keys():\n",
    "        if data_col not in df.columns:\n",
    "            missing_features.append(data_col)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"  缺少特征: {', '.join(missing_features)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 4. 准备特征数据\n",
    "    X = pd.DataFrame()\n",
    "    for data_col, model_feature in feature_mapping.items():\n",
    "        X[model_feature] = df[data_col]\n",
    "    \n",
    "    # 5. 应用特征归一化\n",
    "    # VOD特征归一化（除以2）\n",
    "    vod_features = ['VOD', 'VODHpol', 'VODVpol']\n",
    "    for vod_feature in vod_features:\n",
    "        if vod_feature in X.columns:\n",
    "            X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "    \n",
    "    # LAI特征归一化（除以6）\n",
    "    if 'LAI' in X.columns:\n",
    "        X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "    \n",
    "    # PFT特征归一化（除以100）\n",
    "    pft_features = [\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    for pft_feature in pft_features:\n",
    "        if pft_feature in X.columns:\n",
    "            X[pft_feature] = X[pft_feature] / 100.0\n",
    "    \n",
    "    # 6. 移除缺失值\n",
    "    initial_count = len(X)\n",
    "    X = X.dropna()\n",
    "    removed_count = initial_count - len(X)\n",
    "    if removed_count > 0:\n",
    "        print(f\"  移除了 {removed_count} 行包含缺失值的数据\")\n",
    "    \n",
    "    if X.empty:\n",
    "        print(\"  无有效数据可用于预测\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # 7. 确保特征顺序与模型期望一致\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        X = X[expected_features]\n",
    "    \n",
    "    # 8. 预测VWC\n",
    "    try:\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        # 创建完整长度的预测序列\n",
    "        full_pred = pd.Series(np.nan, index=df.index)\n",
    "        full_pred.loc[X.index] = y_pred\n",
    "        \n",
    "        return full_pred\n",
    "    except Exception as e:\n",
    "        print(f\"  预测失败: {str(e)}\")\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "\n",
    "def create_combined_plots(data_dict_2017, data_dict_2018):\n",
    "    \"\"\"创建组合时间序列图并保存预测结果\"\"\"\n",
    "    print(\"创建组合时间序列图...\")\n",
    "    \n",
    "    # 创建输出目录\n",
    "    output_dir = Path(\"prediction_results\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 创建图形 - 增加底部空间用于多行图例\n",
    "    fig = plt.figure(figsize=(15, 18))\n",
    "    gs = gridspec.GridSpec(4, 1, figure=fig, height_ratios=[1, 1, 1, 0.4], hspace=0.3)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('Vegetation Water Content Time Series', fontsize=20, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 植被类型列表\n",
    "    vegetation_types = [\n",
    "        ('CornVegMeasured', data_dict_2017),  # 玉米\n",
    "        ('OatVegMeasured', data_dict_2017),   # 燕麦\n",
    "        ('GrassVWC', data_dict_2018)           # 草\n",
    "    ]\n",
    "    \n",
    "    # 实测VWC列名映射\n",
    "    ACTUAL_COL_MAPPING = {\n",
    "        'CornVegMeasured': 'total_VWC(kg/m2)',\n",
    "        'OatVegMeasured': 'total_VWC(kg/m2)',\n",
    "        'GrassVWC': 'vegetation water content(kg/m2)'\n",
    "    }\n",
    "    \n",
    "    # 存储所有评估指标\n",
    "    all_metrics = {}\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 根据图片定义极化标记样式\n",
    "    POL_MARKERS = {\n",
    "        'H': '+',   # 加号\n",
    "        'V': '^',   # 三角形\n",
    "        'HV': 's'   # 正方形\n",
    "    }\n",
    "    \n",
    "    # 波段颜色\n",
    "    BAND_COLORS = {\n",
    "        'Ku': 'blue',\n",
    "        'X': 'green',\n",
    "        'C': 'red'\n",
    "    }\n",
    "    \n",
    "    # 极化线型\n",
    "    POL_LINESTYLES = {\n",
    "        'H': '-',\n",
    "        'V': '--',\n",
    "        'HV': '-.'\n",
    "    }\n",
    "    \n",
    "    # 极化名称映射 - 修改1：使用新的标题格式\n",
    "    POL_NAMES = {\n",
    "        'H': 'H-Pol',\n",
    "        'V': 'V-Pol',\n",
    "        'HV': 'H&V-Pol'\n",
    "    }\n",
    "    \n",
    "    # 波段名称映射 - 修改2：使用新的标题格式\n",
    "    BAND_NAMES = {\n",
    "        'Ku': 'Ku-Band',\n",
    "        'X': 'X-Band',\n",
    "        'C': 'C-Band'\n",
    "    }\n",
    "    \n",
    "    # 植被类型显示名称\n",
    "    VEGETATION_TYPES = {\n",
    "        'CornVegMeasured': 'Corn',\n",
    "        'OatVegMeasured': 'Oat',\n",
    "        'GrassVWC': 'Grass'\n",
    "    }\n",
    "    \n",
    "    # 遍历所有植被类型\n",
    "    for idx, (veg_type, data_dict) in enumerate(vegetation_types):\n",
    "        ax = fig.add_subplot(gs[idx])\n",
    "        \n",
    "        # 获取当前植被类型的实测列名\n",
    "        actual_col = ACTUAL_COL_MAPPING[veg_type]\n",
    "        \n",
    "        # 初始化Y轴范围\n",
    "        y_min = float('inf')\n",
    "        y_max = float('-inf')\n",
    "        \n",
    "        # 获取实测数据\n",
    "        if veg_type in data_dict:\n",
    "            df_measured = data_dict[veg_type].copy()\n",
    "            \n",
    "            # 确保日期列存在\n",
    "            if 'Date' not in df_measured.columns:\n",
    "                print(f\"警告: {veg_type} 中没有 'Date' 列\")\n",
    "                continue\n",
    "            \n",
    "            # 按日期排序\n",
    "            df_measured = df_measured.sort_values('Date')\n",
    "            \n",
    "            # 更新Y轴范围（实测值）\n",
    "            if actual_col in df_measured.columns:\n",
    "                measured_values = df_measured[actual_col].dropna()\n",
    "                if not measured_values.empty:\n",
    "                    y_min = min(y_min, measured_values.min())\n",
    "                    y_max = max(y_max, measured_values.max())\n",
    "            \n",
    "            # 获取拟合数据用于预测\n",
    "            fitting_sheet = FITTING_MAPPING.get(veg_type, veg_type)\n",
    "            if fitting_sheet in data_dict:\n",
    "                df_fitting = data_dict[fitting_sheet].copy()\n",
    "                \n",
    "                # 确保日期列存在\n",
    "                if 'Date' not in df_fitting.columns:\n",
    "                    print(f\"警告: {fitting_sheet} 中没有 'Date' 列\")\n",
    "                    continue\n",
    "                \n",
    "                # 按日期排序\n",
    "                df_fitting = df_fitting.sort_values('Date')\n",
    "            else:\n",
    "                # 2018年没有单独的拟合数据\n",
    "                df_fitting = df_measured.copy()\n",
    "            \n",
    "            # 存储评估指标\n",
    "            metrics = []\n",
    "            \n",
    "            # 为每个波段和极化组合预测VWC\n",
    "            for band in BAND_COLORS.keys():\n",
    "                for pol in POL_LINESTYLES.keys():\n",
    "                    # 生成列名\n",
    "                    col_name = f\"Predicted_VWC_{band}_{pol}\"\n",
    "                    \n",
    "                    # 如果列不存在，使用模型预测\n",
    "                    if col_name not in df_fitting.columns:\n",
    "                        print(f\"为 {fitting_sheet} 预测 {band}-{pol} VWC...\")\n",
    "                        df_fitting[col_name] = predict_vwc_for_sheet(df_fitting, band, pol)\n",
    "                    \n",
    "                    # 只在有有效预测值的点进行绘制和评估\n",
    "                    if col_name in df_fitting.columns:\n",
    "                        # 更新Y轴范围（预测值）\n",
    "                        pred_values = df_fitting[col_name].dropna()\n",
    "                        if not pred_values.empty:\n",
    "                            y_min = min(y_min, pred_values.min())\n",
    "                            y_max = max(y_max, pred_values.max())\n",
    "                        \n",
    "                        # 获取有效预测数据点\n",
    "                        valid_mask = df_fitting[col_name].notna()\n",
    "                        valid_dates = df_fitting['Date'][valid_mask]\n",
    "                        valid_values = df_fitting[col_name][valid_mask]\n",
    "                        \n",
    "                        # 如果数据点足够多，使用样条插值生成平滑曲线\n",
    "                        if len(valid_dates) > 3:\n",
    "                            try:\n",
    "                                # 将日期转换为数值（从最小日期开始的天数）\n",
    "                                date_numeric = (valid_dates - valid_dates.min()).dt.days\n",
    "                                \n",
    "                                # 创建样条插值对象\n",
    "                                spline = make_interp_spline(date_numeric, valid_values, k=3)\n",
    "                                \n",
    "                                # 生成更密集的时间点\n",
    "                                dense_dates = np.linspace(date_numeric.min(), date_numeric.max(), 300)\n",
    "                                dense_values = spline(dense_dates)\n",
    "                                \n",
    "                                # 将数值日期转换回实际日期\n",
    "                                dense_dates = valid_dates.min() + pd.to_timedelta(dense_dates, unit='D')\n",
    "                                \n",
    "                                # 绘制平滑曲线\n",
    "                                ax.plot(dense_dates, dense_values,\n",
    "                                        color=BAND_COLORS[band],\n",
    "                                        linestyle=POL_LINESTYLES[pol],\n",
    "                                        linewidth=1.5)\n",
    "                            except Exception as e:\n",
    "                                print(f\"样条插值失败: {str(e)}\")\n",
    "                                # 如果插值失败，使用原始数据点绘制折线\n",
    "                                ax.plot(valid_dates, valid_values,\n",
    "                                        color=BAND_COLORS[band],\n",
    "                                        linestyle=POL_LINESTYLES[pol],\n",
    "                                        linewidth=1.5)\n",
    "                        else:\n",
    "                            # 数据点太少，直接绘制折线\n",
    "                            ax.plot(valid_dates, valid_values,\n",
    "                                    color=BAND_COLORS[band],\n",
    "                                    linestyle=POL_LINESTYLES[pol],\n",
    "                                    linewidth=1.5)\n",
    "                        \n",
    "                        # 找出同时有实测值和预测值的点\n",
    "                        common_data = pd.merge(\n",
    "                            df_measured[['Date', actual_col]], \n",
    "                            df_fitting[['Date', col_name]], \n",
    "                            on='Date', \n",
    "                            how='inner'\n",
    "                        ).dropna(subset=[actual_col, col_name])\n",
    "                        \n",
    "                        if not common_data.empty:\n",
    "                            # 更新Y轴范围（共同数据）\n",
    "                            common_min = min(common_data[actual_col].min(), common_data[col_name].min())\n",
    "                            common_max = max(common_data[actual_col].max(), common_data[col_name].max())\n",
    "                            y_min = min(y_min, common_min)\n",
    "                            y_max = max(y_max, common_max)\n",
    "                            \n",
    "                            # 在实测日期位置绘制实测值点（空心圆）\n",
    "                            ax.plot(common_data['Date'], common_data[actual_col],\n",
    "                                    linestyle='',  # 无线条\n",
    "                                    color='black',\n",
    "                                    marker='o',\n",
    "                                    markersize=8,\n",
    "                                    markerfacecolor='none',  # 透明填充（空心）\n",
    "                                    markeredgewidth=1.5)\n",
    "                            \n",
    "                            # 在实测日期位置绘制预测点（空心标记）\n",
    "                            ax.plot(common_data['Date'], common_data[col_name],\n",
    "                                    linestyle='',  # 无线条\n",
    "                                    color=BAND_COLORS[band],\n",
    "                                    marker=POL_MARKERS[pol],\n",
    "                                    markersize=10,\n",
    "                                    markerfacecolor='none',  # 透明填充（空心）\n",
    "                                    markeredgewidth=1.5)\n",
    "                            \n",
    "                            # 计算评估指标\n",
    "                            rmse = np.sqrt(mean_squared_error(common_data[actual_col], common_data[col_name]))\n",
    "                            r2 = r2_score(common_data[actual_col], common_data[col_name])\n",
    "                            \n",
    "                            # 添加到指标列表\n",
    "                            metrics.append({\n",
    "                                'band': band,\n",
    "                                'pol': pol,\n",
    "                                'rmse': rmse,\n",
    "                                'r2': r2\n",
    "                            })\n",
    "                            \n",
    "                            # 保存预测结果\n",
    "                            model_key = f\"{veg_type}_{band}_{pol}\"\n",
    "                            all_predictions[model_key] = {\n",
    "                                'dates': common_data['Date'].tolist(),\n",
    "                                'measured': common_data[actual_col].tolist(),\n",
    "                                'predicted': common_data[col_name].tolist(),\n",
    "                                'rmse': rmse,\n",
    "                                'r2': r2\n",
    "                            }\n",
    "            \n",
    "            # 设置子图标题 - 修改3：使用新的标题格式\n",
    "            ax.set_title(VEGETATION_TYPES.get(veg_type, veg_type), \n",
    "                         fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if idx == 2:  # 最后一行\n",
    "                ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('VWC (kg/m²)', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # 设置X轴格式\n",
    "            ax.xaxis.set_major_locator(mdates.DayLocator(interval=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # 动态设置Y轴范围\n",
    "            if y_min != float('inf') and y_max != float('-inf'):\n",
    "                # 添加10%的边距\n",
    "                y_range = y_max - y_min\n",
    "                padding = y_range * 0.1\n",
    "                \n",
    "                # 确保最小值不小于0\n",
    "                y_min = max(0, y_min - padding)\n",
    "                y_max = y_max + padding\n",
    "                \n",
    "                ax.set_ylim(y_min, y_max)\n",
    "            else:\n",
    "                # 默认范围\n",
    "                ax.set_ylim(0, 10)\n",
    "            \n",
    "            # 存储指标\n",
    "            all_metrics[veg_type] = metrics\n",
    "    \n",
    "    # ==================================\n",
    "    # 创建图例（精确匹配要求）\n",
    "    # ==================================\n",
    "    \n",
    "    # 创建图例区域的轴\n",
    "    ax_legend = fig.add_subplot(gs[3])\n",
    "    ax_legend.axis('off')  # 隐藏坐标轴\n",
    "    \n",
    "    # 定义图例行内容（标题+项目） - 修改4：使用新的标题格式\n",
    "    legend_rows = [\n",
    "        # 第一行：Ku波段\n",
    "        [f\"{BAND_NAMES['Ku']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "        \n",
    "        # 第二行：X波段\n",
    "        [f\"{BAND_NAMES['X']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "        \n",
    "        # 第三行：C波段\n",
    "        [f\"{BAND_NAMES['C']},{POL_NAMES[pol]}\" for pol in ['H', 'V', 'HV']],\n",
    "\n",
    "        # 第四行：实测点\n",
    "        [f\"Insitu VWC\"]\n",
    "    ]\n",
    "    \n",
    "    # 创建代理艺术家\n",
    "    proxies = {}\n",
    "    \n",
    "    # Insitu VWC代理（空心圆）\n",
    "    proxies['insitu'] = plt.Line2D([], [], \n",
    "                     linestyle='', \n",
    "                     marker='o',\n",
    "                     markersize=10,\n",
    "                     markerfacecolor='none',\n",
    "                     markeredgecolor='black',\n",
    "                     markeredgewidth=1.5,\n",
    "                     label='Insitu VWC')\n",
    "    \n",
    "    # 波段-极化组合代理 - 修改5：使用新的标题格式\n",
    "    for band in ['Ku', 'X', 'C']:\n",
    "        color = BAND_COLORS[band]\n",
    "        for pol in ['H', 'V', 'HV']:\n",
    "            proxies[f\"{band}-{pol}\"] = plt.Line2D([], [],\n",
    "                color=color,\n",
    "                linestyle=POL_LINESTYLES[pol],\n",
    "                linewidth=2,\n",
    "                marker=POL_MARKERS[pol],\n",
    "                markersize=10,\n",
    "                markerfacecolor='none',\n",
    "                markeredgecolor=color,\n",
    "                markeredgewidth=1.5,\n",
    "                label=f\"{BAND_NAMES[band]},{POL_NAMES[pol]}\")\n",
    "    \n",
    "    # 为每行创建图例\n",
    "    y_positions = [0.85, 0.60, 0.35, 0.10]  # 三行垂直位置\n",
    "    \n",
    "    for row_idx, row_items in enumerate(legend_rows):\n",
    "        handles = []\n",
    "        labels = []\n",
    "        \n",
    "        for item in row_items:\n",
    "            # 处理Insitu项\n",
    "            if item == \"Insitu VWC\":\n",
    "                handles.append(proxies['insitu'])\n",
    "                labels.append(item)\n",
    "            # 处理波段-极化项\n",
    "            else:\n",
    "                # 解析新的标签格式\n",
    "                band_part, pol_part = item.split(',')\n",
    "                band = band_part.split('-')[0]  # 提取波段名称\n",
    "                \n",
    "                handles.append(proxies[f\"{band}-{pol}\"])\n",
    "                labels.append(item)  # 使用完整的标签文本\n",
    "        \n",
    "        # 计算当前行文本宽度（均匀分布）\n",
    "        n_items = len(handles)\n",
    "        x_positions = np.linspace(0.05, 0.95, n_items)\n",
    "        \n",
    "        # 绘制当前行的图例项\n",
    "        for i, (handle, label) in enumerate(zip(handles, labels)):\n",
    "            ax_legend.plot([], [])  # 空白绘图以创建图例项\n",
    "            \n",
    "            # 创建图例句柄\n",
    "            leg = ax_legend.legend([handle], [label], \n",
    "                                  loc='lower center',\n",
    "                                  bbox_to_anchor=(x_positions[i], y_positions[row_idx]),\n",
    "                                  frameon=False,\n",
    "                                  handlelength=2,\n",
    "                                  fontsize=10,\n",
    "                                  handletextpad=0.8)\n",
    "            \n",
    "            # 添加到轴（否则会被覆盖）\n",
    "            ax_legend.add_artist(leg)\n",
    "    \n",
    "    # 在子图中显示评估指标\n",
    "    for idx, (veg_type, metrics) in enumerate(all_metrics.items()):\n",
    "        if idx < 3:  # 确保索引有效（排除图例轴）\n",
    "            ax = fig.axes[idx]\n",
    "            \n",
    "            # 创建指标文本\n",
    "            if metrics:\n",
    "                # 使用多列格式显示所有指标\n",
    "                metric_text = \"Evaluation Metrics:\\n\"\n",
    "                \n",
    "                # 按波段分组指标\n",
    "                band_metrics = {}\n",
    "                for metric in metrics:\n",
    "                    band = metric['band']\n",
    "                    if band not in band_metrics:\n",
    "                        band_metrics[band] = []\n",
    "                    band_metrics[band].append(metric)\n",
    "                \n",
    "                # 为每个波段创建一行文本\n",
    "                for band in ['Ku', 'X', 'C']:\n",
    "                    if band in band_metrics:\n",
    "                        band_text = f\"{BAND_NAMES[band]}: \"\n",
    "                        pol_texts = []\n",
    "                        for metric in band_metrics[band]:\n",
    "                            pol_texts.append(f\"{POL_NAMES[metric['pol']]}(RMSE={metric['rmse']:.3f})\")\n",
    "                        band_text += \", \".join(pol_texts)\n",
    "                        metric_text += band_text + \"\\n\"\n",
    "                \n",
    "                # 添加文本框\n",
    "                ax.text(0.02, 0.95, metric_text, \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=9,\n",
    "                        verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    \n",
    "    # 保存图像\n",
    "    figures_dir = Path(\"figures\")\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = figures_dir / \"Combined_VWC_Time_Series_Purify.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"组合时间序列图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存所有预测结果到CSV文件\n",
    "    for model_key, data in all_predictions.items():\n",
    "        veg_type, band, pol = model_key.split('_')\n",
    "        df = pd.DataFrame({\n",
    "            'Date': data['dates'],\n",
    "            'Measured': data['measured'],\n",
    "            'Predicted': data['predicted']\n",
    "        })\n",
    "        csv_path = output_dir / f\"{veg_type}_{band}_{pol}_predictions_Purify.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"保存预测结果至: {csv_path}\")\n",
    "    \n",
    "    # 保存评估指标\n",
    "    metrics_path = output_dir / \"model_metrics_Purify.csv\"\n",
    "    metrics_data = []\n",
    "    for veg_type, metrics in all_metrics.items():\n",
    "        for metric in metrics:\n",
    "            metrics_data.append({\n",
    "                'Vegetation': veg_type,\n",
    "                'Band': metric['band'],\n",
    "                'Polarization': metric['pol'],\n",
    "                'RMSE': metric['rmse'],\n",
    "                'R2': metric['r2']\n",
    "            })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"保存模型评估指标至: {metrics_path}\")\n",
    "\n",
    "def main():\n",
    "    # 2017年数据文件\n",
    "    file_2017 = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\DuolunExp_Veg_ML.xlsx\"\n",
    "    data_2017 = load_data(file_2017)\n",
    "    \n",
    "    # 2018年数据文件\n",
    "    file_2018 = r\"E:\\data\\VWC\\test-VWC\\多频多角度地基微波辐射计及地表参量观测数据集\\ZhenglanqiExp_VWC_ML.xlsx\"\n",
    "    data_2018 = load_data(file_2018)\n",
    "    \n",
    "    # 创建组合时间序列图\n",
    "    create_combined_plots(data_2017, data_2018)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7f9266-636e-4a1e-883d-cbe86f4f337d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载预测结果: prediction_results\n",
      "处理模型: Ku_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: Ku_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: Ku_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: X_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_H\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_V\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "处理模型: C_HV\n",
      "  - 玉米数据点: 8\n",
      "  - 燕麦数据点: 7\n",
      "  - 草数据点: 13\n",
      "散点图已保存至: figures\\Scatter_Predictions_From_Saved_Data_Purify.png\n",
      "\n",
      "模型评估指标:\n",
      "Ku_H:\n",
      "  Corn RMSE = 2.9664\n",
      "  Oat RMSE = 2.8482\n",
      "  Grass RMSE = 1.4324\n",
      "  Total RMSE = 2.3441\n",
      "Ku_V:\n",
      "  Corn RMSE = 2.7527\n",
      "  Oat RMSE = 2.0731\n",
      "  Grass RMSE = 1.4749\n",
      "  Total RMSE = 2.0614\n",
      "Ku_HV:\n",
      "  Corn RMSE = 2.8971\n",
      "  Oat RMSE = 2.4244\n",
      "  Grass RMSE = 1.0185\n",
      "  Total RMSE = 2.0855\n",
      "X_H:\n",
      "  Corn RMSE = 2.6867\n",
      "  Oat RMSE = 1.8765\n",
      "  Grass RMSE = 0.9755\n",
      "  Total RMSE = 1.8397\n",
      "X_V:\n",
      "  Corn RMSE = 1.4954\n",
      "  Oat RMSE = 1.2271\n",
      "  Grass RMSE = 1.2577\n",
      "  Total RMSE = 1.3228\n",
      "X_HV:\n",
      "  Corn RMSE = 2.2848\n",
      "  Oat RMSE = 1.5631\n",
      "  Grass RMSE = 1.3613\n",
      "  Total RMSE = 1.7213\n",
      "C_H:\n",
      "  Corn RMSE = 1.8911\n",
      "  Oat RMSE = 1.4614\n",
      "  Grass RMSE = 0.9320\n",
      "  Total RMSE = 1.3996\n",
      "C_V:\n",
      "  Corn RMSE = 2.0700\n",
      "  Oat RMSE = 1.6317\n",
      "  Grass RMSE = 1.3488\n",
      "  Total RMSE = 1.6537\n",
      "C_HV:\n",
      "  Corn RMSE = 1.9351\n",
      "  Oat RMSE = 1.4954\n",
      "  Grass RMSE = 0.7273\n",
      "  Total RMSE = 1.3691\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 3*3 散点图结果\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "BAND_COLORS = {\n",
    "    'Ku': '#1f77b4',  # 蓝色\n",
    "    'X': '#ff7f0e',   # 橙色\n",
    "    'C': '#2ca02c'    # 绿色\n",
    "}\n",
    "POLS = ['H', 'V', 'HV']\n",
    "\n",
    "# 植被类型标记样式 - 玉米标记改为空心方形（'s'）\n",
    "VEG_MARKERS = {\n",
    "    'CornVegMeasured': {'marker': 's', 'size': 80, 'label': 'Corn (2017)'},  # 改为方形\n",
    "    'OatVegMeasured': {'marker': '^', 'size': 80, 'label': 'Oat (2017)'},\n",
    "    'GrassVWC': {'marker': 'o', 'size': 80, 'label': 'Grass (2018)'}\n",
    "}\n",
    "\n",
    "def load_prediction_data(prediction_dir):\n",
    "    \"\"\"从CSV文件加载预测结果\"\"\"\n",
    "    print(f\"加载预测结果: {prediction_dir}\")\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有CSV文件\n",
    "    for csv_file in prediction_dir.glob(\"*_predictions_Purify.csv\"):\n",
    "        # 解析文件名获取模型信息\n",
    "        filename = csv_file.stem\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 4:  # 格式: {植被类型}_{波段}_{极化}_predictions\n",
    "            veg_type = parts[0]\n",
    "            band = parts[1]\n",
    "            pol = parts[2]\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            \n",
    "            # 加载数据\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # 确保日期是datetime类型\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # 存储数据\n",
    "            if model_key not in all_predictions:\n",
    "                all_predictions[model_key] = {}\n",
    "            \n",
    "            all_predictions[model_key][veg_type] = df\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "def get_model_title(band, pol):\n",
    "    \"\"\"根据波段和极化返回自定义标题\"\"\"\n",
    "    band_names = {\n",
    "        'Ku': 'Ku-Band',\n",
    "        'X': 'X-Band',\n",
    "        'C': 'C-Band'\n",
    "    }\n",
    "    pol_names = {\n",
    "        'H': 'H-Pol',\n",
    "        'V': 'V-Pol',\n",
    "        'HV': 'H&V-Pol'  # 修改这里\n",
    "    }\n",
    "    return f\"{band_names.get(band, band)},{pol_names.get(pol, pol)}\"\n",
    "\n",
    "def create_scatter_plots_from_predictions(prediction_dir):\n",
    "    \"\"\"从预测结果文件创建9个模型的真值与预测值散点图（3x3网格）\"\"\"\n",
    "    # 加载预测结果\n",
    "    all_predictions = load_prediction_data(prediction_dir)\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"警告: 没有找到预测结果文件\")\n",
    "        return\n",
    "    \n",
    "    # 创建3x3网格图\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.suptitle('', fontsize=20, y=0.95)\n",
    "    gs = gridspec.GridSpec(3, 3, wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    # 收集所有散点的最小和最大值（用于统一坐标轴）\n",
    "    all_actual_min, all_actual_max = np.inf, -np.inf\n",
    "    all_pred_min, all_pred_max = np.inf, -np.inf\n",
    "    \n",
    "    # 收集所有评估指标\n",
    "    all_metrics = {}\n",
    "\n",
    "    # 处理每个模型（波段和极化组合）\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            model_key = f\"{band}_{pol}\"\n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            print(f\"处理模型: {model_key}\")\n",
    "            \n",
    "            # 检查该模型是否有预测数据\n",
    "            if model_key not in all_predictions:\n",
    "                print(f\"警告: {model_key} 模型没有预测数据\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 收集该模型的所有植被类型的数据\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            all_veg_types = []\n",
    "            \n",
    "            # 存储各植被类型的数据点\n",
    "            veg_data = {\n",
    "                'CornVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'OatVegMeasured': {'actual': [], 'predicted': []},\n",
    "                'GrassVWC': {'actual': [], 'predicted': []}\n",
    "            }\n",
    "            \n",
    "            # 处理玉米数据\n",
    "            veg_type = 'CornVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 玉米数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理燕麦数据\n",
    "            veg_type = 'OatVegMeasured'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 燕麦数据点: {len(df)}\")\n",
    "            \n",
    "            # 处理草数据\n",
    "            veg_type = 'GrassVWC'\n",
    "            if veg_type in all_predictions[model_key]:\n",
    "                df = all_predictions[model_key][veg_type]\n",
    "                if 'Measured' in df.columns and 'Predicted' in df.columns:\n",
    "                    # 添加数据点\n",
    "                    veg_data[veg_type]['actual'] = df['Measured'].tolist()\n",
    "                    veg_data[veg_type]['predicted'] = df['Predicted'].tolist()\n",
    "                    \n",
    "                    # 添加到总数据\n",
    "                    all_actual.extend(df['Measured'])\n",
    "                    all_predicted.extend(df['Predicted'])\n",
    "                    all_veg_types.extend([veg_type] * len(df))\n",
    "                    print(f\"  - 草数据点: {len(df)}\")\n",
    "            \n",
    "            # 如果没有数据点，跳过\n",
    "            if len(all_actual) == 0:\n",
    "                print(f\"警告: {model_key} 模型没有有效数据点\")\n",
    "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', \n",
    "                        verticalalignment='center', transform=ax.transAxes,\n",
    "                        fontsize=14, color='red')\n",
    "                ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "                continue\n",
    "                \n",
    "            # 转换为numpy数组\n",
    "            all_actual = np.array(all_actual)\n",
    "            all_predicted = np.array(all_predicted)\n",
    "            \n",
    "            # 更新全局最小/最大值\n",
    "            all_actual_min = min(all_actual_min, np.min(all_actual))\n",
    "            all_actual_max = max(all_actual_max, np.max(all_actual))\n",
    "            all_pred_min = min(all_pred_min, np.min(all_predicted))\n",
    "            all_pred_max = max(all_pred_max, np.max(all_predicted))\n",
    "            \n",
    "            # 计算各植被类型的RMSE\n",
    "            rmse_corn = None\n",
    "            rmse_oat = None\n",
    "            rmse_grass = None\n",
    "            \n",
    "            if veg_data['CornVegMeasured']['actual']:\n",
    "                actual_corn = np.array(veg_data['CornVegMeasured']['actual'])\n",
    "                predicted_corn = np.array(veg_data['CornVegMeasured']['predicted'])\n",
    "                rmse_corn = np.sqrt(mean_squared_error(actual_corn, predicted_corn))\n",
    "            \n",
    "            if veg_data['OatVegMeasured']['actual']:\n",
    "                actual_oat = np.array(veg_data['OatVegMeasured']['actual'])\n",
    "                predicted_oat = np.array(veg_data['OatVegMeasured']['predicted'])\n",
    "                rmse_oat = np.sqrt(mean_squared_error(actual_oat, predicted_oat))\n",
    "            \n",
    "            if veg_data['GrassVWC']['actual']:\n",
    "                actual_grass = np.array(veg_data['GrassVWC']['actual'])\n",
    "                predicted_grass = np.array(veg_data['GrassVWC']['predicted'])\n",
    "                rmse_grass = np.sqrt(mean_squared_error(actual_grass, predicted_grass))\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse_total = np.sqrt(mean_squared_error(all_actual, all_predicted))\n",
    "            \n",
    "            # 存储评估指标\n",
    "            all_metrics[model_key] = {\n",
    "                'RMSE_Corn': rmse_corn,\n",
    "                'RMSE_Oat': rmse_oat,\n",
    "                'RMSE_Grass': rmse_grass,\n",
    "                'RMSE_Total': rmse_total\n",
    "            }\n",
    "            \n",
    "            # 绘制散点图 - 按植被类型区分标记\n",
    "            # 先绘制草和燕麦，最后绘制玉米（确保玉米在最上层）\n",
    "            for veg_type in ['GrassVWC', 'OatVegMeasured', 'CornVegMeasured']:\n",
    "                if veg_data[veg_type]['actual']:\n",
    "                    actual_values = np.array(veg_data[veg_type]['actual'])\n",
    "                    predicted_values = np.array(veg_data[veg_type]['predicted'])\n",
    "                    \n",
    "                    marker_style = VEG_MARKERS[veg_type]\n",
    "                    \n",
    "                    # 为玉米标记使用更大的尺寸和线宽\n",
    "                    if veg_type == 'CornVegMeasured':\n",
    "                        size = 100  # 增加大小\n",
    "                        edgewidth = 1.5  # 更粗的线宽\n",
    "                        alpha = 0.9  # 更高的不透明度\n",
    "                    else:\n",
    "                        size = marker_style['size']\n",
    "                        edgewidth = 1.0\n",
    "                        alpha = 0.8\n",
    "                    \n",
    "                    # 所有标记使用相同的波段颜色\n",
    "                    ax.scatter(actual_values, predicted_values, \n",
    "                              marker=marker_style['marker'], \n",
    "                              s=size,\n",
    "                              alpha=alpha,  # 调整透明度\n",
    "                              facecolor='none', \n",
    "                              edgecolor=BAND_COLORS[band],  # 使用波段颜色\n",
    "                              linewidths=edgewidth,\n",
    "                              label=marker_style['label'])\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            ax.plot([0, 4], [0, 4], 'k--', linewidth=1, label='1:1 Line')\n",
    "            \n",
    "            # 设置标题和坐标轴标签\n",
    "            ax.set_title(get_model_title(band, pol), fontsize=14)\n",
    "            if j == 0:  # 第一列添加y轴标签\n",
    "                ax.set_ylabel('RF VWC (kg/m²)', fontsize=12)\n",
    "            if i == 2:  # 最后一行添加x轴标签\n",
    "                ax.set_xlabel('In Situ VWC (kg/m²)', fontsize=12)\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # 显示评估指标\n",
    "            metric_text = \"\"\n",
    "            if rmse_corn is not None:\n",
    "                metric_text += f\"Corn RMSE = {rmse_corn:.3f}\\n\"\n",
    "            if rmse_oat is not None:\n",
    "                metric_text += f\"Oat RMSE = {rmse_oat:.3f}\\n\"\n",
    "            if rmse_grass is not None:\n",
    "                metric_text += f\"Grass RMSE = {rmse_grass:.3f}\\n\"\n",
    "            metric_text += f\"Total RMSE = {rmse_total:.3f}\"\n",
    "            \n",
    "            ax.text(0.05, 0.95, metric_text, transform=ax.transAxes, \n",
    "                   fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 设置所有子图的坐标轴范围一致\n",
    "    max_val = 4\n",
    "    min_val = 0\n",
    "    for ax in fig.get_axes():\n",
    "        ax.set_xlim(min_val, max_val)\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "    \n",
    "    # 添加图例\n",
    "    # 创建代理艺术家用于图例\n",
    "    handles = []\n",
    "    labels = []\n",
    "    \n",
    "    # 添加植被类型标记\n",
    "    for veg_type, style in VEG_MARKERS.items():\n",
    "        # 为玉米标记使用特殊大小\n",
    "        if veg_type == 'CornVegMeasured':\n",
    "            markersize = 10  # 图例中保持相同大小\n",
    "        else:\n",
    "            markersize = 8\n",
    "            \n",
    "        handles.append(\n",
    "            plt.Line2D([], [], marker=style['marker'], linestyle='None', \n",
    "                       markersize=markersize, alpha=0.7, markerfacecolor='none', \n",
    "                       markeredgecolor='gray', label=style['label'])\n",
    "        )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    handles.append(\n",
    "        plt.Line2D([], [], color='k', linestyle='--', linewidth=1, label='1:1 Line')\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.95])  # 调整底部空间\n",
    " \n",
    "    # 添加图例到整个图形\n",
    "    fig.legend(handles=handles, loc='lower center', \n",
    "               bbox_to_anchor=(0.5, 0.05), ncol=4, fontsize=10, \n",
    "               title=\"\")\n",
    "    output_dir = Path(\"figures\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = output_dir / \"Scatter_Predictions_From_Saved_Data_Purify.png\"\n",
    "    plt.savefig(fig_path, dpi=1000, bbox_inches='tight', pad_inches=0.1)\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印所有模型的评估指标\n",
    "    print(\"\\n模型评估指标:\")\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        if metrics['RMSE_Corn'] is not None:\n",
    "            print(f\"  Corn RMSE = {metrics['RMSE_Corn']:.4f}\")\n",
    "        if metrics['RMSE_Oat'] is not None:\n",
    "            print(f\"  Oat RMSE = {metrics['RMSE_Oat']:.4f}\")\n",
    "        if metrics['RMSE_Grass'] is not None:\n",
    "            print(f\"  Grass RMSE = {metrics['RMSE_Grass']:.4f}\")\n",
    "        print(f\"  Total RMSE = {metrics['RMSE_Total']:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # 设置预测结果目录\n",
    "    prediction_dir = Path(\"prediction_results\")\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots_from_predictions(prediction_dir)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f76d9-e2a4-4f3c-aa80-adff87f330e3",
   "metadata": {},
   "source": [
    "2002-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b12e30-84f8-4d54-8fff-7ca9c86a6472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\n",
      "  - SMEX02: 16行\n",
      "    替换了 14 行SM_Satellite数据\n",
      "  - CLASIC07: 18行\n",
      "  - SMAPVEX08: 6行\n",
      "    替换了 6 行LAI_Satellite数据\n",
      "  - SMAPVEX16: 115行\n",
      "\n",
      "处理波段-极化组合: Ku-H\n",
      "加载模型: models/RFR_Ku_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 7 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 9 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-V\n",
      "加载模型: models/RFR_Ku_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 6 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 92 个样本\n",
      "\n",
      "处理波段-极化组合: Ku-HV\n",
      "加载模型: models/RFR_Ku_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 12 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 6 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 23 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 92 个样本\n",
      "\n",
      "处理波段-极化组合: X-H\n",
      "加载模型: models/RFR_X_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 6 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 10 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: X-V\n",
      "加载模型: models/RFR_X_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 7 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 9 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 107 个样本\n",
      "\n",
      "处理波段-极化组合: X-HV\n",
      "加载模型: models/RFR_X_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 9 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 7 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 9 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 9 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 8 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 107 个样本\n",
      "\n",
      "处理波段-极化组合: C-H\n",
      "加载模型: models/RFR_C_Hpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 11 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 5 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 预测完成: 115 个样本\n",
      "\n",
      "处理波段-极化组合: C-V\n",
      "加载模型: models/RFR_C_Vpol_Type1.pkl\n",
      "  模型训练特征: ['VOD', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 2 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 73 个样本\n",
      "\n",
      "处理波段-极化组合: C-HV\n",
      "加载模型: models/RFR_C_HVpol_Type1.pkl\n",
      "  模型训练特征: ['VOD-Hpol', 'VOD-Vpol', 'LAI', 'SM', 'Grass_man', 'Grass_nat', 'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne', 'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne']\n",
      "  SMEX02 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMEX02 移除了 14 行包含缺失值的数据\n",
      "  SMEX02 预测完成: 2 个样本\n",
      "  CLASIC07 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  CLASIC07 移除了 3 行包含缺失值的数据\n",
      "  CLASIC07 预测完成: 15 个样本\n",
      "  SMAPVEX08 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX08 预测完成: 6 个样本\n",
      "  SMAPVEX16 应用归一化处理...\n",
      "    归一化 VOD-Hpol: 除以2\n",
      "    归一化 VOD-Vpol: 除以2\n",
      "    归一化 LAI: 除以6\n",
      "    归一化 Grass_man: 除以100\n",
      "    归一化 Grass_nat: 除以100\n",
      "    归一化 Shrub_bd: 除以100\n",
      "    归一化 Shrub_be: 除以100\n",
      "    归一化 Shrub_nd: 除以100\n",
      "    归一化 Shrub_ne: 除以100\n",
      "    归一化 Tree_bd: 除以100\n",
      "    归一化 Tree_be: 除以100\n",
      "    归一化 Tree_nd: 除以100\n",
      "    归一化 Tree_ne: 除以100\n",
      "  SMAPVEX16 移除了 42 行包含缺失值的数据\n",
      "  SMAPVEX16 预测完成: 73 个样本\n",
      "创建散点图...\n",
      "散点图已保存至: figures/AllSMAPInsituData_VWC_Scatter_purify.png\n",
      "保存预测结果到: Ku_H (145行)\n",
      "保存预测结果到: Ku_V (109行)\n",
      "保存预测结果到: Ku_HV (109行)\n",
      "保存预测结果到: X_H (146行)\n",
      "保存预测结果到: X_V (129行)\n",
      "保存预测结果到: X_HV (129行)\n",
      "保存预测结果到: C_H (141行)\n",
      "保存预测结果到: C_V (96行)\n",
      "保存预测结果到: C_HV (96行)\n",
      "所有预测结果已保存至: E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\details_purify.xlsx\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "# 散点图（4个数据画在一块，写出n，按照波段-极化组合绘制为3*3）\n",
    "# 点形状及颜色：\n",
    "# SMEX02：*；CLASIC07：^；SMEX08：+；SMAPVEX16：o\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 常量定义\n",
    "BANDS = ['Ku', 'X', 'C']\n",
    "POLS = ['H', 'V', 'HV']\n",
    "SHEET_NAMES = ['SMEX02', 'CLASIC07', 'SMAPVEX08', 'SMAPVEX16']\n",
    "VWC_COLUMNS = {\n",
    "    'SMEX02': 'VWC-Field',\n",
    "    'CLASIC07': 'VWC (kg/m²)',\n",
    "    'SMAPVEX08': 'VWC',\n",
    "    'SMAPVEX16': 'PLANT_WATER_CONTENT_AREA'\n",
    "}\n",
    "\n",
    "# 标记和颜色设置\n",
    "MARKER_STYLES = {\n",
    "    'SMEX02': {'marker': 'x', 'color': '#F8766D'},\n",
    "    'CLASIC07': {'marker': '^', 'facecolor': 'none', 'edgecolor': '#00BFC4'},\n",
    "    'SMAPVEX08': {'marker': '+', 'color': '#C77CFF'},\n",
    "    'SMAPVEX16': {'marker': 'o', 'facecolor': 'none', 'edgecolor': '#7CAE00'}\n",
    "}\n",
    "\n",
    "# 设置全局字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    加载并预处理Excel文件中的所有sheet\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): Excel文件路径\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含预处理后数据的字典，键为sheet名称\n",
    "    \"\"\"\n",
    "    print(f\"加载文件: {file_path}\")\n",
    "    data_dict = {}\n",
    "    \n",
    "    for sheet in SHEET_NAMES:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            print(f\"  - {sheet}: {len(df)}行\")\n",
    "            \n",
    "            # 替换SM_Satellite和LAI_Satellite（如果存在地面实测数据）\n",
    "            if 'SM' in df.columns:\n",
    "                mask = df['SM'].notna()\n",
    "                df.loc[mask, 'SM_Satellite'] = df.loc[mask, 'SM']\n",
    "                print(f\"    替换了 {mask.sum()} 行SM_Satellite数据\")\n",
    "            \n",
    "            if 'LAI' in df.columns:\n",
    "                mask = df['LAI'].notna()\n",
    "                df.loc[mask, 'LAI_Satellite'] = df.loc[mask, 'LAI']\n",
    "                print(f\"    替换了 {mask.sum()} 行LAI_Satellite数据\")\n",
    "            \n",
    "            data_dict[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"  加载 {sheet} 时出错: {str(e)}\")\n",
    "            data_dict[sheet] = pd.DataFrame()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_features_for_model(band, pol):\n",
    "    \"\"\"\n",
    "    根据波段和极化类型获取特征列表（使用模型训练时的名称）\n",
    "    \n",
    "    参数:\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    list: 特征列名列表\n",
    "    \"\"\"\n",
    "    # 使用模型训练时的特征名称\n",
    "    features = [\n",
    "        'LAI',  # 注意：训练时使用\"LAI\"而不是\"LAI_Satellite\"\n",
    "        'SM',   # 注意：训练时使用\"SM\"而不是\"SM_Satellite\"\n",
    "        'Grass_man', \n",
    "        'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    # 添加VOD特征 - 根据模型类型\n",
    "    if pol == 'H' or pol == 'V':\n",
    "        # 单极化模型使用\"VOD\"\n",
    "        features.append('VOD')\n",
    "    elif pol == 'HV':\n",
    "        # 双极化模型使用\"VOD-Hpol\"和\"VOD-Vpol\"\n",
    "        features.extend(['VOD-Hpol', 'VOD-Vpol'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predict_vwc(data_dict, band, pol):\n",
    "    \"\"\"\n",
    "    使用指定模型预测VWC，包括特征归一化\n",
    "    \n",
    "    参数:\n",
    "    data_dict (dict): 包含所有sheet数据的字典\n",
    "    band (str): 波段 ('Ku', 'X', 'C')\n",
    "    pol (str): 极化类型 ('H', 'V', 'HV')\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含每个sheet预测结果的字典\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model_path = f\"models/RFR_{band}_{pol}pol_Type1.pkl\"\n",
    "    print(f\"加载模型: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  模型文件不存在: {model_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        # 打印模型训练时的特征名称（如果可用）\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            print(f\"  模型训练特征: {list(model.feature_names_in_)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  加载模型失败: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "    # 获取特征列表\n",
    "    features = get_features_for_model(band, pol)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    predictions = {}\n",
    "    \n",
    "    for sheet, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # 创建特征映射（将数据列名映射到模型期望的特征名）\n",
    "        feature_mapping = {}\n",
    "        for feature in features:\n",
    "            # 特殊处理VOD特征\n",
    "            if feature == 'VOD':\n",
    "                # 单极化模型\n",
    "                if pol == 'H':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_H'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_H'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_H'] = 'VOD'\n",
    "                elif pol == 'V':\n",
    "                    if band == 'Ku':\n",
    "                        feature_mapping['ku_vod_V'] = 'VOD'\n",
    "                    elif band == 'X':\n",
    "                        feature_mapping['x_vod_V'] = 'VOD'\n",
    "                    elif band == 'C':\n",
    "                        feature_mapping['c_vod_V'] = 'VOD'\n",
    "            elif feature == 'VOD-Hpol':\n",
    "                # 双极化模型中的H极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_H'] = 'VOD-Hpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_H'] = 'VOD-Hpol'\n",
    "            elif feature == 'VOD-Vpol':\n",
    "                # 双极化模型中的V极化\n",
    "                if band == 'Ku':\n",
    "                    feature_mapping['ku_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'X':\n",
    "                    feature_mapping['x_vod_V'] = 'VOD-Vpol'\n",
    "                elif band == 'C':\n",
    "                    feature_mapping['c_vod_V'] = 'VOD-Vpol'\n",
    "            else:\n",
    "                # 其他特征映射\n",
    "                if feature == 'LAI':\n",
    "                    feature_mapping['LAI_Satellite'] = 'LAI'\n",
    "                elif feature == 'SM':\n",
    "                    feature_mapping['SM_Satellite'] = 'SM'\n",
    "                elif feature == 'Grass_man':\n",
    "                    feature_mapping['grassman'] = 'Grass_man'\n",
    "                elif feature == 'Grass_nat':\n",
    "                    feature_mapping['grassnat'] = 'Grass_nat'\n",
    "                elif feature == 'Shrub_bd':\n",
    "                    feature_mapping['shrubbd'] = 'Shrub_bd'\n",
    "                elif feature == 'Shrub_be':\n",
    "                    feature_mapping['shrubbe'] = 'Shrub_be'\n",
    "                elif feature == 'Shrub_nd':\n",
    "                    feature_mapping['shrubnd'] = 'Shrub_nd'\n",
    "                elif feature == 'Shrub_ne':\n",
    "                    feature_mapping['shrubne'] = 'Shrub_ne'\n",
    "                elif feature == 'Tree_bd':\n",
    "                    feature_mapping['treebd'] = 'Tree_bd'\n",
    "                elif feature == 'Tree_be':\n",
    "                    feature_mapping['treebe'] = 'Tree_be'\n",
    "                elif feature == 'Tree_nd':\n",
    "                    feature_mapping['treend'] = 'Tree_nd'\n",
    "                elif feature == 'Tree_ne':\n",
    "                    feature_mapping['treene'] = 'Tree_ne'\n",
    "        \n",
    "        # 检查是否包含所有必要特征\n",
    "        missing_features = []\n",
    "        for data_feature in feature_mapping.keys():\n",
    "            if data_feature not in df.columns:\n",
    "                missing_features.append(data_feature)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"  {sheet} 缺少特征: {', '.join(missing_features)}\")\n",
    "            continue\n",
    "        \n",
    "        # 准备数据（使用重命名的特征）\n",
    "        X = df[list(feature_mapping.keys())].copy()\n",
    "        X.columns = [feature_mapping[col] for col in X.columns]\n",
    "        \n",
    "        # 确保特征顺序与模型期望一致\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            X = X[list(model.feature_names_in_)]\n",
    "        \n",
    "        # ========== 添加归一化处理 ==========\n",
    "        print(f\"  {sheet} 应用归一化处理...\")\n",
    "        \n",
    "        # 1. VOD特征归一化（除以2）\n",
    "        vod_features = ['VOD', 'VOD-Hpol', 'VOD-Vpol']\n",
    "        for vod_feature in vod_features:\n",
    "            if vod_feature in X.columns:\n",
    "                X[vod_feature] = X[vod_feature].clip(0, 2) / 2.0\n",
    "                print(f\"    归一化 {vod_feature}: 除以2\")\n",
    "        \n",
    "        # 2. LAI特征归一化（除以6）\n",
    "        if 'LAI' in X.columns:\n",
    "            X['LAI'] = X['LAI'].clip(0, 6) / 6.0\n",
    "            print(f\"    归一化 LAI: 除以6\")\n",
    "        \n",
    "        # 3. PFT特征归一化（除以100）\n",
    "        pft_features = [\n",
    "            'Grass_man', 'Grass_nat',\n",
    "            'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "            'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "        ]\n",
    "        \n",
    "        for pft_feature in pft_features:\n",
    "            if pft_feature in X.columns:\n",
    "                X[pft_feature] = X[pft_feature] / 100.0\n",
    "                print(f\"    归一化 {pft_feature}: 除以100\")\n",
    "        # =================================\n",
    "        \n",
    "        # 移除缺失值\n",
    "        initial_count = len(X)\n",
    "        X = X.dropna()\n",
    "        removed_count = initial_count - len(X)\n",
    "        if removed_count > 0:\n",
    "            print(f\"  {sheet} 移除了 {removed_count} 行包含缺失值的数据\")\n",
    "        \n",
    "        if X.empty:\n",
    "            print(f\"  {sheet} 无有效数据可用于预测\")\n",
    "            continue\n",
    "        \n",
    "        # 预测VWC\n",
    "        y_pred = model.predict(X)\n",
    "        predictions[sheet] = {\n",
    "            'actual': df.loc[X.index, VWC_COLUMNS[sheet]],\n",
    "            'predicted': y_pred,\n",
    "            'source': sheet,\n",
    "            'row': df.loc[X.index, 'row'],\n",
    "            'col': df.loc[X.index, 'col'],\n",
    "            'lat': df.loc[X.index, 'Latitude'],\n",
    "            'lon': df.loc[X.index, 'Longitude'],\n",
    "            'date': df.loc[X.index, 'Date']\n",
    "        }\n",
    "        print(f\"  {sheet} 预测完成: {len(y_pred)} 个样本\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def calculate_rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    计算RMSE\n",
    "    \n",
    "    参数:\n",
    "    actual (array-like): 实际值\n",
    "    predicted (array-like): 预测值\n",
    "    \n",
    "    返回:\n",
    "    float: RMSE值\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "\n",
    "def create_scatter_plots(all_predictions):\n",
    "    \"\"\"\n",
    "    创建3x3散点子图\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    print(\"创建散点图...\")\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "    \n",
    "    # 设置全局标题\n",
    "    fig.suptitle('', fontsize=24, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for i, band in enumerate(BANDS):\n",
    "        for j, pol in enumerate(POLS):\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            \n",
    "            # 获取当前组合的预测结果\n",
    "            predictions = all_predictions.get((band, pol), {})\n",
    "            \n",
    "            # 收集所有数据点\n",
    "            all_actual = []\n",
    "            all_predicted = []\n",
    "            \n",
    "            # 绘制每个sheet的数据点\n",
    "            for sheet in SHEET_NAMES:\n",
    "                if sheet in predictions:\n",
    "                    actual = predictions[sheet]['actual']\n",
    "                    predicted = predictions[sheet]['predicted']\n",
    "                    \n",
    "                    # 添加到总集合\n",
    "                    all_actual.extend(actual)\n",
    "                    all_predicted.extend(predicted)\n",
    "                    \n",
    "                    # 绘制当前sheet的点\n",
    "                    if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "                        # 对CLASIC07、SMAPVEX16特殊处理：空心\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=MARKER_STYLES[sheet]['marker'],\n",
    "                            facecolor=MARKER_STYLES[sheet]['facecolor'],  # 内部无填充\n",
    "                            edgecolor=MARKER_STYLES[sheet]['edgecolor'],  # 使用边缘颜色\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            linewidths=1.0,  # 确保边框可见\n",
    "                            label=sheet\n",
    "                        )\n",
    "                    else:\n",
    "                        # 其他数据集保持原样\n",
    "                        ax.scatter(\n",
    "                            actual, predicted,\n",
    "                            marker=MARKER_STYLES[sheet]['marker'],\n",
    "                            color=MARKER_STYLES[sheet].get('color', MARKER_STYLES[sheet].get('edgecolor', None)),\n",
    "                            s=50,\n",
    "                            alpha=0.7,\n",
    "                            label=sheet\n",
    "                        )\n",
    "            \n",
    "            # 如果没有数据，跳过\n",
    "            if not all_actual:\n",
    "                ax.text(0.5, 0.5, '无数据', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=16)\n",
    "                ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            # 计算整体RMSE\n",
    "            rmse = calculate_rmse(np.array(all_actual), np.array(all_predicted))\n",
    "            \n",
    "            # 添加1:1参考线\n",
    "            max_val = max(max(all_actual), max(all_predicted)) * 1.05\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7)\n",
    "            \n",
    "            # 设置坐标轴范围\n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            \n",
    "            # 设置坐标轴标签\n",
    "            if i == 2:  # 最后一行\n",
    "                ax.set_xlabel('Insitu VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            if j == 0:  # 第一列\n",
    "                ax.set_ylabel('Predicted VWC (kg/m²)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 添加标题和RMSE\n",
    "            ax.set_title(f\"{band}-{pol}\", fontsize=16, fontweight='bold')\n",
    "            ax.text(0.05, 0.95, f\"RMSE: {rmse:.3f} kg/m²\", \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=16,\n",
    "                    fontweight='bold',\n",
    "                    verticalalignment='top')\n",
    "            \n",
    "            # 添加网格\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 添加图例\n",
    "    handles, labels = [], []\n",
    "    for sheet in SHEET_NAMES:\n",
    "        style = MARKER_STYLES[sheet]\n",
    "        \n",
    "        if sheet in ['CLASIC07', 'SMAPVEX16']:\n",
    "            # 为CLASIC07、SMAPVEX16创建空心图例\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w',\n",
    "                                     markerfacecolor=style['facecolor'],  # 内部白色\n",
    "                                     markeredgecolor=style['edgecolor'],  # 边缘颜色\n",
    "                                     markersize=10,\n",
    "                                     markeredgewidth=1.0))  # 边框宽度\n",
    "        else:\n",
    "            handles.append(plt.Line2D([0], [0], \n",
    "                                     marker=style['marker'], \n",
    "                                     color='w', \n",
    "                                     markerfacecolor=style.get('color', style.get('edgecolor')),\n",
    "                                     markeredgecolor=style.get('color', style.get('edgecolor')), \n",
    "                                     markersize=10))\n",
    "        labels.append(sheet)\n",
    "    \n",
    "    fig.legend(handles, labels, \n",
    "               loc='lower center', \n",
    "               ncol=4, \n",
    "               fontsize=12,\n",
    "               frameon=True,\n",
    "               fancybox=True,\n",
    "               shadow=True,\n",
    "               bbox_to_anchor=(0.5, 0.02))\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    # 保存图像\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = \"figures/AllSMAPInsituData_VWC_Scatter_purify.png\"  # 更新为指定的文件名\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"散点图已保存至: {fig_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def save_prediction_details(all_predictions):\n",
    "    \"\"\"\n",
    "    将预测结果保存到Excel文件中\n",
    "    \n",
    "    参数:\n",
    "    all_predictions (dict): 包含所有波段和极化组合预测结果的字典\n",
    "    \"\"\"\n",
    "    output_dir = Path(r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\")\n",
    "    output_file = output_dir / \"details_purify.xlsx\"\n",
    "    \n",
    "    # 创建Excel写入器\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # 遍历所有波段和极化组合\n",
    "        for (band, pol), predictions in all_predictions.items():\n",
    "            if not predictions:\n",
    "                continue\n",
    "                \n",
    "            # 创建当前组合的数据框\n",
    "            all_data = []\n",
    "            \n",
    "            # 收集所有sheet的数据\n",
    "            for sheet, data in predictions.items():\n",
    "                # 创建当前sheet的数据框\n",
    "                sheet_df = pd.DataFrame({\n",
    "                    'Date': data['date'],\n",
    "                    'Row': data['row'],\n",
    "                    'Col': data['col'],\n",
    "                    'Latitude': data['lat'],\n",
    "                    'Longitude': data['lon'],\n",
    "                    'Actual_VWC': data['actual'],\n",
    "                    'Predicted_VWC': data['predicted'],\n",
    "                    'Source': data['source']\n",
    "                })\n",
    "                \n",
    "                # 添加波段和极化信息\n",
    "                sheet_df['Band'] = band\n",
    "                sheet_df['Polarization'] = pol\n",
    "                \n",
    "                all_data.append(sheet_df)\n",
    "            \n",
    "            # 合并所有数据\n",
    "            if all_data:\n",
    "                combined_df = pd.concat(all_data, ignore_index=True)\n",
    "                \n",
    "                # 保存到Excel\n",
    "                sheet_name = f\"{band}_{pol}\"\n",
    "                combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                print(f\"保存预测结果到: {sheet_name} ({len(combined_df)}行)\")\n",
    "    \n",
    "    print(f\"所有预测结果已保存至: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # 输入文件路径\n",
    "    input_file = r\"E:\\data\\VWC\\test-VWC\\SMEX02_CLASIC07_SMEX08_SMAPVEX16\\InsituData_Pixel_ML.xlsx\"\n",
    "    \n",
    "    # 加载并预处理数据\n",
    "    data_dict = load_and_preprocess_data(input_file)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # 遍历所有波段和极化组合\n",
    "    for band in BANDS:\n",
    "        for pol in POLS:\n",
    "            print(f\"\\n处理波段-极化组合: {band}-{pol}\")\n",
    "            predictions = predict_vwc(data_dict, band, pol)\n",
    "            all_predictions[(band, pol)] = predictions\n",
    "    \n",
    "    # 创建散点图\n",
    "    create_scatter_plots(all_predictions)\n",
    "    \n",
    "    # 保存预测结果到Excel\n",
    "    save_prediction_details(all_predictions)\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ede11-441c-4cd6-a006-537b61366d3c",
   "metadata": {},
   "source": [
    "# .VWC-SHB2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1827d2f-55b6-4983-9f6f-cabc41da9953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                   D:\\Anaconda\n",
      "                       D:\\Miniconda\n",
      "d2l                    D:\\ProgramData\\anaconda3\\envs\\d2l\n",
      "gdal_env               D:\\ProgramData\\anaconda3\\envs\\gdal_env\n",
      "geo_env                D:\\ProgramData\\anaconda3\\envs\\geo_env\n",
      "project              * D:\\ProgramData\\anaconda3\\envs\\project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf57b2-0231-4c40-8753-3a599abf1aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

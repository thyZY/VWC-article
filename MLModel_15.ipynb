{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c07d4f",
   "metadata": {},
   "source": [
    "## 补全除了随机森林模型之外的其他模型的训练，将训练结果进行保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4310fa4a",
   "metadata": {},
   "source": [
    "## 1.随机森林模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528c2ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "开始训练模型: 6 VOD + LAI + 10 PFTs + Hveg\n",
      "================================================================================\n",
      "\n",
      "加载数据集: G:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx...\n",
      "\n",
      "初始数据类型:\n",
      "SamplingDate       datetime64[ns]\n",
      "LFMCValue                  object\n",
      "AGB                       float64\n",
      "Hveg                      float64\n",
      "Grass_man                 float64\n",
      "Grass_nat                 float64\n",
      "Shrub_bd                  float64\n",
      "Shrub_be                   object\n",
      "Shrub_nd                  float64\n",
      "Shrub_ne                  float64\n",
      "Tree_bd                    object\n",
      "Tree_be                    object\n",
      "Tree_nd                    object\n",
      "Tree_ne                    object\n",
      "LAI                       float64\n",
      "VOD_Ku_Hpol_Asc           float64\n",
      "VOD_X_Hpol_Asc            float64\n",
      "VOD_C_Hpol_Asc            float64\n",
      "VOD_Ku_Vpol_Asc           float64\n",
      "VOD_X_Vpol_Asc            float64\n",
      "VOD_C_Vpol_Asc            float64\n",
      "dtype: object\n",
      "清洗并转换列: LFMCValue (当前类型: object) 为 float64\n",
      "清洗并转换列: Shrub_be (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_bd (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_be (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_nd (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_ne (当前类型: object) 为 float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 15:03:19,980] A new study created in memory with name: VWC_6VOD_LAI_PFTs_Hveg_Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: 数据中存在缺失值，正在清理...\n",
      "清理后样本数: 16099\n",
      "\n",
      "最终数据类型:\n",
      "VOD_Ku_Hpol_Asc    float64\n",
      "VOD_Ku_Vpol_Asc    float64\n",
      "VOD_X_Hpol_Asc     float64\n",
      "VOD_X_Vpol_Asc     float64\n",
      "VOD_C_Hpol_Asc     float64\n",
      "VOD_C_Vpol_Asc     float64\n",
      "LAI                float64\n",
      "Hveg               float64\n",
      "Grass_man          float64\n",
      "Grass_nat          float64\n",
      "Shrub_bd           float64\n",
      "Shrub_be           float64\n",
      "Shrub_nd           float64\n",
      "Shrub_ne           float64\n",
      "Tree_bd            float64\n",
      "Tree_be            float64\n",
      "Tree_nd            float64\n",
      "Tree_ne            float64\n",
      "dtype: object\n",
      "目标变量类型: float64\n",
      "数据预处理完成, 耗时: 0.61分钟\n",
      "使用特征: 18个 (6 VOD, 1 LAI, 1 Hveg, 10 PFT)\n",
      "样本数量: 16013\n",
      "训练集样本数: 10680\n",
      "测试集样本数: 5333\n",
      "\n",
      "开始贝叶斯优化调参...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 15:03:27,702] Trial 0 finished with value: 1.7484255120906451 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:03:38,939] Trial 1 finished with value: 1.7610052873815731 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:03:47,268] Trial 2 finished with value: 1.75415351649218 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:03:55,241] Trial 3 finished with value: 1.7992555819007472 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:03:59,676] Trial 4 finished with value: 1.7826154416197244 and parameters: {'n_estimators': 300, 'max_features': 'log2', 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:04,126] Trial 5 finished with value: 1.8211839926232076 and parameters: {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:13,605] Trial 6 finished with value: 1.8508043896268696 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:17,590] Trial 7 finished with value: 1.8336587012215095 and parameters: {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:22,901] Trial 8 finished with value: 1.933314763482055 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:26,979] Trial 9 finished with value: 1.8071970956824424 and parameters: {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:38,446] Trial 10 finished with value: 1.891637970330697 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:46,681] Trial 11 finished with value: 1.765252363345736 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:04:54,138] Trial 12 finished with value: 1.8028891292179445 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:08,924] Trial 13 finished with value: 1.7650006165138001 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:15,986] Trial 14 finished with value: 1.881692856929007 and parameters: {'n_estimators': 600, 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:27,627] Trial 15 finished with value: 1.8211642220886382 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:33,913] Trial 16 finished with value: 1.784654068534643 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:41,057] Trial 17 finished with value: 1.75014692630102 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:47,355] Trial 18 finished with value: 1.8019189346617541 and parameters: {'n_estimators': 400, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:05:54,599] Trial 19 finished with value: 1.75014692630102 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:06:04,532] Trial 20 finished with value: 1.7644570878449433 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:06:11,646] Trial 21 finished with value: 1.75014692630102 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 1.7484255120906451.\n",
      "[I 2025-09-28 15:06:19,164] Trial 22 finished with value: 1.739091750222989 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:06:26,658] Trial 23 finished with value: 1.7420774393279923 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:06:35,792] Trial 24 finished with value: 1.7412133167633463 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:06:43,163] Trial 25 finished with value: 1.741873948569881 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:06:51,225] Trial 26 finished with value: 1.7920133723942193 and parameters: {'n_estimators': 600, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:06:59,953] Trial 27 finished with value: 1.7467053369525598 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:07:12,765] Trial 28 finished with value: 1.74068396589482 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:07:25,790] Trial 29 finished with value: 1.7666336741808952 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:07:35,526] Trial 30 finished with value: 1.8361147783503964 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:07:46,262] Trial 31 finished with value: 1.7413726847531443 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:08:00,840] Trial 32 finished with value: 1.7406517947448426 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:08:14,354] Trial 33 finished with value: 1.7512815227037468 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:08:30,175] Trial 34 finished with value: 1.7495483149410322 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:08:42,747] Trial 35 finished with value: 1.7425180676615581 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:08:54,783] Trial 36 finished with value: 1.8124023634955815 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:09:08,815] Trial 37 finished with value: 1.7443003101860242 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:09:21,839] Trial 38 finished with value: 1.7412795511133492 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:09:28,200] Trial 39 finished with value: 1.8205861450294463 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:09:42,718] Trial 40 finished with value: 1.7406827763059975 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:09:57,213] Trial 41 finished with value: 1.740682776305998 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 22 with value: 1.739091750222989.\n",
      "[I 2025-09-28 15:10:12,292] Trial 42 finished with value: 1.7380601569280814 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:10:32,877] Trial 43 finished with value: 1.7422366852062825 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:10:47,123] Trial 44 finished with value: 1.7479323814774836 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:10:58,729] Trial 45 finished with value: 1.806222852812222 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:11:13,283] Trial 46 finished with value: 1.740682776305998 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:11:28,060] Trial 47 finished with value: 1.7652817916451233 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:11:40,853] Trial 48 finished with value: 1.7834404505916854 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:11:56,931] Trial 49 finished with value: 1.7514340539769215 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:12:11,150] Trial 50 finished with value: 1.7886215985840033 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:12:26,140] Trial 51 finished with value: 1.740682776305998 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:12:39,772] Trial 52 finished with value: 1.74068396589482 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:12:55,321] Trial 53 finished with value: 1.7406827763059975 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:13:10,771] Trial 54 finished with value: 1.7466027605176102 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 1.7380601569280814.\n",
      "[I 2025-09-28 15:13:29,227] Trial 55 finished with value: 1.7380399049458721 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:13:42,824] Trial 56 finished with value: 1.8371970150155943 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:13:59,358] Trial 57 finished with value: 1.7663867961081716 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:14:15,562] Trial 58 finished with value: 1.7485898896503353 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:14:29,303] Trial 59 finished with value: 1.742541363213239 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:14:36,482] Trial 60 finished with value: 1.7426632125555042 and parameters: {'n_estimators': 300, 'max_features': 'log2', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:14:52,977] Trial 61 finished with value: 1.740682776305998 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:15:10,804] Trial 62 finished with value: 1.740682776305998 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:15:25,529] Trial 63 finished with value: 1.747923421087092 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:15:41,991] Trial 64 finished with value: 1.7396800852334073 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:15:59,404] Trial 65 finished with value: 1.7428771309423585 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:16:09,782] Trial 66 finished with value: 1.8809766221174002 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:16:26,428] Trial 67 finished with value: 1.7396481668134491 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:16:39,349] Trial 68 finished with value: 1.7791401947126222 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:16:57,844] Trial 69 finished with value: 1.7475679815831142 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:17:11,721] Trial 70 finished with value: 1.801635664959425 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:17:29,034] Trial 71 finished with value: 1.7396481668134491 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:17:46,884] Trial 72 finished with value: 1.7389890236996348 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:18:04,742] Trial 73 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:18:22,536] Trial 74 finished with value: 1.7389890236996348 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:18:42,663] Trial 75 finished with value: 1.7391387274388541 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:19:02,595] Trial 76 finished with value: 1.7438883717628966 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:19:21,300] Trial 77 finished with value: 1.7475679815831142 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:19:43,143] Trial 78 finished with value: 1.7453696834607544 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:20:00,065] Trial 79 finished with value: 1.747634143692818 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:20:21,050] Trial 80 finished with value: 1.7478278192507801 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:20:39,088] Trial 81 finished with value: 1.7389890236996348 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:20:56,468] Trial 82 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:21:15,915] Trial 83 finished with value: 1.7391387274388541 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:21:33,742] Trial 84 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:21:46,704] Trial 85 finished with value: 1.7854276284061306 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:22:06,230] Trial 86 finished with value: 1.7448506490458127 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:22:22,751] Trial 87 finished with value: 1.7476341436928184 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:22:36,291] Trial 88 finished with value: 1.8213735480591224 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:22:55,035] Trial 89 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:23:13,735] Trial 90 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:23:31,824] Trial 91 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:23:50,395] Trial 92 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:24:09,468] Trial 93 finished with value: 1.7448506490458127 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:24:27,723] Trial 94 finished with value: 1.738989023699635 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:24:45,001] Trial 95 finished with value: 1.7476341436928184 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:25:04,463] Trial 96 finished with value: 1.7448506490458127 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:25:16,814] Trial 97 finished with value: 1.8521278419184266 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:25:36,794] Trial 98 finished with value: 1.7391387274388541 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 55 with value: 1.7380399049458721.\n",
      "[I 2025-09-28 15:25:49,051] Trial 99 finished with value: 1.7788705283568464 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 55 with value: 1.7380399049458721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最佳参数组合:\n",
      "n_estimators: 900\n",
      "max_features: log2\n",
      "max_depth: 40\n",
      "min_samples_split: 5\n",
      "min_samples_leaf: 1\n",
      "bootstrap: False\n",
      "最佳验证RMSE: 1.7380\n",
      "优化历史数据已保存至: optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_history.csv\n",
      "优化过程图保存至: optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_history.png\n",
      "警告: plotly未安装，跳过等高线图绘制\n",
      "\n",
      "训练最终模型...\n",
      "\n",
      "测试集评估...\n",
      "测试集 RMSE: 1.7245\n",
      "测试集 R²: 0.8817\n",
      "测试集对应原始行已保存至: test_data/test_rows_6VOD_LAI_PFTs_Hveg_Model.csv\n",
      "预测图保存至: figures/prediction_results_6VOD_LAI_PFTs_Hveg_6VOD_LAI_PFTs_Hveg.png\n",
      "模型已保存至: models/RFR_6VOD_LAI_PFTs_Hveg.pkl\n",
      "特征重要性图保存至: figures/feature_importance_6VOD_LAI_PFTs_Hveg.png\n",
      "特征重要性数据已保存至: figures/feature_importance_6VOD_LAI_PFTs_Hveg.csv\n",
      "\n",
      "Top 10特征重要性:\n",
      "1. Hveg: 0.2533\n",
      "2. Tree_ne: 0.2206\n",
      "3. Grass_nat: 0.1632\n",
      "4. LAI: 0.1055\n",
      "5. Shrub_ne: 0.0504\n",
      "6. VOD_X_Hpol_Asc: 0.0367\n",
      "7. VOD_C_Hpol_Asc: 0.0321\n",
      "8. VOD_Ku_Hpol_Asc: 0.0272\n",
      "9. Grass_man: 0.0268\n",
      "10. Tree_bd: 0.0219\n",
      "\n",
      "================================================================================\n",
      "模型训练完成!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 全局文件路径常量\n",
    "DATA_FILE_PATH = r\"G:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\"\n",
    "\n",
    "def load_and_preprocess_selected_data():\n",
    "    \"\"\"数据加载函数 - 只选择6个VOD、LAI、Hveg和10个PFT特征，不进行归一化\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    print(f\"加载数据集: {DATA_FILE_PATH}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 定义所有需要的列\n",
    "    vod_columns = [\n",
    "        'VOD_Ku_Hpol_Asc', 'VOD_Ku_Vpol_Asc',\n",
    "        'VOD_X_Hpol_Asc', 'VOD_X_Vpol_Asc',\n",
    "        'VOD_C_Hpol_Asc', 'VOD_C_Vpol_Asc'\n",
    "    ]\n",
    "    \n",
    "    pft_columns = [\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    required_columns = [\n",
    "        'AGB', 'LFMCValue', 'SamplingDate',  # 用于计算目标变量\n",
    "        'LAI', 'Hveg'  # 主要特征\n",
    "    ] + vod_columns + pft_columns\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_excel(DATA_FILE_PATH, usecols=required_columns)\n",
    "    \n",
    "    # === 数据类型诊断 ===\n",
    "    print(\"\\n初始数据类型:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # 确定需要转换为 float64 的列\n",
    "    columns_to_convert = [col for col in df.columns if col != 'SamplingDate']\n",
    "    \n",
    "    # 清洗并转换为 float64\n",
    "    for col in columns_to_convert:\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            print(f\"清洗并转换列: {col} (当前类型: {df[col].dtype}) 为 float64\")\n",
    "            # 转字符串，去掉空格、逗号、制表符等干扰字符\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"[^\\d\\.\\-eE]\", \"\", regex=True)\n",
    "                .replace({\"\": np.nan})\n",
    "            )\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif df[col].dtype != 'float64':\n",
    "            df[col] = df[col].astype('float64')\n",
    "    \n",
    "    # 检查缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 数据中存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 计算 VWC_sample\n",
    "    df['VWC_sample'] = (df['AGB'] * df['LFMCValue']) / 1000\n",
    "    df['VWC_sample'] = pd.to_numeric(df['VWC_sample'], errors='coerce')\n",
    "    \n",
    "    # 再次清理缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 类型转换后存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 过滤 VWC_sample\n",
    "    df = df[df['VWC_sample'] <= 30]\n",
    "    \n",
    "    # 特征工程\n",
    "    if 'SamplingDate' in df and pd.api.types.is_datetime64_any_dtype(df['SamplingDate']):\n",
    "        df['Year_diff'] = df['SamplingDate'].dt.year.apply(lambda x: 2020 - x)\n",
    "    else:\n",
    "        print(\"警告: SamplingDate列不存在或不是日期类型，跳过年份差计算\")\n",
    "    \n",
    "    # 定义特征列\n",
    "    feature_columns = vod_columns + ['LAI', 'Hveg'] + pft_columns\n",
    "    available_features = [col for col in feature_columns if col in df]\n",
    "    missing_features = set(feature_columns) - set(available_features)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"警告: 以下特征不存在: {missing_features}\")\n",
    "    \n",
    "    if not available_features:\n",
    "        raise ValueError(\"错误: 没有找到任何特征列\")\n",
    "    \n",
    "    X = df[available_features]\n",
    "    y = df['VWC_sample']\n",
    "    \n",
    "    # 最终检查\n",
    "    print(\"\\n最终数据类型:\")\n",
    "    print(X.dtypes)\n",
    "    print(f\"目标变量类型: {y.dtype}\")\n",
    "    print(f\"数据预处理完成, 耗时: {(time.time()-start_time)/60:.2f}分钟\")\n",
    "    print(f\"使用特征: {len(available_features)}个 (6 VOD, 1 LAI, 1 Hveg, 10 PFT)\")\n",
    "    print(f\"样本数量: {len(X)}\")\n",
    "    \n",
    "    return X, y, df.index\n",
    "\n",
    "def objective(trial, X_train, y_train):\n",
    "    \"\"\"贝叶斯优化目标函数\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000, step=100),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 50, step=10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestRegressor(**params, random_state=SEED, n_jobs=-1)\n",
    "    \n",
    "    # 五折交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "def plot_results_all(y_true, y_pred, filename):\n",
    "    \"\"\"结果可视化函数（更新文件名后缀）\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # 计算RMSE和R2指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 绘制散点图\n",
    "    plt.scatter(\n",
    "        y_true, y_pred,\n",
    "        marker='x',\n",
    "        color='#FF0000',\n",
    "        linewidths=0.5,\n",
    "        s=40,\n",
    "        alpha=0.8,\n",
    "        zorder=2\n",
    "    )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围和标签\n",
    "    plt.xlim(0, max_val + 1)\n",
    "    plt.ylim(0, max_val + 1)\n",
    "    plt.xlabel('Insitu VWC (kg/m2)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('RF VWC (kg/m2)', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 添加标题（更新后缀）\n",
    "    plt.title(\"6 VOD + LAI + PFTs + Hveg Random Forest Model\", fontsize=16, pad=20, fontweight='bold')\n",
    "    \n",
    "    # 添加指标文本\n",
    "    plt.text(0.05, 0.95,\n",
    "             f'RMSE = {rmse:.3f} kg/m²\\nR² = {r2:.4f}',\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=12,\n",
    "             fontweight='bold',\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    # 网格线和样式调整\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像（更新后缀）\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    plot_path = f\"figures/{filename}_6VOD_LAI_PFTs_Hveg.png\"  # 更新后缀\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"预测图保存至: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_optimization_history(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化过程历史图并保存数据\"\"\"\n",
    "    # 创建优化历史数据框\n",
    "    history_df = pd.DataFrame({\n",
    "        'trial_number': [t.number for t in study.trials],\n",
    "        'value': [t.value for t in study.trials],\n",
    "        'params': [t.params for t in study.trials],\n",
    "        'state': [t.state for t in study.trials]\n",
    "    })\n",
    "    \n",
    "    # 保存优化历史到CSV\n",
    "    os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "    csv_path = f\"optimization_history/{filename_prefix}_history.csv\"\n",
    "    history_df.to_csv(csv_path, index=False)\n",
    "    print(f\"优化历史数据已保存至: {csv_path}\")\n",
    "    \n",
    "    # 提取所有有效试验的值\n",
    "    valid_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    values = [t.value for t in valid_trials]\n",
    "    best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "    \n",
    "    # 绘制优化过程图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 绘制当前试验值和历史最佳值\n",
    "    plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "    plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "    \n",
    "    # 标记全局最佳值\n",
    "    best_value = min(values)\n",
    "    best_index = values.index(best_value) + 1\n",
    "    plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                label=f'全局最佳 (试验#{best_index})')\n",
    "    \n",
    "    # 设置图表元素\n",
    "    plt.xlabel('试验次数', fontsize=12)\n",
    "    plt.ylabel('RMSE', fontsize=12)\n",
    "    plt.title('贝叶斯优化过程 (6 VOD + LAI + PFTs + Hveg)', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 保存图像\n",
    "    plot_path = f\"optimization_history/{filename_prefix}_history.png\"\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"优化过程图保存至: {plot_path}\")\n",
    "    \n",
    "    return history_df\n",
    "\n",
    "def plot_optimization_contour(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化等高线图（添加详细错误处理）\"\"\"\n",
    "    try:\n",
    "        import plotly\n",
    "        import optuna.visualization as vis\n",
    "        \n",
    "        # 使用Optuna内置可视化工具\n",
    "        fig = vis.plot_contour(study, params=['n_estimators', 'max_depth'])\n",
    "        if fig:\n",
    "            fig.update_layout(\n",
    "                title='贝叶斯优化参数关系 (6 VOD + LAI + PFTs + Hveg)',\n",
    "                font=dict(size=12),\n",
    "                width=800,\n",
    "                height=600\n",
    "            )\n",
    "            \n",
    "            # 保存为HTML格式以便后续交互查看\n",
    "            os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "            html_path = f\"optimization_history/{filename_prefix}_contour.html\"\n",
    "            fig.write_html(html_path)\n",
    "            print(f\"优化等高线图已保存至: {html_path}\")\n",
    "            \n",
    "            # 尝试保存为静态图片\n",
    "            img_path = f\"optimization_history/{filename_prefix}_contour.png\"\n",
    "            try:\n",
    "                # 明确指定使用kaleido引擎\n",
    "                fig.write_image(img_path, engine=\"kaleido\")\n",
    "                print(f\"优化等高线图已保存至: {img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"警告: 使用kaleido引擎保存静态图片失败: {str(e)}\")\n",
    "                print(\"尝试使用orca引擎...\")\n",
    "                try:\n",
    "                    fig.write_image(img_path, engine=\"orca\")\n",
    "                    print(f\"使用orca引擎保存成功: {img_path}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"使用orca引擎也失败: {str(e2)}\")\n",
    "                    print(\"跳过静态图片保存\")\n",
    "    except ImportError:\n",
    "        print(\"警告: plotly未安装，跳过等高线图绘制\")\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "\n",
    "def visualize_optimization_from_csv(csv_path):\n",
    "    \"\"\"从CSV文件重新绘制优化历史图\"\"\"\n",
    "    try:\n",
    "        history_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 过滤有效试验\n",
    "        history_df = history_df[history_df['state'] == 'COMPLETE'].copy()\n",
    "        \n",
    "        if history_df.empty:\n",
    "            print(\"警告: CSV中没有有效的试验数据\")\n",
    "            return\n",
    "            \n",
    "        # 提取值和最佳值\n",
    "        values = history_df['value'].tolist()\n",
    "        best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "        \n",
    "        # 绘制优化过程图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "        plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "        \n",
    "        # 标记全局最佳值\n",
    "        best_value = min(values)\n",
    "        best_index = values.index(best_value) + 1\n",
    "        plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                    label=f'全局最佳 (试验#{best_index})')\n",
    "        \n",
    "        # 设置图表元素\n",
    "        plt.xlabel('试验次数', fontsize=12)\n",
    "        plt.ylabel('RMSE', fontsize=12)\n",
    "        plt.title('贝叶斯优化过程 (从CSV文件生成)', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        \n",
    "        # 保存和显示\n",
    "        plt_path = csv_path.replace('.csv', '_from_csv.png')\n",
    "        plt.savefig(plt_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"优化过程图已保存至: {plt_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"可视化失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def train_selected_model():\n",
    "    \"\"\"训练使用6 VOD + LAI + PFTs + Hveg的新模型\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"开始训练模型: 6 VOD + LAI + 10 PFTs + Hveg\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. 数据加载与预处理（添加Hveg，去除归一化）\n",
    "    X, y, processed_indices = load_and_preprocess_selected_data()\n",
    "    \n",
    "    # 2. 数据划分\n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "        X, y, processed_indices,\n",
    "        test_size=0.333,\n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"训练集样本数: {len(X_train)}\")\n",
    "    print(f\"测试集样本数: {len(X_test)}\")\n",
    "    \n",
    "    # 3. 贝叶斯优化调参\n",
    "    print(\"\\n开始贝叶斯优化调参...\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"VWC_6VOD_LAI_PFTs_Hveg_Optimization\",\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=SEED)\n",
    "    )\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), \n",
    "                   n_trials=100)\n",
    "    \n",
    "    # 获取最佳参数\n",
    "    best_params = study.best_params\n",
    "    print(\"\\n最佳参数组合:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"最佳验证RMSE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 4. 优化过程可视化（保存图像和数据）\n",
    "    history_df = plot_optimization_history(study, \"optuna_study_6VOD_LAI_PFTs_Hveg\")\n",
    "    \n",
    "    # 尝试绘制等高线图\n",
    "    try:\n",
    "        plot_optimization_contour(study, \"optuna_study_6VOD_LAI_PFTs_Hveg\")\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "    \n",
    "    # 5. 使用最佳参数训练最终模型\n",
    "    print(\"\\n训练最终模型...\")\n",
    "    final_model = RandomForestRegressor(\n",
    "        **best_params,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. 测试集评估\n",
    "    print(\"\\n测试集评估...\")\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"测试集 RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"测试集 R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # 7. 保存测试集对应原始行（更新后缀）\n",
    "    test_data_dir = \"test_data\"\n",
    "    os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "    # 读取原始表格（仅测试集对应行）\n",
    "    # 重新读取原始数据以获取完整列\n",
    "    full_df = pd.read_excel(DATA_FILE_PATH)\n",
    "    test_rows = full_df.loc[test_idx]\n",
    "    test_rows['y_pred'] = y_pred\n",
    "    test_rows['y_true'] = y_test.values\n",
    "\n",
    "    # 保存精简数据集（更新后缀）\n",
    "    test_data_path = f\"{test_data_dir}/test_rows_6VOD_LAI_PFTs_Hveg_Model.csv\"\n",
    "    test_rows.to_csv(test_data_path, index=False)\n",
    "    print(f\"测试集对应原始行已保存至: {test_data_path}\") \n",
    "    \n",
    "    # 8. 可视化预测结果（更新后缀）\n",
    "    plot_results_all(y_test, y_pred, \"prediction_results_6VOD_LAI_PFTs_Hveg\")\n",
    "    \n",
    "    # 9. 保存模型（更新后缀）\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_path = \"models/RFR_6VOD_LAI_PFTs_Hveg.pkl\"  # 更新后缀\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"模型已保存至: {model_path}\")\n",
    "    \n",
    "    # 10. 特征重要性分析\n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        feature_importances = pd.Series(final_model.feature_importances_, index=X.columns)\n",
    "        feature_importances = feature_importances.sort_values(ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        feature_importances.plot(kind='barh')\n",
    "        plt.title('Feature Importance - 6 VOD + LAI + PFTs + Hveg Model', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像（更新后缀）\n",
    "        importance_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg.png\"\n",
    "        plt.savefig(importance_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"特征重要性图保存至: {importance_path}\")\n",
    "        \n",
    "        # 保存特征重要性数据\n",
    "        feature_imp_df = pd.DataFrame({\n",
    "            'feature': feature_importances.index,\n",
    "            'importance': feature_importances.values\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        feature_imp_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg.csv\"\n",
    "        feature_imp_df.to_csv(feature_imp_path, index=False)\n",
    "        print(f\"特征重要性数据已保存至: {feature_imp_path}\")\n",
    "        \n",
    "        # 打印关键特征重要性\n",
    "        print(\"\\nTop 10特征重要性:\")\n",
    "        for i, (feature, importance) in enumerate(feature_importances.head(10).items()):\n",
    "            print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    else:\n",
    "        print(\"警告: 模型没有feature_importances_属性，跳过特征重要性分析\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_selected_model()\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n模型训练完成!\\n\" + \"=\"*80)\n",
    "    \n",
    "    # 示例：如何使用可视化函数从CSV重新绘图\n",
    "    # 注释掉以下两行以跳过示例\n",
    "    # csv_path = \"optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_history.csv\"\n",
    "    # visualize_optimization_from_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25a8d4",
   "metadata": {},
   "source": [
    "## 2.LightGBM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d878a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "开始训练模型: 6 VOD + LAI + 10 PFTs + Hveg (LightGBM)\n",
      "================================================================================\n",
      "\n",
      "加载数据集: G:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx...\n",
      "\n",
      "初始数据类型:\n",
      "SamplingDate       datetime64[ns]\n",
      "LFMCValue                  object\n",
      "AGB                       float64\n",
      "Hveg                      float64\n",
      "Grass_man                 float64\n",
      "Grass_nat                 float64\n",
      "Shrub_bd                  float64\n",
      "Shrub_be                   object\n",
      "Shrub_nd                  float64\n",
      "Shrub_ne                  float64\n",
      "Tree_bd                    object\n",
      "Tree_be                    object\n",
      "Tree_nd                    object\n",
      "Tree_ne                    object\n",
      "LAI                       float64\n",
      "VOD_Ku_Hpol_Asc           float64\n",
      "VOD_X_Hpol_Asc            float64\n",
      "VOD_C_Hpol_Asc            float64\n",
      "VOD_Ku_Vpol_Asc           float64\n",
      "VOD_X_Vpol_Asc            float64\n",
      "VOD_C_Vpol_Asc            float64\n",
      "dtype: object\n",
      "清洗并转换列: LFMCValue (当前类型: object) 为 float64\n",
      "清洗并转换列: Shrub_be (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_bd (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_be (当前类型: object) 为 float64\n",
      "清洗并转换列: Tree_nd (当前类型: object) 为 float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 14:44:27,080] A new study created in memory with name: VWC_6VOD_LAI_PFTs_Hveg_Optimization_LGBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗并转换列: Tree_ne (当前类型: object) 为 float64\n",
      "警告: 数据中存在缺失值，正在清理...\n",
      "清理后样本数: 16099\n",
      "\n",
      "最终数据类型:\n",
      "VOD_Ku_Hpol_Asc    float64\n",
      "VOD_Ku_Vpol_Asc    float64\n",
      "VOD_X_Hpol_Asc     float64\n",
      "VOD_X_Vpol_Asc     float64\n",
      "VOD_C_Hpol_Asc     float64\n",
      "VOD_C_Vpol_Asc     float64\n",
      "LAI                float64\n",
      "Hveg               float64\n",
      "Grass_man          float64\n",
      "Grass_nat          float64\n",
      "Shrub_bd           float64\n",
      "Shrub_be           float64\n",
      "Shrub_nd           float64\n",
      "Shrub_ne           float64\n",
      "Tree_bd            float64\n",
      "Tree_be            float64\n",
      "Tree_nd            float64\n",
      "Tree_ne            float64\n",
      "dtype: object\n",
      "目标变量类型: float64\n",
      "数据预处理完成, 耗时: 0.60分钟\n",
      "使用特征: 18个 (6 VOD, 1 LAI, 1 Hveg, 10 PFT)\n",
      "样本数量: 16013\n",
      "训练集样本数: 10680\n",
      "测试集样本数: 5333\n",
      "\n",
      "开始贝叶斯优化调参...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 14:44:29,777] Trial 0 finished with value: 1.8549321169755921 and parameters: {'n_estimators': 450, 'learning_rate': 0.2536999076681772, 'max_depth': 12, 'num_leaves': 159, 'min_child_samples': 19, 'subsample': 0.662397808134481, 'colsample_bytree': 0.6232334448672797, 'reg_alpha': 8.661761457749352, 'reg_lambda': 6.011150117432088}. Best is trial 0 with value: 1.8549321169755921.\n",
      "[I 2025-09-28 14:44:41,556] Trial 1 finished with value: 1.8268650409299259 and parameters: {'n_estimators': 750, 'learning_rate': 0.010725209743171996, 'max_depth': 15, 'num_leaves': 215, 'min_child_samples': 25, 'subsample': 0.6727299868828402, 'colsample_bytree': 0.6733618039413735, 'reg_alpha': 3.0424224295953772, 'reg_lambda': 5.247564316322379}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:44:45,449] Trial 2 finished with value: 1.8586187038101496 and parameters: {'n_estimators': 500, 'learning_rate': 0.02692655251486473, 'max_depth': 10, 'num_leaves': 48, 'min_child_samples': 33, 'subsample': 0.7465447373174767, 'colsample_bytree': 0.7824279936868144, 'reg_alpha': 7.851759613930136, 'reg_lambda': 1.9967378215835974}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:44:46,586] Trial 3 finished with value: 1.9495806118576986 and parameters: {'n_estimators': 550, 'learning_rate': 0.07500118950416987, 'max_depth': 3, 'num_leaves': 161, 'min_child_samples': 21, 'subsample': 0.6260206371941118, 'colsample_bytree': 0.9795542149013333, 'reg_alpha': 9.656320330745594, 'reg_lambda': 8.08397348116461}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:44:52,088] Trial 4 finished with value: 1.8554641707561967 and parameters: {'n_estimators': 350, 'learning_rate': 0.013940346079873234, 'max_depth': 11, 'num_leaves': 121, 'min_child_samples': 16, 'subsample': 0.798070764044508, 'colsample_bytree': 0.6137554084460873, 'reg_alpha': 9.093204020787821, 'reg_lambda': 2.587799816000169}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:44:59,786] Trial 5 finished with value: 1.844700566173298 and parameters: {'n_estimators': 700, 'learning_rate': 0.028869220380495747, 'max_depth': 9, 'num_leaves': 146, 'min_child_samples': 22, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'reg_alpha': 9.394989415641891, 'reg_lambda': 8.948273504276488}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:01,628] Trial 6 finished with value: 1.8532789947762094 and parameters: {'n_estimators': 650, 'learning_rate': 0.22999586428143728, 'max_depth': 4, 'num_leaves': 62, 'min_child_samples': 9, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'reg_alpha': 2.713490317738959, 'reg_lambda': 8.287375091519294}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:03,928] Trial 7 finished with value: 1.924671117310457 and parameters: {'n_estimators': 400, 'learning_rate': 0.026000059117302653, 'max_depth': 10, 'num_leaves': 48, 'min_child_samples': 82, 'subsample': 0.6298202574719083, 'colsample_bytree': 0.9947547746402069, 'reg_alpha': 7.722447692966574, 'reg_lambda': 1.987156815341724}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:04,599] Trial 8 finished with value: 1.9000330035492818 and parameters: {'n_estimators': 100, 'learning_rate': 0.1601531217136121, 'max_depth': 12, 'num_leaves': 190, 'min_child_samples': 79, 'subsample': 0.6296178606936361, 'colsample_bytree': 0.7433862914177091, 'reg_alpha': 1.1586905952512971, 'reg_lambda': 8.631034258755935}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:05,878] Trial 9 finished with value: 2.0251400178359726 and parameters: {'n_estimators': 650, 'learning_rate': 0.030816017044468066, 'max_depth': 3, 'num_leaves': 89, 'min_child_samples': 36, 'subsample': 0.8918424713352255, 'colsample_bytree': 0.8550229885420852, 'reg_alpha': 8.872127425763265, 'reg_lambda': 4.722149251619493}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:14,368] Trial 10 finished with value: 1.8726146373226744 and parameters: {'n_estimators': 1000, 'learning_rate': 0.010206070557577008, 'max_depth': 15, 'num_leaves': 244, 'min_child_samples': 59, 'subsample': 0.876098829427658, 'colsample_bytree': 0.7021773835060796, 'reg_alpha': 4.040260720186448, 'reg_lambda': 4.792951727359478}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:18,727] Trial 11 finished with value: 1.8632690444562505 and parameters: {'n_estimators': 900, 'learning_rate': 0.05192545113847505, 'max_depth': 7, 'num_leaves': 228, 'min_child_samples': 48, 'subsample': 0.9831904699630576, 'colsample_bytree': 0.8890237037952976, 'reg_alpha': 5.732909776512291, 'reg_lambda': 9.981775739199884}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:23,108] Trial 12 finished with value: 1.887981014107202 and parameters: {'n_estimators': 750, 'learning_rate': 0.016324514507051233, 'max_depth': 7, 'num_leaves': 205, 'min_child_samples': 35, 'subsample': 0.9683188126021011, 'colsample_bytree': 0.8997607110419878, 'reg_alpha': 5.741682198643653, 'reg_lambda': 6.423826776354142}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:29,101] Trial 13 finished with value: 1.8517109838805255 and parameters: {'n_estimators': 850, 'learning_rate': 0.05748699526284608, 'max_depth': 15, 'num_leaves': 120, 'min_child_samples': 61, 'subsample': 0.8600904642990117, 'colsample_bytree': 0.6966219731921359, 'reg_alpha': 0.7867968644475858, 'reg_lambda': 3.454668886882282}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:33,076] Trial 14 finished with value: 1.8989161312343417 and parameters: {'n_estimators': 750, 'learning_rate': 0.017144316786395827, 'max_depth': 7, 'num_leaves': 184, 'min_child_samples': 48, 'subsample': 0.7028953142543801, 'colsample_bytree': 0.827318128998343, 'reg_alpha': 3.51659680124457, 'reg_lambda': 6.795982412915362}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:36,166] Trial 15 finished with value: 1.9755153215546624 and parameters: {'n_estimators': 700, 'learning_rate': 0.01046523847842795, 'max_depth': 13, 'num_leaves': 17, 'min_child_samples': 6, 'subsample': 0.8052449957834974, 'colsample_bytree': 0.9304229184560635, 'reg_alpha': 6.705451426048862, 'reg_lambda': 9.772664655950779}. Best is trial 1 with value: 1.8268650409299259.\n",
      "[I 2025-09-28 14:45:41,601] Trial 16 finished with value: 1.8263886930587163 and parameters: {'n_estimators': 850, 'learning_rate': 0.0413029744324308, 'max_depth': 8, 'num_leaves': 151, 'min_child_samples': 29, 'subsample': 0.9438599500782205, 'colsample_bytree': 0.6728371142890298, 'reg_alpha': 2.0317492802821864, 'reg_lambda': 0.13179214380923554}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:45:45,057] Trial 17 finished with value: 1.853392631558424 and parameters: {'n_estimators': 1000, 'learning_rate': 0.09768906566028059, 'max_depth': 5, 'num_leaves': 215, 'min_child_samples': 31, 'subsample': 0.9342715124668821, 'colsample_bytree': 0.6656222143908919, 'reg_alpha': 2.3951225471837514, 'reg_lambda': 0.3187050352598851}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:45:49,717] Trial 18 finished with value: 1.8425144015685735 and parameters: {'n_estimators': 900, 'learning_rate': 0.040022352384840344, 'max_depth': 8, 'num_leaves': 100, 'min_child_samples': 43, 'subsample': 0.8005828061689466, 'colsample_bytree': 0.6687268138887317, 'reg_alpha': 1.8298315699622398, 'reg_lambda': 0.25038383154988175}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:45:51,811] Trial 19 finished with value: 1.8639376930588554 and parameters: {'n_estimators': 250, 'learning_rate': 0.11548688783855848, 'max_depth': 14, 'num_leaves': 253, 'min_child_samples': 66, 'subsample': 0.6846840582961851, 'colsample_bytree': 0.7282533642196176, 'reg_alpha': 4.255821096179198, 'reg_lambda': 3.8310442404828144}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:45:54,339] Trial 20 finished with value: 1.972807636454013 and parameters: {'n_estimators': 850, 'learning_rate': 0.020963669789959127, 'max_depth': 5, 'num_leaves': 185, 'min_child_samples': 94, 'subsample': 0.7590602526122234, 'colsample_bytree': 0.6555079757722394, 'reg_alpha': 0.11620961627553239, 'reg_lambda': 1.1708235317519229}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:45:59,238] Trial 21 finished with value: 1.8439193829352558 and parameters: {'n_estimators': 900, 'learning_rate': 0.04632089507760641, 'max_depth': 8, 'num_leaves': 96, 'min_child_samples': 42, 'subsample': 0.8124689051264062, 'colsample_bytree': 0.6618666813579508, 'reg_alpha': 2.1678656293291896, 'reg_lambda': 0.1254068983720285}. Best is trial 16 with value: 1.8263886930587163.\n",
      "[I 2025-09-28 14:46:05,807] Trial 22 finished with value: 1.8210518116411039 and parameters: {'n_estimators': 850, 'learning_rate': 0.03995709670865366, 'max_depth': 9, 'num_leaves': 100, 'min_child_samples': 26, 'subsample': 0.9261888917112227, 'colsample_bytree': 0.6962831044441021, 'reg_alpha': 1.4769870017632694, 'reg_lambda': 1.1544979113299274}. Best is trial 22 with value: 1.8210518116411039.\n",
      "[I 2025-09-28 14:46:12,529] Trial 23 finished with value: 1.8137406797109095 and parameters: {'n_estimators': 800, 'learning_rate': 0.037841319191774456, 'max_depth': 9, 'num_leaves': 123, 'min_child_samples': 25, 'subsample': 0.9244959097361198, 'colsample_bytree': 0.6023071564543114, 'reg_alpha': 3.1835034813518606, 'reg_lambda': 1.121125502925417}. Best is trial 23 with value: 1.8137406797109095.\n",
      "[I 2025-09-28 14:46:19,883] Trial 24 finished with value: 1.7960861035203084 and parameters: {'n_estimators': 600, 'learning_rate': 0.03652726785714283, 'max_depth': 9, 'num_leaves': 134, 'min_child_samples': 11, 'subsample': 0.9277990446681116, 'colsample_bytree': 0.60404359274921, 'reg_alpha': 1.4290809700689047, 'reg_lambda': 1.2966777264990053}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:27,659] Trial 25 finished with value: 1.798347514277615 and parameters: {'n_estimators': 600, 'learning_rate': 0.06444736172649977, 'max_depth': 10, 'num_leaves': 127, 'min_child_samples': 12, 'subsample': 0.9178583203561476, 'colsample_bytree': 0.6055590232716067, 'reg_alpha': 1.2795852374379102, 'reg_lambda': 1.5617131914558415}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:33,731] Trial 26 finished with value: 1.803209407021729 and parameters: {'n_estimators': 550, 'learning_rate': 0.07318612647442489, 'max_depth': 10, 'num_leaves': 131, 'min_child_samples': 13, 'subsample': 0.90306277322938, 'colsample_bytree': 0.6009720944843767, 'reg_alpha': 0.2532859527890263, 'reg_lambda': 2.793932786147309}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:41,165] Trial 27 finished with value: 1.7964498410783158 and parameters: {'n_estimators': 550, 'learning_rate': 0.08482963737537094, 'max_depth': 11, 'num_leaves': 135, 'min_child_samples': 10, 'subsample': 0.8427408320862595, 'colsample_bytree': 0.6314129027145786, 'reg_alpha': 0.024218930016196127, 'reg_lambda': 3.0775619225283055}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:48,001] Trial 28 finished with value: 1.8205970402586853 and parameters: {'n_estimators': 600, 'learning_rate': 0.13879799111703053, 'max_depth': 11, 'num_leaves': 79, 'min_child_samples': 7, 'subsample': 0.8426112655578385, 'colsample_bytree': 0.6424159409433047, 'reg_alpha': 0.9817362118347348, 'reg_lambda': 3.8243295302152926}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:53,678] Trial 29 finished with value: 1.813941578082602 and parameters: {'n_estimators': 450, 'learning_rate': 0.07289336185100301, 'max_depth': 12, 'num_leaves': 161, 'min_child_samples': 17, 'subsample': 0.8361873838744651, 'colsample_bytree': 0.6323960874659893, 'reg_alpha': 0.1034843896909674, 'reg_lambda': 1.7894926851389608}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:46:59,093] Trial 30 finished with value: 1.8344055004165143 and parameters: {'n_estimators': 300, 'learning_rate': 0.1854511994787191, 'max_depth': 11, 'num_leaves': 171, 'min_child_samples': 14, 'subsample': 0.9604867554037246, 'colsample_bytree': 0.6290870390531014, 'reg_alpha': 0.7797812534033308, 'reg_lambda': 2.6104435789462106}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:47:05,116] Trial 31 finished with value: 1.8043003788622134 and parameters: {'n_estimators': 550, 'learning_rate': 0.06963493798064131, 'max_depth': 10, 'num_leaves': 135, 'min_child_samples': 12, 'subsample': 0.8944288231516302, 'colsample_bytree': 0.60071133159985, 'reg_alpha': 0.0021451375058831323, 'reg_lambda': 3.0462618649597357}. Best is trial 24 with value: 1.7960861035203084.\n",
      "[I 2025-09-28 14:47:14,239] Trial 32 finished with value: 1.7950245982636173 and parameters: {'n_estimators': 500, 'learning_rate': 0.1014925112991695, 'max_depth': 11, 'num_leaves': 136, 'min_child_samples': 5, 'subsample': 0.9027793497320977, 'colsample_bytree': 0.6308046682980608, 'reg_alpha': 0.5887703617906848, 'reg_lambda': 2.9880410871937295}. Best is trial 32 with value: 1.7950245982636173.\n",
      "[I 2025-09-28 14:47:21,951] Trial 33 finished with value: 1.8055132039061852 and parameters: {'n_estimators': 450, 'learning_rate': 0.09635626746043115, 'max_depth': 13, 'num_leaves': 111, 'min_child_samples': 6, 'subsample': 0.8645803094177995, 'colsample_bytree': 0.6347034669569758, 'reg_alpha': 1.6670388097318405, 'reg_lambda': 1.7005579056884845}. Best is trial 32 with value: 1.7950245982636173.\n",
      "[I 2025-09-28 14:47:28,256] Trial 34 finished with value: 1.827957206014765 and parameters: {'n_estimators': 500, 'learning_rate': 0.09624491942187804, 'max_depth': 12, 'num_leaves': 142, 'min_child_samples': 19, 'subsample': 0.9077938428282625, 'colsample_bytree': 0.7161457519086983, 'reg_alpha': 0.7913682015947623, 'reg_lambda': 4.154901179547752}. Best is trial 32 with value: 1.7950245982636173.\n",
      "[I 2025-09-28 14:47:41,078] Trial 35 finished with value: 1.7875467798939233 and parameters: {'n_estimators': 600, 'learning_rate': 0.06105643351607285, 'max_depth': 11, 'num_leaves': 174, 'min_child_samples': 5, 'subsample': 0.958695533183044, 'colsample_bytree': 0.6293717435842083, 'reg_alpha': 1.5392312387651277, 'reg_lambda': 5.649431370227012}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:47:52,142] Trial 36 finished with value: 1.8256287086355687 and parameters: {'n_estimators': 500, 'learning_rate': 0.11480650840403012, 'max_depth': 13, 'num_leaves': 176, 'min_child_samples': 5, 'subsample': 0.9998283547111023, 'colsample_bytree': 0.7669699924693705, 'reg_alpha': 2.5564421131542545, 'reg_lambda': 6.045137292167471}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:47:57,552] Trial 37 finished with value: 1.8174696293742936 and parameters: {'n_estimators': 400, 'learning_rate': 0.08499452080097199, 'max_depth': 11, 'num_leaves': 153, 'min_child_samples': 21, 'subsample': 0.959551402346081, 'colsample_bytree': 0.6454078948307838, 'reg_alpha': 3.6300203858142965, 'reg_lambda': 5.35583517782748}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:07,334] Trial 38 finished with value: 1.8573627820490504 and parameters: {'n_estimators': 650, 'learning_rate': 0.2581932153615473, 'max_depth': 14, 'num_leaves': 165, 'min_child_samples': 10, 'subsample': 0.7740355078153208, 'colsample_bytree': 0.6879163360980132, 'reg_alpha': 0.5853586465465899, 'reg_lambda': 5.361646981082474}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:15,774] Trial 39 finished with value: 1.8143560251034831 and parameters: {'n_estimators': 600, 'learning_rate': 0.053827231501156154, 'max_depth': 11, 'num_leaves': 200, 'min_child_samples': 17, 'subsample': 0.8355560148961885, 'colsample_bytree': 0.6252794705695325, 'reg_alpha': 3.0069327090422244, 'reg_lambda': 6.997154359563419}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:20,177] Trial 40 finished with value: 1.8316431378366165 and parameters: {'n_estimators': 350, 'learning_rate': 0.032906809104679496, 'max_depth': 12, 'num_leaves': 113, 'min_child_samples': 26, 'subsample': 0.8827735538060053, 'colsample_bytree': 0.7810813763007055, 'reg_alpha': 1.3555829473386425, 'reg_lambda': 2.317984717463476}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:27,586] Trial 41 finished with value: 1.802254813322694 and parameters: {'n_estimators': 600, 'learning_rate': 0.060389017303852245, 'max_depth': 10, 'num_leaves': 138, 'min_child_samples': 12, 'subsample': 0.9144232921319316, 'colsample_bytree': 0.6171940570053126, 'reg_alpha': 1.468812003797067, 'reg_lambda': 4.310083615613215}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:33,428] Trial 42 finished with value: 1.816448938461288 and parameters: {'n_estimators': 550, 'learning_rate': 0.12344562583925744, 'max_depth': 9, 'num_leaves': 129, 'min_child_samples': 10, 'subsample': 0.9449213497838743, 'colsample_bytree': 0.6167657932377505, 'reg_alpha': 0.5489896144540215, 'reg_lambda': 3.2467259842800678}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:45,701] Trial 43 finished with value: 1.7976030371474252 and parameters: {'n_estimators': 700, 'learning_rate': 0.0653328635139825, 'max_depth': 10, 'num_leaves': 151, 'min_child_samples': 5, 'subsample': 0.8572638367618036, 'colsample_bytree': 0.6484169953458258, 'reg_alpha': 1.2082178333226872, 'reg_lambda': 0.7480565013461902}. Best is trial 35 with value: 1.7875467798939233.\n",
      "[I 2025-09-28 14:48:58,871] Trial 44 finished with value: 1.780934542522625 and parameters: {'n_estimators': 700, 'learning_rate': 0.024367900255525585, 'max_depth': 11, 'num_leaves': 151, 'min_child_samples': 5, 'subsample': 0.8572728441973634, 'colsample_bytree': 0.651634380650459, 'reg_alpha': 2.1792284271022506, 'reg_lambda': 0.7207472085459188}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:06,990] Trial 45 finished with value: 1.8142258426972675 and parameters: {'n_estimators': 650, 'learning_rate': 0.024059087036625945, 'max_depth': 11, 'num_leaves': 172, 'min_child_samples': 20, 'subsample': 0.8812307724114634, 'colsample_bytree': 0.6806219411426233, 'reg_alpha': 4.986430469169311, 'reg_lambda': 2.2301262363810825}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:12,516] Trial 46 finished with value: 1.826176165017602 and parameters: {'n_estimators': 500, 'learning_rate': 0.022852602136045765, 'max_depth': 12, 'num_leaves': 78, 'min_child_samples': 15, 'subsample': 0.8224686559782279, 'colsample_bytree': 0.7161979355192917, 'reg_alpha': 1.938606069038743, 'reg_lambda': 7.412249228049565}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:19,508] Trial 47 finished with value: 1.8406677019018076 and parameters: {'n_estimators': 700, 'learning_rate': 0.013105114650940854, 'max_depth': 9, 'num_leaves': 112, 'min_child_samples': 23, 'subsample': 0.972945194055335, 'colsample_bytree': 0.6530080283483485, 'reg_alpha': 8.359030379476579, 'reg_lambda': 0.6721782065946483}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:28,570] Trial 48 finished with value: 1.8030907827797478 and parameters: {'n_estimators': 450, 'learning_rate': 0.03420153172565847, 'max_depth': 13, 'num_leaves': 143, 'min_child_samples': 9, 'subsample': 0.8665986546066187, 'colsample_bytree': 0.8131810067009912, 'reg_alpha': 2.8036768783910415, 'reg_lambda': 5.686755113534238}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:32,284] Trial 49 finished with value: 1.8805485857269963 and parameters: {'n_estimators': 650, 'learning_rate': 0.02900586671036829, 'max_depth': 11, 'num_leaves': 158, 'min_child_samples': 73, 'subsample': 0.9398900365418068, 'colsample_bytree': 0.7439358105636079, 'reg_alpha': 0.4307641049979498, 'reg_lambda': 4.519402008720546}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:44,798] Trial 50 finished with value: 1.8041342579280049 and parameters: {'n_estimators': 750, 'learning_rate': 0.04602912502259053, 'max_depth': 14, 'num_leaves': 206, 'min_child_samples': 16, 'subsample': 0.8450454121361648, 'colsample_bytree': 0.6252392294414403, 'reg_alpha': 0.9725387549739426, 'reg_lambda': 3.680151122066185}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:49:56,158] Trial 51 finished with value: 1.796205938712843 and parameters: {'n_estimators': 700, 'learning_rate': 0.08020717843696457, 'max_depth': 10, 'num_leaves': 151, 'min_child_samples': 7, 'subsample': 0.8566773577935836, 'colsample_bytree': 0.6487468640574862, 'reg_alpha': 1.1575541652345065, 'reg_lambda': 0.7233960870507797}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:08,271] Trial 52 finished with value: 1.7891578609156462 and parameters: {'n_estimators': 750, 'learning_rate': 0.08251941634224338, 'max_depth': 10, 'num_leaves': 180, 'min_child_samples': 5, 'subsample': 0.8902347412332453, 'colsample_bytree': 0.6774678251146462, 'reg_alpha': 2.37141006651054, 'reg_lambda': 0.8803423882507507}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:17,556] Trial 53 finished with value: 1.811552995695679 and parameters: {'n_estimators': 800, 'learning_rate': 0.08499966067639816, 'max_depth': 8, 'num_leaves': 195, 'min_child_samples': 8, 'subsample': 0.8949145338369402, 'colsample_bytree': 0.6793633749772412, 'reg_alpha': 2.286068831468658, 'reg_lambda': 0.7147300473375493}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:29,812] Trial 54 finished with value: 1.7822025576212712 and parameters: {'n_estimators': 750, 'learning_rate': 0.018978168086366296, 'max_depth': 9, 'num_leaves': 178, 'min_child_samples': 5, 'subsample': 0.9521249339430254, 'colsample_bytree': 0.6614332990979789, 'reg_alpha': 1.8205100544882704, 'reg_lambda': 1.360914304254885}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:48,402] Trial 55 finished with value: 1.8036116657826908 and parameters: {'n_estimators': 800, 'learning_rate': 0.02129549777732679, 'max_depth': 9, 'num_leaves': 178, 'min_child_samples': 5, 'subsample': 0.9876428108541149, 'colsample_bytree': 0.951513965505689, 'reg_alpha': 3.3635948554460873, 'reg_lambda': 1.3384293926919493}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:52,239] Trial 56 finished with value: 1.883447077477759 and parameters: {'n_estimators': 700, 'learning_rate': 0.01804698296454851, 'max_depth': 6, 'num_leaves': 189, 'min_child_samples': 18, 'subsample': 0.9570378819979793, 'colsample_bytree': 0.865949221338295, 'reg_alpha': 1.8454549321605396, 'reg_lambda': 2.053973310435228}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:50:53,036] Trial 57 finished with value: 2.4973462591439715 and parameters: {'n_estimators': 100, 'learning_rate': 0.01277052851718179, 'max_depth': 8, 'num_leaves': 167, 'min_child_samples': 97, 'subsample': 0.6056470054581535, 'colsample_bytree': 0.6676504810208687, 'reg_alpha': 3.8955983329788553, 'reg_lambda': 0.4547305274474258}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:02,668] Trial 58 finished with value: 1.8006780731959378 and parameters: {'n_estimators': 750, 'learning_rate': 0.02702940452080648, 'max_depth': 9, 'num_leaves': 224, 'min_child_samples': 13, 'subsample': 0.9468812841389884, 'colsample_bytree': 0.710138905740827, 'reg_alpha': 2.685116335622184, 'reg_lambda': 1.4178339907669715}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:06,622] Trial 59 finished with value: 1.9010715077226519 and parameters: {'n_estimators': 800, 'learning_rate': 0.015593744061025787, 'max_depth': 7, 'num_leaves': 182, 'min_child_samples': 55, 'subsample': 0.9303227357347869, 'colsample_bytree': 0.6949479480205984, 'reg_alpha': 2.1437259472304966, 'reg_lambda': 0.9295588970795112}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:18,201] Trial 60 finished with value: 1.8003049772757822 and parameters: {'n_estimators': 600, 'learning_rate': 0.018990651473811793, 'max_depth': 10, 'num_leaves': 215, 'min_child_samples': 9, 'subsample': 0.9751340515616584, 'colsample_bytree': 0.6618249805190778, 'reg_alpha': 6.966136290011652, 'reg_lambda': 1.8739220114312096}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:32,421] Trial 61 finished with value: 1.79003831009948 and parameters: {'n_estimators': 700, 'learning_rate': 0.049150764320942376, 'max_depth': 10, 'num_leaves': 147, 'min_child_samples': 5, 'subsample': 0.9042568810678551, 'colsample_bytree': 0.6156899896229675, 'reg_alpha': 1.65515220015713, 'reg_lambda': 0.45799661946111836}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:44,468] Trial 62 finished with value: 1.7975856978619036 and parameters: {'n_estimators': 750, 'learning_rate': 0.04921816339038759, 'max_depth': 10, 'num_leaves': 162, 'min_child_samples': 10, 'subsample': 0.9083036126381768, 'colsample_bytree': 0.6159696744073541, 'reg_alpha': 1.5824928092422734, 'reg_lambda': 0.3356241563428678}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:51:55,384] Trial 63 finished with value: 1.7945379379658284 and parameters: {'n_estimators': 650, 'learning_rate': 0.043877212480391156, 'max_depth': 9, 'num_leaves': 145, 'min_child_samples': 5, 'subsample': 0.8823632497012668, 'colsample_bytree': 0.6406685257057769, 'reg_alpha': 4.424877306640498, 'reg_lambda': 1.0596943620362635}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:06,135] Trial 64 finished with value: 1.8088728203591757 and parameters: {'n_estimators': 650, 'learning_rate': 0.043405128757930136, 'max_depth': 12, 'num_leaves': 146, 'min_child_samples': 15, 'subsample': 0.8749086405468098, 'colsample_bytree': 0.6438989988873884, 'reg_alpha': 4.414786514784637, 'reg_lambda': 4.994228175122345}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:09,656] Trial 65 finished with value: 1.9144809014391453 and parameters: {'n_estimators': 650, 'learning_rate': 0.29866373378393074, 'max_depth': 11, 'num_leaves': 158, 'min_child_samples': 38, 'subsample': 0.8917239285143884, 'colsample_bytree': 0.6715059430587643, 'reg_alpha': 5.891726690828682, 'reg_lambda': 0.9922500441635582}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:18,709] Trial 66 finished with value: 1.7958212700857092 and parameters: {'n_estimators': 750, 'learning_rate': 0.05675567754247479, 'max_depth': 8, 'num_leaves': 193, 'min_child_samples': 7, 'subsample': 0.9145148795514929, 'colsample_bytree': 0.6393167696084658, 'reg_alpha': 2.9738863170692316, 'reg_lambda': 0.11655832544384881}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:24,553] Trial 67 finished with value: 1.8238071270799807 and parameters: {'n_estimators': 950, 'learning_rate': 0.16376891708516336, 'max_depth': 10, 'num_leaves': 173, 'min_child_samples': 5, 'subsample': 0.8190702644376182, 'colsample_bytree': 0.688437693514348, 'reg_alpha': 4.650174495089159, 'reg_lambda': 1.511488436634572}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:37,565] Trial 68 finished with value: 1.7950274305256637 and parameters: {'n_estimators': 700, 'learning_rate': 0.011450120074863368, 'max_depth': 11, 'num_leaves': 186, 'min_child_samples': 14, 'subsample': 0.8998274569869263, 'colsample_bytree': 0.733014685146672, 'reg_alpha': 2.395761624169423, 'reg_lambda': 0.020361532402454863}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:41,169] Trial 69 finished with value: 1.8318040721852635 and parameters: {'n_estimators': 750, 'learning_rate': 0.050927496063697675, 'max_depth': 9, 'num_leaves': 27, 'min_child_samples': 22, 'subsample': 0.875882470883823, 'colsample_bytree': 0.657951117950372, 'reg_alpha': 1.7973366731648313, 'reg_lambda': 2.4306999715527713}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:42,496] Trial 70 finished with value: 1.8433120618091479 and parameters: {'n_estimators': 150, 'learning_rate': 0.1067824910607192, 'max_depth': 9, 'num_leaves': 154, 'min_child_samples': 29, 'subsample': 0.951253410597494, 'colsample_bytree': 0.6136571106163617, 'reg_alpha': 5.538250187169726, 'reg_lambda': 0.46985855565286483}. Best is trial 44 with value: 1.780934542522625.\n",
      "[I 2025-09-28 14:52:57,438] Trial 71 finished with value: 1.7796772321396432 and parameters: {'n_estimators': 700, 'learning_rate': 0.014690938828384301, 'max_depth': 11, 'num_leaves': 184, 'min_child_samples': 8, 'subsample': 0.9037738193545155, 'colsample_bytree': 0.6325233891007582, 'reg_alpha': 2.406959858268811, 'reg_lambda': 0.11515099352172231}. Best is trial 71 with value: 1.7796772321396432.\n",
      "[I 2025-09-28 14:53:12,813] Trial 72 finished with value: 1.7845788874327464 and parameters: {'n_estimators': 800, 'learning_rate': 0.014300390674333044, 'max_depth': 11, 'num_leaves': 166, 'min_child_samples': 8, 'subsample': 0.8864179703268017, 'colsample_bytree': 0.6353731657292011, 'reg_alpha': 2.5281141971636547, 'reg_lambda': 1.095043888157415}. Best is trial 71 with value: 1.7796772321396432.\n",
      "[I 2025-09-28 14:53:27,692] Trial 73 finished with value: 1.7858545493156988 and parameters: {'n_estimators': 850, 'learning_rate': 0.014542314557827696, 'max_depth': 10, 'num_leaves': 180, 'min_child_samples': 8, 'subsample': 0.922632337127811, 'colsample_bytree': 0.6358967132466277, 'reg_alpha': 2.4979265065860203, 'reg_lambda': 0.9762164975584293}. Best is trial 71 with value: 1.7796772321396432.\n",
      "[I 2025-09-28 14:53:47,247] Trial 74 finished with value: 1.7777039657528317 and parameters: {'n_estimators': 850, 'learning_rate': 0.014894401459148393, 'max_depth': 12, 'num_leaves': 180, 'min_child_samples': 8, 'subsample': 0.9231652141032185, 'colsample_bytree': 0.655906734691294, 'reg_alpha': 2.513837453306293, 'reg_lambda': 0.4527479758489359}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:54:07,448] Trial 75 finished with value: 1.7822676509732847 and parameters: {'n_estimators': 900, 'learning_rate': 0.015220677972987175, 'max_depth': 12, 'num_leaves': 209, 'min_child_samples': 9, 'subsample': 0.9229776262784481, 'colsample_bytree': 0.6799518548165743, 'reg_alpha': 3.2627651094849717, 'reg_lambda': 0.9268837563182242}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:54:25,202] Trial 76 finished with value: 1.795688407572476 and parameters: {'n_estimators': 950, 'learning_rate': 0.015028870212308525, 'max_depth': 12, 'num_leaves': 208, 'min_child_samples': 12, 'subsample': 0.9354116252819179, 'colsample_bytree': 0.6575439665217114, 'reg_alpha': 3.1921135595717693, 'reg_lambda': 6.2013559234628755}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:54:30,553] Trial 77 finished with value: 1.9112552579730455 and parameters: {'n_estimators': 900, 'learning_rate': 0.011776186739493533, 'max_depth': 12, 'num_leaves': 199, 'min_child_samples': 90, 'subsample': 0.9185831013396424, 'colsample_bytree': 0.6286310189932006, 'reg_alpha': 2.667546553017037, 'reg_lambda': 1.5796099886902941}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:54:44,493] Trial 78 finished with value: 1.807322883980333 and parameters: {'n_estimators': 850, 'learning_rate': 0.014145101706690111, 'max_depth': 13, 'num_leaves': 166, 'min_child_samples': 18, 'subsample': 0.9662899357993026, 'colsample_bytree': 0.7032363231154354, 'reg_alpha': 3.47252458891459, 'reg_lambda': 0.5538682892031934}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:55:04,708] Trial 79 finished with value: 1.7870094883435328 and parameters: {'n_estimators': 800, 'learning_rate': 0.01694938510344247, 'max_depth': 13, 'num_leaves': 226, 'min_child_samples': 9, 'subsample': 0.9272857693081786, 'colsample_bytree': 0.6872822900145815, 'reg_alpha': 3.747147733496929, 'reg_lambda': 1.2361062531142737}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:55:26,584] Trial 80 finished with value: 1.7871331094613132 and parameters: {'n_estimators': 850, 'learning_rate': 0.019180467025769768, 'max_depth': 13, 'num_leaves': 239, 'min_child_samples': 9, 'subsample': 0.9332648624692972, 'colsample_bytree': 0.6677335511462245, 'reg_alpha': 3.9143944205705212, 'reg_lambda': 1.3081357431917078}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:55:52,081] Trial 81 finished with value: 1.7850062297687685 and parameters: {'n_estimators': 850, 'learning_rate': 0.016942418911531563, 'max_depth': 14, 'num_leaves': 237, 'min_child_samples': 8, 'subsample': 0.9254652727728438, 'colsample_bytree': 0.6872108627943025, 'reg_alpha': 3.7070598617208703, 'reg_lambda': 1.2544602971053112}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:56:14,210] Trial 82 finished with value: 1.7915405292925015 and parameters: {'n_estimators': 900, 'learning_rate': 0.016823505759645672, 'max_depth': 14, 'num_leaves': 232, 'min_child_samples': 11, 'subsample': 0.9242137097395068, 'colsample_bytree': 0.6872259230567436, 'reg_alpha': 3.072658076345786, 'reg_lambda': 1.787271761434012}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:56:36,096] Trial 83 finished with value: 1.801886713143506 and parameters: {'n_estimators': 950, 'learning_rate': 0.010060350118956125, 'max_depth': 15, 'num_leaves': 246, 'min_child_samples': 15, 'subsample': 0.9191847766689932, 'colsample_bytree': 0.7047542043076402, 'reg_alpha': 3.6120909364296674, 'reg_lambda': 2.054208611663292}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:56:57,812] Trial 84 finished with value: 1.780235240317119 and parameters: {'n_estimators': 800, 'learning_rate': 0.014418348333460118, 'max_depth': 14, 'num_leaves': 221, 'min_child_samples': 8, 'subsample': 0.7803719850328714, 'colsample_bytree': 0.6585432760448088, 'reg_alpha': 2.846572502487028, 'reg_lambda': 1.0928577105470292}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:57:17,710] Trial 85 finished with value: 1.7868309501061153 and parameters: {'n_estimators': 850, 'learning_rate': 0.014410428740010039, 'max_depth': 15, 'num_leaves': 234, 'min_child_samples': 13, 'subsample': 0.8015775865105863, 'colsample_bytree': 0.6543242167458113, 'reg_alpha': 2.866073600265702, 'reg_lambda': 1.0794422281415406}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:57:40,967] Trial 86 finished with value: 1.8076356136471456 and parameters: {'n_estimators': 900, 'learning_rate': 0.012593342470110812, 'max_depth': 14, 'num_leaves': 210, 'min_child_samples': 8, 'subsample': 0.7800100336637908, 'colsample_bytree': 0.725963730828962, 'reg_alpha': 9.908412605276453, 'reg_lambda': 0.27372508097311177}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:57:54,732] Trial 87 finished with value: 1.8032277813435507 and parameters: {'n_estimators': 800, 'learning_rate': 0.020690983335894336, 'max_depth': 14, 'num_leaves': 252, 'min_child_samples': 19, 'subsample': 0.73070971458291, 'colsample_bytree': 0.6391137340897948, 'reg_alpha': 2.5205768541691964, 'reg_lambda': 0.9366736897164916}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:58:10,526] Trial 88 finished with value: 1.8166878740675902 and parameters: {'n_estimators': 1000, 'learning_rate': 0.011607997145679227, 'max_depth': 12, 'num_leaves': 223, 'min_child_samples': 16, 'subsample': 0.7524234066988784, 'colsample_bytree': 0.6747317689815081, 'reg_alpha': 3.2511018793089543, 'reg_lambda': 9.422069282816661}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:58:21,698] Trial 89 finished with value: 1.8192992102365388 and parameters: {'n_estimators': 800, 'learning_rate': 0.013599469115792327, 'max_depth': 12, 'num_leaves': 217, 'min_child_samples': 24, 'subsample': 0.776318071457558, 'colsample_bytree': 0.6636443517631954, 'reg_alpha': 2.021011426726789, 'reg_lambda': 1.6677520122698373}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:58:37,461] Trial 90 finished with value: 1.7900390343573391 and parameters: {'n_estimators': 950, 'learning_rate': 0.015463479284674791, 'max_depth': 11, 'num_leaves': 189, 'min_child_samples': 12, 'subsample': 0.9390725376907555, 'colsample_bytree': 0.6496468361268783, 'reg_alpha': 2.2421302324394023, 'reg_lambda': 0.6786969215488549}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:59:01,831] Trial 91 finished with value: 1.7803804092722566 and parameters: {'n_estimators': 850, 'learning_rate': 0.01424815433500598, 'max_depth': 15, 'num_leaves': 234, 'min_child_samples': 8, 'subsample': 0.7992206609541216, 'colsample_bytree': 0.6508557114666095, 'reg_alpha': 2.7300305959194735, 'reg_lambda': 1.138740158360279}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:59:23,850] Trial 92 finished with value: 1.7802334835383764 and parameters: {'n_estimators': 850, 'learning_rate': 0.018358013936443335, 'max_depth': 15, 'num_leaves': 200, 'min_child_samples': 8, 'subsample': 0.7906389839855452, 'colsample_bytree': 0.6367212973896418, 'reg_alpha': 2.823998975417023, 'reg_lambda': 0.3039669265781436}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 14:59:47,795] Trial 93 finished with value: 1.7802519014428302 and parameters: {'n_estimators': 900, 'learning_rate': 0.017997988979199516, 'max_depth': 15, 'num_leaves': 203, 'min_child_samples': 7, 'subsample': 0.7690713236758518, 'colsample_bytree': 0.6528640260576329, 'reg_alpha': 2.8350616216610725, 'reg_lambda': 0.074165679851949}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 15:00:08,825] Trial 94 finished with value: 1.7876791966766827 and parameters: {'n_estimators': 900, 'learning_rate': 0.024355291992525605, 'max_depth': 15, 'num_leaves': 199, 'min_child_samples': 11, 'subsample': 0.7662731094673427, 'colsample_bytree': 0.60934455162677, 'reg_alpha': 2.8899125751174775, 'reg_lambda': 0.04953344949638962}. Best is trial 74 with value: 1.7777039657528317.\n",
      "[I 2025-09-28 15:00:29,555] Trial 95 finished with value: 1.7744565175605778 and parameters: {'n_estimators': 800, 'learning_rate': 0.018829031543052318, 'max_depth': 15, 'num_leaves': 202, 'min_child_samples': 7, 'subsample': 0.790482146446866, 'colsample_bytree': 0.6231804830313077, 'reg_alpha': 2.095487778593813, 'reg_lambda': 0.4035925553970658}. Best is trial 95 with value: 1.7744565175605778.\n",
      "[I 2025-09-28 15:00:48,423] Trial 96 finished with value: 1.7919856027871046 and parameters: {'n_estimators': 850, 'learning_rate': 0.018230790345383486, 'max_depth': 15, 'num_leaves': 219, 'min_child_samples': 14, 'subsample': 0.7914242802601009, 'colsample_bytree': 0.6498917580645386, 'reg_alpha': 2.0563384937080373, 'reg_lambda': 0.3087400169831582}. Best is trial 95 with value: 1.7744565175605778.\n",
      "[I 2025-09-28 15:01:12,688] Trial 97 finished with value: 1.7795644284444072 and parameters: {'n_estimators': 900, 'learning_rate': 0.019758099626756467, 'max_depth': 15, 'num_leaves': 212, 'min_child_samples': 7, 'subsample': 0.784767171162147, 'colsample_bytree': 0.6182174838497345, 'reg_alpha': 2.805178419977052, 'reg_lambda': 0.6390870828723819}. Best is trial 95 with value: 1.7744565175605778.\n",
      "[I 2025-09-28 15:01:40,252] Trial 98 finished with value: 1.782409793639117 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022210963864105187, 'max_depth': 15, 'num_leaves': 212, 'min_child_samples': 7, 'subsample': 0.7378902892005683, 'colsample_bytree': 0.6097177618041012, 'reg_alpha': 2.7736038244599848, 'reg_lambda': 0.5936963895849992}. Best is trial 95 with value: 1.7744565175605778.\n",
      "[I 2025-09-28 15:02:02,057] Trial 99 finished with value: 1.7858463841387535 and parameters: {'n_estimators': 950, 'learning_rate': 0.019872316140933106, 'max_depth': 15, 'num_leaves': 202, 'min_child_samples': 11, 'subsample': 0.7858513520197481, 'colsample_bytree': 0.6250483797951499, 'reg_alpha': 2.1624570824144493, 'reg_lambda': 0.27616952741148737}. Best is trial 95 with value: 1.7744565175605778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最佳参数组合:\n",
      "n_estimators: 800\n",
      "learning_rate: 0.018829031543052318\n",
      "max_depth: 15\n",
      "num_leaves: 202\n",
      "min_child_samples: 7\n",
      "subsample: 0.790482146446866\n",
      "colsample_bytree: 0.6231804830313077\n",
      "reg_alpha: 2.095487778593813\n",
      "reg_lambda: 0.4035925553970658\n",
      "最佳验证RMSE: 1.7745\n",
      "优化历史数据已保存至: optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_LGBM_history.csv\n",
      "优化过程图保存至: optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_LGBM_history.png\n",
      "警告: plotly未安装，跳过等高线图绘制\n",
      "\n",
      "训练最终模型...\n",
      "\n",
      "测试集评估...\n",
      "测试集 RMSE: 1.7920\n",
      "测试集 R²: 0.8722\n",
      "测试集对应原始行已保存至: test_data/test_rows_6VOD_LAI_PFTs_Hveg_LGBM_Model.csv\n",
      "预测图保存至: figures/prediction_results_6VOD_LAI_PFTs_Hveg_LGBM_6VOD_LAI_PFTs_Hveg.png\n",
      "模型已保存至: models/LGBM_6VOD_LAI_PFTs_Hveg.pkl\n",
      "特征重要性图保存至: figures/feature_importance_6VOD_LAI_PFTs_Hveg_LGBM.png\n",
      "特征重要性数据已保存至: figures/feature_importance_6VOD_LAI_PFTs_Hveg_LGBM.csv\n",
      "\n",
      "Top 10特征重要性:\n",
      "1. LAI: 16151.0000\n",
      "2. VOD_Ku_Vpol_Asc: 15417.0000\n",
      "3. VOD_X_Vpol_Asc: 14521.0000\n",
      "4. VOD_Ku_Hpol_Asc: 14261.0000\n",
      "5. VOD_C_Vpol_Asc: 13688.0000\n",
      "6. VOD_C_Hpol_Asc: 13347.0000\n",
      "7. VOD_X_Hpol_Asc: 12752.0000\n",
      "8. Tree_ne: 11288.0000\n",
      "9. Shrub_ne: 11186.0000\n",
      "10. Grass_nat: 9889.0000\n",
      "\n",
      "================================================================================\n",
      "模型训练完成!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb  # 替换为LightGBM\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 全局文件路径常量\n",
    "DATA_FILE_PATH = r\"G:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\"\n",
    "\n",
    "def load_and_preprocess_selected_data():\n",
    "    \"\"\"数据加载函数 - 只选择6个VOD、LAI、Hveg和10个PFT特征，不进行归一化\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    print(f\"加载数据集: {DATA_FILE_PATH}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 定义所有需要的列\n",
    "    vod_columns = [\n",
    "        'VOD_Ku_Hpol_Asc', 'VOD_Ku_Vpol_Asc',\n",
    "        'VOD_X_Hpol_Asc', 'VOD_X_Vpol_Asc',\n",
    "        'VOD_C_Hpol_Asc', 'VOD_C_Vpol_Asc'\n",
    "    ]\n",
    "    \n",
    "    pft_columns = [\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    required_columns = [\n",
    "        'AGB', 'LFMCValue', 'SamplingDate',  # 用于计算目标变量\n",
    "        'LAI', 'Hveg'  # 主要特征\n",
    "    ] + vod_columns + pft_columns\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_excel(DATA_FILE_PATH, usecols=required_columns)\n",
    "    \n",
    "    # === 数据类型诊断 ===\n",
    "    print(\"\\n初始数据类型:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # 确定需要转换为 float64 的列\n",
    "    columns_to_convert = [col for col in df.columns if col != 'SamplingDate']\n",
    "    \n",
    "    # 清洗并转换为 float64\n",
    "    for col in columns_to_convert:\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            print(f\"清洗并转换列: {col} (当前类型: {df[col].dtype}) 为 float64\")\n",
    "            # 转字符串，去掉空格、逗号、制表符等干扰字符\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"[^\\d\\.\\-eE]\", \"\", regex=True)\n",
    "                .replace({\"\": np.nan})\n",
    "            )\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif df[col].dtype != 'float64':\n",
    "            df[col] = df[col].astype('float64')\n",
    "    \n",
    "    # 检查缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 数据中存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 计算 VWC_sample\n",
    "    df['VWC_sample'] = (df['AGB'] * df['LFMCValue']) / 1000\n",
    "    df['VWC_sample'] = pd.to_numeric(df['VWC_sample'], errors='coerce')\n",
    "    \n",
    "    # 再次清理缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 类型转换后存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 过滤 VWC_sample\n",
    "    df = df[df['VWC_sample'] <= 30]\n",
    "    \n",
    "    # 特征工程\n",
    "    if 'SamplingDate' in df and pd.api.types.is_datetime64_any_dtype(df['SamplingDate']):\n",
    "        df['Year_diff'] = df['SamplingDate'].dt.year.apply(lambda x: 2020 - x)\n",
    "    else:\n",
    "        print(\"警告: SamplingDate列不存在或不是日期类型，跳过年份差计算\")\n",
    "    \n",
    "    # 定义特征列\n",
    "    feature_columns = vod_columns + ['LAI', 'Hveg'] + pft_columns\n",
    "    available_features = [col for col in feature_columns if col in df]\n",
    "    missing_features = set(feature_columns) - set(available_features)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"警告: 以下特征不存在: {missing_features}\")\n",
    "    \n",
    "    if not available_features:\n",
    "        raise ValueError(\"错误: 没有找到任何特征列\")\n",
    "    \n",
    "    X = df[available_features]\n",
    "    y = df['VWC_sample']\n",
    "    \n",
    "    # 最终检查\n",
    "    print(\"\\n最终数据类型:\")\n",
    "    print(X.dtypes)\n",
    "    print(f\"目标变量类型: {y.dtype}\")\n",
    "    print(f\"数据预处理完成, 耗时: {(time.time()-start_time)/60:.2f}分钟\")\n",
    "    print(f\"使用特征: {len(available_features)}个 (6 VOD, 1 LAI, 1 Hveg, 10 PFT)\")\n",
    "    print(f\"样本数量: {len(X)}\")\n",
    "    \n",
    "    return X, y, df.index\n",
    "\n",
    "def objective(trial, X_train, y_train):\n",
    "    \"\"\"贝叶斯优化目标函数 - 修改为LightGBM超参数\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 255),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': SEED,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1  # 静默模式\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)  # 使用LightGBM模型\n",
    "    \n",
    "    # 五折交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "def plot_results_all(y_true, y_pred, filename):\n",
    "    \"\"\"结果可视化函数（更新文件名后缀）\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # 计算RMSE和R2指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 绘制散点图\n",
    "    plt.scatter(\n",
    "        y_true, y_pred,\n",
    "        marker='x',\n",
    "        color='#FF0000',\n",
    "        linewidths=0.5,\n",
    "        s=40,\n",
    "        alpha=0.8,\n",
    "        zorder=2\n",
    "    )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围和标签\n",
    "    plt.xlim(0, max_val + 1)\n",
    "    plt.ylim(0, max_val + 1)\n",
    "    plt.xlabel('Insitu VWC (kg/m2)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('LightGBM VWC (kg/m2)', fontsize=12, fontweight='bold')  # 修改ylabel\n",
    "    \n",
    "    # 添加标题（更新后缀）\n",
    "    plt.title(\"6 VOD + LAI + PFTs + Hveg LightGBM Model\", fontsize=16, pad=20, fontweight='bold')  # 修改标题\n",
    "    \n",
    "    # 添加指标文本\n",
    "    plt.text(0.05, 0.95,\n",
    "             f'RMSE = {rmse:.3f} kg/m²\\nR² = {r2:.4f}',\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=12,\n",
    "             fontweight='bold',\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    # 网格线和样式调整\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像（更新后缀）\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    plot_path = f\"figures/{filename}_6VOD_LAI_PFTs_Hveg.png\"  # 更新后缀\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"预测图保存至: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_optimization_history(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化过程历史图并保存数据\"\"\"\n",
    "    # 创建优化历史数据框\n",
    "    history_df = pd.DataFrame({\n",
    "        'trial_number': [t.number for t in study.trials],\n",
    "        'value': [t.value for t in study.trials],\n",
    "        'params': [t.params for t in study.trials],\n",
    "        'state': [t.state for t in study.trials]\n",
    "    })\n",
    "    \n",
    "    # 保存优化历史到CSV\n",
    "    os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "    csv_path = f\"optimization_history/{filename_prefix}_history.csv\"\n",
    "    history_df.to_csv(csv_path, index=False)\n",
    "    print(f\"优化历史数据已保存至: {csv_path}\")\n",
    "    \n",
    "    # 提取所有有效试验的值\n",
    "    valid_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    values = [t.value for t in valid_trials]\n",
    "    best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "    \n",
    "    # 绘制优化过程图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 绘制当前试验值和历史最佳值\n",
    "    plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "    plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "    \n",
    "    # 标记全局最佳值\n",
    "    best_value = min(values)\n",
    "    best_index = values.index(best_value) + 1\n",
    "    plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                label=f'全局最佳 (试验#{best_index})')\n",
    "    \n",
    "    # 设置图表元素\n",
    "    plt.xlabel('试验次数', fontsize=12)\n",
    "    plt.ylabel('RMSE', fontsize=12)\n",
    "    plt.title('贝叶斯优化过程 (6 VOD + LAI + PFTs + Hveg)', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 保存图像\n",
    "    plot_path = f\"optimization_history/{filename_prefix}_history.png\"\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"优化过程图保存至: {plot_path}\")\n",
    "    \n",
    "    return history_df\n",
    "\n",
    "def plot_optimization_contour(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化等高线图（添加详细错误处理）\"\"\"\n",
    "    try:\n",
    "        import plotly\n",
    "        import optuna.visualization as vis\n",
    "        \n",
    "        # 使用Optuna内置可视化工具\n",
    "        fig = vis.plot_contour(study, params=['n_estimators', 'max_depth'])\n",
    "        if fig:\n",
    "            fig.update_layout(\n",
    "                title='贝叶斯优化参数关系 (6 VOD + LAI + PFTs + Hveg)',\n",
    "                font=dict(size=12),\n",
    "                width=800,\n",
    "                height=600\n",
    "            )\n",
    "            \n",
    "            # 保存为HTML格式以便后续交互查看\n",
    "            os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "            html_path = f\"optimization_history/{filename_prefix}_contour.html\"\n",
    "            fig.write_html(html_path)\n",
    "            print(f\"优化等高线图已保存至: {html_path}\")\n",
    "            \n",
    "            # 尝试保存为静态图片\n",
    "            img_path = f\"optimization_history/{filename_prefix}_contour.png\"\n",
    "            try:\n",
    "                # 明确指定使用kaleido引擎\n",
    "                fig.write_image(img_path, engine=\"kaleido\")\n",
    "                print(f\"优化等高线图已保存至: {img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"警告: 使用kaleido引擎保存静态图片失败: {str(e)}\")\n",
    "                print(\"尝试使用orca引擎...\")\n",
    "                try:\n",
    "                    fig.write_image(img_path, engine=\"orca\")\n",
    "                    print(f\"使用orca引擎保存成功: {img_path}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"使用orca引擎也失败: {str(e2)}\")\n",
    "                    print(\"跳过静态图片保存\")\n",
    "    except ImportError:\n",
    "        print(\"警告: plotly未安装，跳过等高线图绘制\")\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "\n",
    "def visualize_optimization_from_csv(csv_path):\n",
    "    \"\"\"从CSV文件重新绘制优化历史图\"\"\"\n",
    "    try:\n",
    "        history_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 过滤有效试验\n",
    "        history_df = history_df[history_df['state'] == 'COMPLETE'].copy()\n",
    "        \n",
    "        if history_df.empty:\n",
    "            print(\"警告: CSV中没有有效的试验数据\")\n",
    "            return\n",
    "            \n",
    "        # 提取值和最佳值\n",
    "        values = history_df['value'].tolist()\n",
    "        best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "        \n",
    "        # 绘制优化过程图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "        plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "        \n",
    "        # 标记全局最佳值\n",
    "        best_value = min(values)\n",
    "        best_index = values.index(best_value) + 1\n",
    "        plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                    label=f'全局最佳 (试验#{best_index})')\n",
    "        \n",
    "        # 设置图表元素\n",
    "        plt.xlabel('试验次数', fontsize=12)\n",
    "        plt.ylabel('RMSE', fontsize=12)\n",
    "        plt.title('贝叶斯优化过程 (从CSV文件生成)', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        \n",
    "        # 保存和显示\n",
    "        plt_path = csv_path.replace('.csv', '_from_csv.png')\n",
    "        plt.savefig(plt_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"优化过程图已保存至: {plt_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"可视化失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def train_selected_model():\n",
    "    \"\"\"训练使用6 VOD + LAI + PFTs + Hveg的新模型\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"开始训练模型: 6 VOD + LAI + 10 PFTs + Hveg (LightGBM)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. 数据加载与预处理（添加Hveg，去除归一化）\n",
    "    X, y, processed_indices = load_and_preprocess_selected_data()\n",
    "    \n",
    "    # 2. 数据划分\n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "        X, y, processed_indices,\n",
    "        test_size=0.333,\n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"训练集样本数: {len(X_train)}\")\n",
    "    print(f\"测试集样本数: {len(X_test)}\")\n",
    "    \n",
    "    # 3. 贝叶斯优化调参\n",
    "    print(\"\\n开始贝叶斯优化调参...\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"VWC_6VOD_LAI_PFTs_Hveg_Optimization_LGBM\",  # 更新study名称\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=SEED)\n",
    "    )\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), \n",
    "                   n_trials=100)\n",
    "    \n",
    "    # 获取最佳参数\n",
    "    best_params = study.best_params\n",
    "    print(\"\\n最佳参数组合:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"最佳验证RMSE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 4. 优化过程可视化（保存图像和数据）\n",
    "    history_df = plot_optimization_history(study, \"optuna_study_6VOD_LAI_PFTs_Hveg_LGBM\")  # 更新文件名\n",
    "    \n",
    "    # 尝试绘制等高线图\n",
    "    try:\n",
    "        plot_optimization_contour(study, \"optuna_study_6VOD_LAI_PFTs_Hveg_LGBM\")  # 更新文件名\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "    \n",
    "    # 5. 使用最佳参数训练最终模型\n",
    "    print(\"\\n训练最终模型...\")\n",
    "    final_model = lgb.LGBMRegressor(  # 使用LightGBM\n",
    "        **best_params,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. 测试集评估\n",
    "    print(\"\\n测试集评估...\")\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"测试集 RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"测试集 R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # 7. 保存测试集对应原始行（更新后缀）\n",
    "    test_data_dir = \"test_data\"\n",
    "    os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "    # 读取原始表格（仅测试集对应行）\n",
    "    # 重新读取原始数据以获取完整列\n",
    "    full_df = pd.read_excel(DATA_FILE_PATH)\n",
    "    test_rows = full_df.loc[test_idx]\n",
    "    test_rows['y_pred'] = y_pred\n",
    "    test_rows['y_true'] = y_test.values\n",
    "\n",
    "    # 保存精简数据集（更新后缀）\n",
    "    test_data_path = f\"{test_data_dir}/test_rows_6VOD_LAI_PFTs_Hveg_LGBM_Model.csv\"  # 更新后缀\n",
    "    test_rows.to_csv(test_data_path, index=False)\n",
    "    print(f\"测试集对应原始行已保存至: {test_data_path}\") \n",
    "    \n",
    "    # 8. 可视化预测结果（更新后缀）\n",
    "    plot_results_all(y_test, y_pred, \"prediction_results_6VOD_LAI_PFTs_Hveg_LGBM\")  # 更新后缀\n",
    "    \n",
    "    # 9. 保存模型（更新后缀）\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_path = \"models/LGBM_6VOD_LAI_PFTs_Hveg.pkl\"  # 更新后缀为LGBM\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"模型已保存至: {model_path}\")\n",
    "    \n",
    "    # 10. 特征重要性分析\n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        feature_importances = pd.Series(final_model.feature_importances_, index=X.columns)\n",
    "        feature_importances = feature_importances.sort_values(ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        feature_importances.plot(kind='barh')\n",
    "        plt.title('Feature Importance - 6 VOD + LAI + PFTs + Hveg LightGBM Model', fontsize=16, fontweight='bold')  # 更新标题\n",
    "        plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像（更新后缀）\n",
    "        importance_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg_LGBM.png\"  # 更新后缀\n",
    "        plt.savefig(importance_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"特征重要性图保存至: {importance_path}\")\n",
    "        \n",
    "        # 保存特征重要性数据\n",
    "        feature_imp_df = pd.DataFrame({\n",
    "            'feature': feature_importances.index,\n",
    "            'importance': feature_importances.values\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        feature_imp_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg_LGBM.csv\"  # 更新后缀\n",
    "        feature_imp_df.to_csv(feature_imp_path, index=False)\n",
    "        print(f\"特征重要性数据已保存至: {feature_imp_path}\")\n",
    "        \n",
    "        # 打印关键特征重要性\n",
    "        print(\"\\nTop 10特征重要性:\")\n",
    "        for i, (feature, importance) in enumerate(feature_importances.head(10).items()):\n",
    "            print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    else:\n",
    "        print(\"警告: 模型没有feature_importances_属性，跳过特征重要性分析\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_selected_model()\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n模型训练完成!\\n\" + \"=\"*80)\n",
    "    \n",
    "    # 示例：如何使用可视化函数从CSV重新绘图\n",
    "    # 注释掉以下两行以跳过示例\n",
    "    # csv_path = \"optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_LGBM_history.csv\"  # 更新路径\n",
    "    # visualize_optimization_from_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb8034",
   "metadata": {},
   "source": [
    "# 3.XGBoost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb  # 替换为XGBoost\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 全局文件路径常量\n",
    "DATA_FILE_PATH = r\"G:\\Matlab\\EX2025\\AuxiliaryData\\LFMC-gridMean-ML.xlsx\"\n",
    "\n",
    "def load_and_preprocess_selected_data():\n",
    "    \"\"\"数据加载函数 - 只选择6个VOD、LAI、Hveg和10个PFT特征，不进行归一化\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    print(f\"加载数据集: {DATA_FILE_PATH}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 定义所有需要的列\n",
    "    vod_columns = [\n",
    "        'VOD_Ku_Hpol_Asc', 'VOD_Ku_Vpol_Asc',\n",
    "        'VOD_X_Hpol_Asc', 'VOD_X_Vpol_Asc',\n",
    "        'VOD_C_Hpol_Asc', 'VOD_C_Vpol_Asc'\n",
    "    ]\n",
    "    \n",
    "    pft_columns = [\n",
    "        'Grass_man', 'Grass_nat',\n",
    "        'Shrub_bd', 'Shrub_be', 'Shrub_nd', 'Shrub_ne',\n",
    "        'Tree_bd', 'Tree_be', 'Tree_nd', 'Tree_ne'\n",
    "    ]\n",
    "    \n",
    "    required_columns = [\n",
    "        'AGB', 'LFMCValue', 'SamplingDate',  # 用于计算目标变量\n",
    "        'LAI', 'Hveg'  # 主要特征\n",
    "    ] + vod_columns + pft_columns\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_excel(DATA_FILE_PATH, usecols=required_columns)\n",
    "    \n",
    "    # === 数据类型诊断 ===\n",
    "    print(\"\\n初始数据类型:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # 确定需要转换为 float64 的列\n",
    "    columns_to_convert = [col for col in df.columns if col != 'SamplingDate']\n",
    "    \n",
    "    # 清洗并转换为 float64\n",
    "    for col in columns_to_convert:\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            print(f\"清洗并转换列: {col} (当前类型: {df[col].dtype}) 为 float64\")\n",
    "            # 转字符串，去掉空格、逗号、制表符等干扰字符\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"[^\\d\\.\\-eE]\", \"\", regex=True)\n",
    "                .replace({\"\": np.nan})\n",
    "            )\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif df[col].dtype != 'float64':\n",
    "            df[col] = df[col].astype('float64')\n",
    "    \n",
    "    # 检查缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 数据中存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 计算 VWC_sample\n",
    "    df['VWC_sample'] = (df['AGB'] * df['LFMCValue']) / 1000\n",
    "    df['VWC_sample'] = pd.to_numeric(df['VWC_sample'], errors='coerce')\n",
    "    \n",
    "    # 再次清理缺失值\n",
    "    if df.isnull().any().any():\n",
    "        print(\"警告: 类型转换后存在缺失值，正在清理...\")\n",
    "        df = df.dropna()\n",
    "        print(f\"清理后样本数: {len(df)}\")\n",
    "    \n",
    "    # 过滤 VWC_sample\n",
    "    df = df[df['VWC_sample'] <= 30]\n",
    "    \n",
    "    # 特征工程\n",
    "    if 'SamplingDate' in df and pd.api.types.is_datetime64_any_dtype(df['SamplingDate']):\n",
    "        df['Year_diff'] = df['SamplingDate'].dt.year.apply(lambda x: 2020 - x)\n",
    "    else:\n",
    "        print(\"警告: SamplingDate列不存在或不是日期类型，跳过年份差计算\")\n",
    "    \n",
    "    # 定义特征列\n",
    "    feature_columns = vod_columns + ['LAI', 'Hveg'] + pft_columns\n",
    "    available_features = [col for col in feature_columns if col in df]\n",
    "    missing_features = set(feature_columns) - set(available_features)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"警告: 以下特征不存在: {missing_features}\")\n",
    "    \n",
    "    if not available_features:\n",
    "        raise ValueError(\"错误: 没有找到任何特征列\")\n",
    "    \n",
    "    X = df[available_features]\n",
    "    y = df['VWC_sample']\n",
    "    \n",
    "    # 最终检查\n",
    "    print(\"\\n最终数据类型:\")\n",
    "    print(X.dtypes)\n",
    "    print(f\"目标变量类型: {y.dtype}\")\n",
    "    print(f\"数据预处理完成, 耗时: {(time.time()-start_time)/60:.2f}分钟\")\n",
    "    print(f\"使用特征: {len(available_features)}个 (6 VOD, 1 LAI, 1 Hveg, 10 PFT)\")\n",
    "    print(f\"样本数量: {len(X)}\")\n",
    "    \n",
    "    return X, y, df.index\n",
    "\n",
    "def objective(trial, X_train, y_train):\n",
    "    \"\"\"贝叶斯优化目标函数 - 修改为XGBoost超参数\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': SEED,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0  # 静默模式\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params)  # 使用XGBoost模型\n",
    "    \n",
    "    # 五折交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "def plot_results_all(y_true, y_pred, filename):\n",
    "    \"\"\"结果可视化函数（更新文件名后缀）\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # 计算RMSE和R2指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 绘制散点图\n",
    "    plt.scatter(\n",
    "        y_true, y_pred,\n",
    "        marker='x',\n",
    "        color='#FF0000',\n",
    "        linewidths=0.5,\n",
    "        s=40,\n",
    "        alpha=0.8,\n",
    "        zorder=2\n",
    "    )\n",
    "    \n",
    "    # 添加1:1参考线\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', lw=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # 设置坐标轴范围和标签\n",
    "    plt.xlim(0, max_val + 1)\n",
    "    plt.ylim(0, max_val + 1)\n",
    "    plt.xlabel('Insitu VWC (kg/m2)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('XGBoost VWC (kg/m2)', fontsize=12, fontweight='bold')  # 修改ylabel\n",
    "    \n",
    "    # 添加标题（更新后缀）\n",
    "    plt.title(\"6 VOD + LAI + PFTs + Hveg XGBoost Model\", fontsize=16, pad=20, fontweight='bold')  # 修改标题\n",
    "    \n",
    "    # 添加指标文本\n",
    "    plt.text(0.05, 0.95,\n",
    "             f'RMSE = {rmse:.3f} kg/m²\\nR² = {r2:.4f}',\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=12,\n",
    "             fontweight='bold',\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    # 网格线和样式调整\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像（更新后缀）\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    plot_path = f\"figures/{filename}_6VOD_LAI_PFTs_Hveg.png\"  # 更新后缀\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"预测图保存至: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_optimization_history(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化过程历史图并保存数据\"\"\"\n",
    "    # 创建优化历史数据框\n",
    "    history_df = pd.DataFrame({\n",
    "        'trial_number': [t.number for t in study.trials],\n",
    "        'value': [t.value for t in study.trials],\n",
    "        'params': [t.params for t in study.trials],\n",
    "        'state': [t.state for t in study.trials]\n",
    "    })\n",
    "    \n",
    "    # 保存优化历史到CSV\n",
    "    os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "    csv_path = f\"optimization_history/{filename_prefix}_history.csv\"\n",
    "    history_df.to_csv(csv_path, index=False)\n",
    "    print(f\"优化历史数据已保存至: {csv_path}\")\n",
    "    \n",
    "    # 提取所有有效试验的值\n",
    "    valid_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    values = [t.value for t in valid_trials]\n",
    "    best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "    \n",
    "    # 绘制优化过程图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 绘制当前试验值和历史最佳值\n",
    "    plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "    plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "    \n",
    "    # 标记全局最佳值\n",
    "    best_value = min(values)\n",
    "    best_index = values.index(best_value) + 1\n",
    "    plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                label=f'全局最佳 (试验#{best_index})')\n",
    "    \n",
    "    # 设置图表元素\n",
    "    plt.xlabel('试验次数', fontsize=12)\n",
    "    plt.ylabel('RMSE', fontsize=12)\n",
    "    plt.title('贝叶斯优化过程 (6 VOD + LAI + PFTs + Hveg)', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 保存图像\n",
    "    plot_path = f\"optimization_history/{filename_prefix}_history.png\"\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"优化过程图保存至: {plot_path}\")\n",
    "    \n",
    "    return history_df\n",
    "\n",
    "def plot_optimization_contour(study, filename_prefix):\n",
    "    \"\"\"绘制贝叶斯优化等高线图（添加详细错误处理）\"\"\"\n",
    "    try:\n",
    "        import plotly\n",
    "        import optuna.visualization as vis\n",
    "        \n",
    "        # 使用Optuna内置可视化工具\n",
    "        fig = vis.plot_contour(study, params=['n_estimators', 'max_depth'])\n",
    "        if fig:\n",
    "            fig.update_layout(\n",
    "                title='贝叶斯优化参数关系 (6 VOD + LAI + PFTs + Hveg)',\n",
    "                font=dict(size=12),\n",
    "                width=800,\n",
    "                height=600\n",
    "            )\n",
    "            \n",
    "            # 保存为HTML格式以便后续交互查看\n",
    "            os.makedirs(\"optimization_history\", exist_ok=True)\n",
    "            html_path = f\"optimization_history/{filename_prefix}_contour.html\"\n",
    "            fig.write_html(html_path)\n",
    "            print(f\"优化等高线图已保存至: {html_path}\")\n",
    "            \n",
    "            # 尝试保存为静态图片\n",
    "            img_path = f\"optimization_history/{filename_prefix}_contour.png\"\n",
    "            try:\n",
    "                # 明确指定使用kaleido引擎\n",
    "                fig.write_image(img_path, engine=\"kaleido\")\n",
    "                print(f\"优化等高线图已保存至: {img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"警告: 使用kaleido引擎保存静态图片失败: {str(e)}\")\n",
    "                print(\"尝试使用orca引擎...\")\n",
    "                try:\n",
    "                    fig.write_image(img_path, engine=\"orca\")\n",
    "                    print(f\"使用orca引擎保存成功: {img_path}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"使用orca引擎也失败: {str(e2)}\")\n",
    "                    print(\"跳过静态图片保存\")\n",
    "    except ImportError:\n",
    "        print(\"警告: plotly未安装，跳过等高线图绘制\")\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "\n",
    "def visualize_optimization_from_csv(csv_path):\n",
    "    \"\"\"从CSV文件重新绘制优化历史图\"\"\"\n",
    "    try:\n",
    "        history_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 过滤有效试验\n",
    "        history_df = history_df[history_df['state'] == 'COMPLETE'].copy()\n",
    "        \n",
    "        if history_df.empty:\n",
    "            print(\"警告: CSV中没有有效的试验数据\")\n",
    "            return\n",
    "            \n",
    "        # 提取值和最佳值\n",
    "        values = history_df['value'].tolist()\n",
    "        best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "        \n",
    "        # 绘制优化过程图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(values)+1), values, 'o-', color='blue', alpha=0.5, label='当前试验RMSE')\n",
    "        plt.plot(range(1, len(values)+1), best_values, 'r-', linewidth=2, label='历史最佳RMSE')\n",
    "        \n",
    "        # 标记全局最佳值\n",
    "        best_value = min(values)\n",
    "        best_index = values.index(best_value) + 1\n",
    "        plt.scatter(best_index, best_value, marker='*', s=200, color='red', \n",
    "                    label=f'全局最佳 (试验#{best_index})')\n",
    "        \n",
    "        # 设置图表元素\n",
    "        plt.xlabel('试验次数', fontsize=12)\n",
    "        plt.ylabel('RMSE', fontsize=12)\n",
    "        plt.title('贝叶斯优化过程 (从CSV文件生成)', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        \n",
    "        # 保存和显示\n",
    "        plt_path = csv_path.replace('.csv', '_from_csv.png')\n",
    "        plt.savefig(plt_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"优化过程图已保存至: {plt_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"可视化失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def train_selected_model():\n",
    "    \"\"\"训练使用6 VOD + LAI + PFTs + Hveg的新模型\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"开始训练模型: 6 VOD + LAI + 10 PFTs + Hveg (XGBoost)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. 数据加载与预处理\n",
    "    X, y, processed_indices = load_and_preprocess_selected_data()\n",
    "    \n",
    "    # 2. 数据划分\n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "        X, y, processed_indices,\n",
    "        test_size=0.333,\n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"训练集样本数: {len(X_train)}\")\n",
    "    print(f\"测试集样本数: {len(X_test)}\")\n",
    "    \n",
    "    # 3. 贝叶斯优化调参\n",
    "    print(\"\\n开始贝叶斯优化调参...\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"VWC_6VOD_LAI_PFTs_Hveg_Optimization_XGB\",  # 更新study名称\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=SEED)\n",
    "    )\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), \n",
    "                   n_trials=100)\n",
    "    \n",
    "    # 获取最佳参数\n",
    "    best_params = study.best_params\n",
    "    print(\"\\n最佳参数组合:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"最佳验证RMSE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 4. 优化过程可视化\n",
    "    history_df = plot_optimization_history(study, \"optuna_study_6VOD_LAI_PFTs_Hveg_XGB\")  # 更新文件名\n",
    "    \n",
    "    # 尝试绘制等高线图\n",
    "    try:\n",
    "        plot_optimization_contour(study, \"optuna_study_6VOD_LAI_PFTs_Hveg_XGB\")  # 更新文件名\n",
    "    except Exception as e:\n",
    "        print(f\"绘制等高线图时发生错误: {str(e)}\")\n",
    "    \n",
    "    # 5. 使用最佳参数训练最终模型\n",
    "    print(\"\\n训练最终模型...\")\n",
    "    final_model = xgb.XGBRegressor(  # 使用XGBoost\n",
    "        **best_params,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. 测试集评估\n",
    "    print(\"\\n测试集评估...\")\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"测试集 RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"测试集 R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # 7. 保存测试集对应原始行\n",
    "    test_data_dir = \"test_data\"\n",
    "    os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "    # 读取原始表格（仅测试集对应行）\n",
    "    full_df = pd.read_excel(DATA_FILE_PATH)\n",
    "    test_rows = full_df.loc[test_idx]\n",
    "    test_rows['y_pred'] = y_pred\n",
    "    test_rows['y_true'] = y_test.values\n",
    "\n",
    "    # 保存精简数据集\n",
    "    test_data_path = f\"{test_data_dir}/test_rows_6VOD_LAI_PFTs_Hveg_XGB_Model.csv\"  # 更新后缀\n",
    "    test_rows.to_csv(test_data_path, index=False)\n",
    "    print(f\"测试集对应原始行已保存至: {test_data_path}\") \n",
    "    \n",
    "    # 8. 可视化预测结果\n",
    "    plot_results_all(y_test, y_pred, \"prediction_results_6VOD_LAI_PFTs_Hveg_XGB\")  # 更新后缀\n",
    "    \n",
    "    # 9. 保存模型\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_path = \"models/XGB_6VOD_LAI_PFTs_Hveg.pkl\"  # 更新后缀为XGB\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"模型已保存至: {model_path}\")\n",
    "    \n",
    "    # 10. 特征重要性分析\n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        feature_importances = pd.Series(final_model.feature_importances_, index=X.columns)\n",
    "        feature_importances = feature_importances.sort_values(ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        feature_importances.plot(kind='barh')\n",
    "        plt.title('Feature Importance - 6 VOD + LAI + PFTs + Hveg XGBoost Model', fontsize=16, fontweight='bold')  # 更新标题\n",
    "        plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图像\n",
    "        importance_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg_XGB.png\"  # 更新后缀\n",
    "        plt.savefig(importance_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"特征重要性图保存至: {importance_path}\")\n",
    "        \n",
    "        # 保存特征重要性数据\n",
    "        feature_imp_df = pd.DataFrame({\n",
    "            'feature': feature_importances.index,\n",
    "            'importance': feature_importances.values\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        feature_imp_path = f\"figures/feature_importance_6VOD_LAI_PFTs_Hveg_XGB.csv\"  # 更新后缀\n",
    "        feature_imp_df.to_csv(feature_imp_path, index=False)\n",
    "        print(f\"特征重要性数据已保存至: {feature_imp_path}\")\n",
    "        \n",
    "        # 打印关键特征重要性\n",
    "        print(\"\\nTop 10特征重要性:\")\n",
    "        for i, (feature, importance) in enumerate(feature_importances.head(10).items()):\n",
    "            print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    else:\n",
    "        print(\"警告: 模型没有feature_importances_属性，跳过特征重要性分析\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_selected_model()\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n模型训练完成!\\n\" + \"=\"*80)\n",
    "    \n",
    "    # 示例：如何使用可视化函数从CSV重新绘图\n",
    "    # 注释掉以下两行以跳过示例\n",
    "    # csv_path = \"optimization_history/optuna_study_6VOD_LAI_PFTs_Hveg_XGB_history.csv\"  # 更新路径\n",
    "    # visualize_optimization_from_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85a33e",
   "metadata": {},
   "source": [
    "<!-- # 4.TabTransformer -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a41cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Project312)",
   "language": "python",
   "name": "project312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
